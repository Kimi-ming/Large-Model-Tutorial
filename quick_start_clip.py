#!/usr/bin/env python3
"""
CLIPå¿«é€Ÿå¼€å§‹ç¤ºä¾‹

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„CLIPæ¨¡å‹æ¨ç†ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    import torch
    from transformers import CLIPModel, CLIPProcessor
    from PIL import Image
    import requests
    from io import BytesIO
except ImportError as e:
    print("âŒ ç¼ºå°‘ä¾èµ–åº“ï¼Œè¯·å…ˆå®‰è£…:")
    print("   pip install torch transformers pillow requests")
    print(f"\né”™è¯¯è¯¦æƒ…: {e}")
    sys.exit(1)


def download_sample_image():
    """ä¸‹è½½ç¤ºä¾‹å›¾åƒï¼ˆå¸¦å¤šä¸ªå¤‡ç”¨URLï¼‰"""
    print("ğŸ“¥ å‡†å¤‡ç¤ºä¾‹å›¾åƒ...")
    
    # å¤šä¸ªå¤‡ç”¨å›¾åƒURLï¼ˆä»ç®€å•åˆ°å¤æ‚ï¼‰
    image_urls = [
        # å¤‡ç”¨1: çº¯è‰²å›¾åƒï¼ˆdata URIï¼Œæ°¸ä¸å¤±æ•ˆï¼‰
        "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==",
        # å¤‡ç”¨2: å…¬å¼€å›¾åƒURL
        "https://picsum.photos/400/300",
        # å¤‡ç”¨3: Unsplash
        "https://images.unsplash.com/photo-1543466835-00a7907e9de1?w=400",
    ]
    
    # å°è¯•ä»URLä¸‹è½½
    for idx, url in enumerate(image_urls[1:], 1):  # è·³è¿‡data URIï¼Œä½œä¸ºæœ€åå¤‡ç”¨
        try:
            print(f"å°è¯•ä¸‹è½½... (æ–¹æ¡ˆ {idx})")
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            image = Image.open(BytesIO(response.content))
            # ç¡®ä¿å›¾åƒæ˜¯RGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            print(f"âœ… å›¾åƒä¸‹è½½æˆåŠŸ (æ¥æº: æ–¹æ¡ˆ {idx})")
            return image
        except Exception as e:
            print(f"âš ï¸  æ–¹æ¡ˆ {idx} å¤±è´¥: {e}")
            continue
    
    # æ‰€æœ‰URLéƒ½å¤±è´¥ï¼Œåˆ›å»ºæœ¬åœ°æ¼”ç¤ºå›¾åƒ
    print("ğŸ’¡ ä½¿ç”¨æœ¬åœ°ç”Ÿæˆçš„æ¼”ç¤ºå›¾åƒ...")
    try:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¸å˜å›¾åƒ
        import numpy as np
        width, height = 400, 300
        img_array = np.zeros((height, width, 3), dtype=np.uint8)
        
        # åˆ›å»ºæ¸å˜æ•ˆæœ
        for i in range(height):
            for j in range(width):
                img_array[i, j] = [
                    int(255 * i / height),  # Red gradient
                    int(255 * j / width),   # Green gradient
                    128                      # Constant blue
                ]
        
        image = Image.fromarray(img_array, 'RGB')
        print("âœ… ä½¿ç”¨æœ¬åœ°ç”Ÿæˆçš„æ¼”ç¤ºå›¾åƒ")
        return image
    except Exception as e:
        # æœ€åçš„æœ€åï¼Œåˆ›å»ºçº¯è‰²å›¾åƒ
        print(f"âš ï¸  ç”Ÿæˆå¤±è´¥: {e}")
        print("ğŸ’¡ ä½¿ç”¨çº¯è‰²å›¾åƒ...")
        image = Image.new('RGB', (400, 300), color=(73, 109, 137))
        return image


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸš€ CLIP å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 70)
    
    # 1. æ£€æŸ¥è®¾å¤‡
    print("\nğŸ“Š æ­¥éª¤ 1/4: æ£€æŸ¥ç¯å¢ƒ")
    print("-" * 70)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    if device == "cuda":
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    
    # 2. åŠ è½½æ¨¡å‹
    print("\nğŸ“¥ æ­¥éª¤ 2/4: åŠ è½½CLIPæ¨¡å‹")
    print("-" * 70)
    print("æ­£åœ¨åŠ è½½ openai/clip-vit-base-patch32...")
    
    try:
        model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        model = model.to(device)
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. æˆ–å…ˆä¸‹è½½æ¨¡å‹: ./scripts/download_models.sh clip")
        sys.exit(1)
    
    # 3. å‡†å¤‡æ•°æ®
    print("\nğŸ–¼ï¸  æ­¥éª¤ 3/4: å‡†å¤‡æµ‹è¯•æ•°æ®")
    print("-" * 70)
    
    # å‡†å¤‡å›¾åƒ
    image = download_sample_image()
    
    # å‡†å¤‡å€™é€‰æ–‡æœ¬
    texts = [
        "a photo of a dog",
        "a photo of a cat",
        "a photo of a car",
        "a photo of a bird",
        "a photo of a flower"
    ]
    
    print(f"å›¾åƒå°ºå¯¸: {image.size}")
    print(f"å€™é€‰æ–‡æœ¬æ•°: {len(texts)}")
    print(f"å€™é€‰æ–‡æœ¬: {texts}")
    
    # 4. æ¨ç†
    print("\nğŸ”® æ­¥éª¤ 4/4: æ‰§è¡Œæ¨ç†")
    print("-" * 70)
    
    try:
        # é¢„å¤„ç†
        inputs = processor(
            text=texts,
            images=image,
            return_tensors="pt",
            padding=True
        )
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        # æ¨ç†
        with torch.no_grad():
            outputs = model(**inputs)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        logits_per_image = outputs.logits_per_image
        probs = logits_per_image.softmax(dim=1)
        
        print("âœ… æ¨ç†å®Œæˆ\n")
        
        # æ˜¾ç¤ºç»“æœ
        print("ğŸ“Š å›¾æ–‡åŒ¹é…ç»“æœ:")
        print("-" * 70)
        
        results = []
        for i, (text, prob) in enumerate(zip(texts, probs[0])):
            results.append((text, prob.item()))
        
        # æŒ‰æ¦‚ç‡æ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        
        for i, (text, prob) in enumerate(results, 1):
            bar_length = int(prob * 50)
            bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
            print(f"{i}. {text:30s} {bar} {prob:6.2%}")
        
        print("\n" + "=" * 70)
        print("ğŸ‰ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹å®Œæˆï¼")
        print("=" * 70)
        
        # ä¸‹ä¸€æ­¥æç¤º
        print("\nğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ :")
        print("   1. æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: docs/01-æ¨¡å‹è°ƒç ”ä¸é€‰å‹/")
        print("   2. è¿è¡ŒåŸºå‡†æµ‹è¯•: ./scripts/run_benchmarks.sh")
        print("   3. å°è¯•æ¨¡å‹å¾®è°ƒ: notebooks/01_lora_finetuning_tutorial.ipynb")
        print("   4. æ›´å¤šç¤ºä¾‹ä»£ç : code/01-model-evaluation/examples/")
        
        print("\nğŸ’¡ æç¤º:")
        print("   - ä¿®æ”¹ texts åˆ—è¡¨æ¥æµ‹è¯•ä¸åŒçš„æ–‡æœ¬")
        print("   - ä½¿ç”¨è‡ªå·±çš„å›¾åƒ: image = Image.open('your_image.jpg')")
        print("   - æŸ¥çœ‹å®Œæ•´æ•™ç¨‹: docs/05-ä½¿ç”¨è¯´æ˜/02-å¿«é€Ÿå¼€å§‹.md")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

