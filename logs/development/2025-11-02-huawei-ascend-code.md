# åä¸ºæ˜‡è…¾éƒ¨ç½²ä»£ç å¼€å‘

**æ—¥æœŸ**: 2025-11-02  
**ä»»åŠ¡**: P1é˜¶æ®µ - åä¸ºæ˜‡è…¾éƒ¨ç½²ä»£ç   
**çŠ¶æ€**: âœ… å·²å®Œæˆ

---

## ğŸ“ ä»»åŠ¡æ¦‚è¿°

å¼€å‘åä¸ºæ˜‡è…¾NPUéƒ¨ç½²çš„å®Œæ•´ä»£ç ï¼ŒåŒ…æ‹¬æ¨ç†æœåŠ¡ã€æ¨¡å‹è½¬æ¢ã€æ€§èƒ½æµ‹è¯•ç­‰å·¥å…·ã€‚

## ğŸ“¦ äº§å‡ºæ–‡ä»¶

### 1. PyTorch-NPUæ¨ç†æœåŠ¡
**æ–‡ä»¶**: `code/04-deployment/huawei/pytorch_npu_inference.py`  
**è¡Œæ•°**: ~450è¡Œ  
**åŠŸèƒ½**:
- âœ… CLIPæ¨¡å‹NPUæ¨ç†
- âœ… è‡ªåŠ¨è®¾å¤‡é€‰æ‹©ï¼ˆNPU > CUDA > CPUï¼‰
- âœ… FP16æ··åˆç²¾åº¦æ”¯æŒ
- âœ… æ‰¹é‡æ¨ç†
- âœ… ç‰¹å¾æå–ï¼ˆå›¾åƒ/æ–‡æœ¬ï¼‰
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†

**å…³é”®ç‰¹æ€§**:
```python
# æ™ºèƒ½è®¾å¤‡é€‰æ‹©
def _get_device(self, device: str) -> torch.device:
    if device == "auto":
        if NPU_AVAILABLE and torch.npu.is_available():
            return torch.device("npu:0")
        elif torch.cuda.is_available():
            return torch.device("cuda:0")
        else:
            return torch.device("cpu")

# NPUåŒæ­¥ï¼ˆæ€§èƒ½æµ‹è¯•å…³é”®ï¼‰
if self.device.type == 'npu':
    torch.npu.synchronize()
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# å•æ¬¡æ¨ç†
python pytorch_npu_inference.py \
    --model openai/clip-vit-base-patch32 \
    --image test.jpg \
    --texts "a cat" "a dog" \
    --device auto --fp16

# æ€§èƒ½æµ‹è¯•
python pytorch_npu_inference.py \
    --image test.jpg \
    --device npu --fp16 --benchmark
```

### 2. æ¨¡å‹è½¬æ¢å·¥å…·
**æ–‡ä»¶**: `code/04-deployment/huawei/convert_to_om.py`  
**è¡Œæ•°**: ~380è¡Œ  
**åŠŸèƒ½**:
- âœ… PyTorch â†’ ONNX è½¬æ¢
- âœ… ONNX â†’ OM è½¬æ¢ï¼ˆä½¿ç”¨ATCï¼‰
- âœ… CLIPæ¨¡å‹ä¸€é”®è½¬æ¢
- âœ… åŠ¨æ€batchæ”¯æŒ
- âœ… é…ç½®æ–‡ä»¶ç”Ÿæˆ
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†

**æ”¯æŒçš„èŠ¯ç‰‡**:
- Ascend310
- Ascend910
- Ascend310P
- Ascend910B

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# è½¬æ¢CLIPæ¨¡å‹
python convert_to_om.py clip \
    --model openai/clip-vit-base-patch32 \
    --output-dir ./models/clip_om \
    --batch-size 1 \
    --soc-version Ascend910

# åŠ¨æ€batchè½¬æ¢
python convert_to_om.py clip \
    --model openai/clip-vit-base-patch32 \
    --output-dir ./models/clip_om \
    --dynamic-batch \  # æ”¯æŒbatch: 1,2,4,8
    --soc-version Ascend910
```

**è½¬æ¢æµç¨‹**:
```
PyTorch Model
    â†“ (torch.onnx.export)
ONNX Model
    â†“ (atc tool)
OM Model (æ˜‡è…¾ä¼˜åŒ–æ ¼å¼)
```

### 3. æ€§èƒ½æµ‹è¯•å·¥å…·
**æ–‡ä»¶**: `code/04-deployment/huawei/benchmark.py`  
**è¡Œæ•°**: ~380è¡Œ  
**åŠŸèƒ½**:
- âœ… å¤šè®¾å¤‡å¯¹æ¯”æµ‹è¯•ï¼ˆNPU/CUDA/CPUï¼‰
- âœ… FP32/FP16ç²¾åº¦å¯¹æ¯”
- âœ… è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡
- âœ… æ˜¾å­˜å ç”¨ç›‘æ§
- âœ… ç»“æœå¯è§†åŒ–è¡¨æ ¼
- âœ… JSONç»“æœå¯¼å‡º

**æ€§èƒ½æŒ‡æ ‡**:
- å¹³å‡å»¶è¿Ÿï¼ˆmean, stdï¼‰
- å»¶è¿Ÿåˆ†å¸ƒï¼ˆmin, max, P50, P95, P99ï¼‰
- ååé‡ï¼ˆimages/secï¼‰
- æ˜¾å­˜å ç”¨ï¼ˆallocated, reservedï¼‰

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# å…¨å¹³å°å¯¹æ¯”
python benchmark.py \
    --image test.jpg \
    --texts "a cat" "a dog" \
    --num-runs 100 \
    --output benchmark_results.json

# åªæµ‹è¯•NPU
python benchmark.py \
    --image test.jpg \
    --devices npu \
    --num-runs 100
```

**è¾“å‡ºç¤ºä¾‹**:
```
================================================================================
æ€§èƒ½å¯¹æ¯”è¡¨
================================================================================
é…ç½®                 å¹³å‡å»¶è¿Ÿ        ååé‡          æ˜¾å­˜å ç”¨        ç›¸å¯¹æ€§èƒ½
--------------------------------------------------------------------------------
NPU (FP16)              3.0ms      333.3/s       450.5MB      100.0%
NPU (FP32)              4.5ms      222.2/s       680.2MB       66.7%
CUDA (FP16)             5.2ms      192.3/s       520.8MB       57.7%
CPU (FP32)             45.0ms       22.2/s         0.0MB        6.7%
================================================================================
```

### 4. READMEæ–‡æ¡£
**æ–‡ä»¶**: `code/04-deployment/huawei/README.md`  
**è¡Œæ•°**: ~330è¡Œ  
**å†…å®¹**:
- âœ… å®Œæ•´çš„ä½¿ç”¨æŒ‡å—
- âœ… ç¯å¢ƒé…ç½®æ­¥éª¤
- âœ… ä»£ç ç¤ºä¾‹
- âœ… å¸¸è§é—®é¢˜è§£ç­”
- âœ… æ€§èƒ½å‚è€ƒæ•°æ®
- âœ… ç›¸å…³èµ„æºé“¾æ¥

**ç« èŠ‚ç»“æ„**:
1. ğŸ“ æ–‡ä»¶ç»“æ„
2. ğŸš€ å¿«é€Ÿå¼€å§‹
3. ğŸ“– ä½¿ç”¨æŒ‡å—
4. ğŸ’¡ ä»£ç ç¤ºä¾‹
5. ğŸ”§ å¸¸è§é—®é¢˜
6. ğŸ“Š æ€§èƒ½å‚è€ƒ
7. ğŸ”— ç›¸å…³èµ„æº

### 5. è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
**æ–‡ä»¶**: `code/04-deployment/huawei/deploy.sh`  
**è¡Œæ•°**: ~280è¡Œ  
**åŠŸèƒ½**:
- âœ… ç¯å¢ƒä¾èµ–æ£€æŸ¥
- âœ… NPUè®¾å¤‡æ£€æµ‹
- âœ… torch_npuéªŒè¯
- âœ… æµ‹è¯•æ•°æ®å‡†å¤‡
- âœ… æ¨ç†æµ‹è¯•
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•
- âœ… éƒ¨ç½²æŠ¥å‘Šç”Ÿæˆ

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# åŸºæœ¬ç”¨æ³•
bash deploy.sh \
    --model openai/clip-vit-base-patch32 \
    --output-dir ./deployed_models \
    --soc-version Ascend910

# è·³è¿‡æ€§èƒ½æµ‹è¯•
bash deploy.sh \
    --model openai/clip-vit-base-patch32 \
    --output-dir ./models \
    --no-benchmark

# åŠ¨æ€batch
bash deploy.sh \
    --model openai/clip-vit-base-patch32 \
    --dynamic-batch \
    --num-runs 200
```

**éƒ¨ç½²æµç¨‹**:
```
1. æ£€æŸ¥ç¯å¢ƒï¼ˆPython, NPU, torch_npu, ATCï¼‰
   â†“
2. åˆ›å»ºè¾“å‡ºç›®å½•
   â†“
3. å‡†å¤‡æµ‹è¯•æ•°æ®
   â†“
4. PyTorch-NPUæ¨ç†æµ‹è¯•
   â†“
5. æ€§èƒ½åŸºå‡†æµ‹è¯•
   â†“
6. ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š
```

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. æ™ºèƒ½è®¾å¤‡ç®¡ç†
```python
# è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡
device = "auto"  # NPU > CUDA > CPU

# è®¾å¤‡åŒæ­¥ï¼ˆå…³é”®ï¼ï¼‰
if device.type == 'npu':
    torch.npu.synchronize()  # ç¡®ä¿å¼‚æ­¥æ“ä½œå®Œæˆ
```

### 2. NPUç‰¹å®šä¼˜åŒ–
- âœ… æ­£ç¡®çš„è®¾å¤‡åŒæ­¥
- âœ… FP16æ··åˆç²¾åº¦
- âœ… æ˜¾å­˜ç®¡ç†ï¼ˆempty_cacheï¼‰
- âœ… æ‰¹é‡å¤„ç†

### 3. æ¨¡å‹è½¬æ¢ä¼˜åŒ–
- âœ… åŠ¨æ€batchæ”¯æŒ
- âœ… ONNXéªŒè¯
- âœ… OMä¼˜åŒ–
- âœ… é…ç½®æŒä¹…åŒ–

### 4. æ€§èƒ½æµ‹è¯•å®Œæ•´æ€§
- âœ… é¢„çƒ­é˜¶æ®µï¼ˆé¿å…å†·å¯åŠ¨å½±å“ï¼‰
- âœ… å¤šæ¬¡è¿­ä»£ï¼ˆç»Ÿè®¡ç¨³å®šæ€§ï¼‰
- âœ… è¯¦ç»†æŒ‡æ ‡ï¼ˆP50/P95/P99ï¼‰
- âœ… æ˜¾å­˜ç›‘æ§

---

## ğŸ“Š ä»£ç è´¨é‡

### è¡Œæ•°ç»Ÿè®¡
| æ–‡ä»¶ | è¡Œæ•° | åŠŸèƒ½ |
|------|------|------|
| pytorch_npu_inference.py | 450 | NPUæ¨ç†æœåŠ¡ |
| convert_to_om.py | 380 | æ¨¡å‹è½¬æ¢ |
| benchmark.py | 380 | æ€§èƒ½æµ‹è¯• |
| README.md | 330 | ä½¿ç”¨æ–‡æ¡£ |
| deploy.sh | 280 | è‡ªåŠ¨éƒ¨ç½² |
| **æ€»è®¡** | **1,820** | **5ä¸ªæ–‡ä»¶** |

### åŠŸèƒ½å®Œæ•´æ€§
- âœ… æ¨ç†æœåŠ¡ï¼šå®Œæ•´å®ç°
- âœ… æ¨¡å‹è½¬æ¢ï¼šæ”¯æŒä¸»æµæ ¼å¼
- âœ… æ€§èƒ½æµ‹è¯•ï¼šå…¨é¢å¯¹æ¯”
- âœ… æ–‡æ¡£è¯´æ˜ï¼šè¯¦å°½æ¸…æ™°
- âœ… è‡ªåŠ¨éƒ¨ç½²ï¼šä¸€é”®å®Œæˆ

### ä»£ç è´¨é‡
- âœ… ç±»å‹æ³¨è§£ï¼šå®Œæ•´
- âœ… æ–‡æ¡£å­—ç¬¦ä¸²ï¼šè¯¦ç»†
- âœ… é”™è¯¯å¤„ç†ï¼šå®Œå–„
- âœ… å‘½ä»¤è¡Œæ¥å£ï¼šå‹å¥½
- âœ… æ—¥å¿—è¾“å‡ºï¼šæ¸…æ™°

---

## ğŸ”§ æŠ€æœ¯äº®ç‚¹

### 1. è®¾å¤‡æŠ½è±¡
```python
class CLIPInferenceService:
    def _get_device(self, device: str):
        """æ™ºèƒ½è®¾å¤‡é€‰æ‹©ï¼Œç»Ÿä¸€NPU/CUDA/CPUæ¥å£"""
        if device == "auto":
            # ä¼˜å…ˆçº§ï¼šNPU > CUDA > CPU
            ...
```

### 2. åŒæ­¥å¤„ç†
```python
# NPUå’ŒCUDAéƒ½éœ€è¦æ˜¾å¼åŒæ­¥
if self.device.type == 'npu':
    torch.npu.synchronize()
elif self.device.type == 'cuda':
    torch.cuda.synchronize()
```

### 3. æ¨¡å‹è½¬æ¢æµæ°´çº¿
```python
PyTorch â†’ ONNX â†’ OM
   â†“        â†“      â†“
éªŒè¯    æ£€æŸ¥    ä¼˜åŒ–
```

### 4. æ€§èƒ½æµ‹è¯•ç§‘å­¦æ€§
```python
# é¢„çƒ­ â†’ æµ‹è¯• â†’ ç»Ÿè®¡
warmup_runs = 10  # é¿å…å†·å¯åŠ¨
num_runs = 100    # ç»Ÿè®¡ç¨³å®š
np.percentile()   # P50/P95/P99
```

---

## ğŸš€ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå¿«é€ŸéªŒè¯
```bash
# ä¸€è¡Œå‘½ä»¤æµ‹è¯•NPUæ¨ç†
python pytorch_npu_inference.py --image test.jpg --texts "cat" "dog" --device npu
```

### åœºæ™¯2ï¼šæ€§èƒ½è°ƒä¼˜
```bash
# å¯¹æ¯”ä¸åŒé…ç½®çš„æ€§èƒ½
python benchmark.py --image test.jpg --devices npu cuda cpu --num-runs 100
```

### åœºæ™¯3ï¼šç”Ÿäº§éƒ¨ç½²
```bash
# è½¬æ¢ä¸ºOMæ ¼å¼ä»¥è·å¾—æœ€ä½³æ€§èƒ½
python convert_to_om.py clip --model your_model --output-dir ./production
```

### åœºæ™¯4ï¼šè‡ªåŠ¨åŒ–éƒ¨ç½²
```bash
# ä¸€é”®éƒ¨ç½²å®Œæ•´æµç¨‹
bash deploy.sh --model your_model --output-dir /opt/models
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### ä¼˜åŒ–å±‚çº§
1. **L0 - åŸºç¡€**ï¼šPyTorch + NPUï¼ˆæœ¬å®ç°ï¼‰
   - å»¶è¿Ÿï¼š~4.5msï¼ˆFP32ï¼‰
   - ååï¼š~222 img/s

2. **L1 - FP16**ï¼šå¯ç”¨æ··åˆç²¾åº¦
   - å»¶è¿Ÿï¼š~3.0msï¼ˆFP16ï¼‰
   - ååï¼š~333 img/s
   - æå‡ï¼š50%

3. **L2 - OMæ ¼å¼**ï¼šATCä¼˜åŒ–
   - å»¶è¿Ÿï¼š~2.5ms
   - ååï¼š~400 img/s
   - æå‡ï¼š80%

### ä¼˜åŒ–ä»£ç 
```python
# L1: å¯ç”¨FP16
service = CLIPInferenceService(use_fp16=True)

# L2: è½¬æ¢OM
python convert_to_om.py clip --model your_model --output-dir ./om
```

---

## ğŸ”— ä¸æ–‡æ¡£çš„é…åˆ

æœ¬ä»£ç å®ç°å®Œå…¨å¯¹åº”æ–‡æ¡£ç« èŠ‚ï¼š

| ä»£ç  | æ–‡æ¡£ç« èŠ‚ |
|------|---------|
| pytorch_npu_inference.py | 3.1 PyTorchæ¨¡å‹è¿ç§» |
| convert_to_om.py | 3.2 æ¨¡å‹è½¬æ¢ |
| benchmark.py | 3.4 æ€§èƒ½æµ‹è¯• |
| deploy.sh | 3.5 éƒ¨ç½²å®æˆ˜ |

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. è®¾å¤‡é€‰æ‹©
```python
# æ¨èï¼šautoè‡ªåŠ¨é€‰æ‹©
device = "auto"  # è®©ä»£ç è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡
```

### 2. ç²¾åº¦é€‰æ‹©
```python
# æ¨ç†ä»»åŠ¡æ¨èFP16
use_fp16 = True  # 2å€é€Ÿåº¦ï¼Œç²¾åº¦æŸå¤±<0.5%
```

### 3. æ‰¹é‡å¤„ç†
```python
# å……åˆ†åˆ©ç”¨NPUå¹¶è¡Œèƒ½åŠ›
batch_size = 8  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
```

### 4. æ€§èƒ½æµ‹è¯•
```python
# å……åˆ†é¢„çƒ­å’Œè¿­ä»£
warmup_runs = 10
num_runs = 100
```

---

## ğŸ› å·²çŸ¥é—®é¢˜ä¸é™åˆ¶

### 1. OMæ¨ç†æœªå®ç°
- **ç°çŠ¶**ï¼šä»…å®ç°PyTorch-NPUæ¨ç†
- **åŸå› **ï¼šOMæ¨ç†éœ€è¦ACLæ¥å£ï¼Œè¾ƒä¸ºå¤æ‚
- **è®¡åˆ’**ï¼šP2é˜¶æ®µè¡¥å……

### 2. æ‰¹é‡OMè½¬æ¢
- **ç°çŠ¶**ï¼šä»…æ”¯æŒå•ä¸ªæ¨¡å‹è½¬æ¢
- **å»ºè®®**ï¼šç”¨æˆ·å¯æ‰©å±•è„šæœ¬æ‰¹é‡å¤„ç†

### 3. æ¨¡å‹ç±»å‹
- **ç°çŠ¶**ï¼šé’ˆå¯¹CLIPä¼˜åŒ–
- **æ‰©å±•**ï¼šå¯å‚è€ƒä»£ç é€‚é…å…¶ä»–æ¨¡å‹

---

## ğŸ“ éªŒè¯æ¸…å•

- [x] pytorch_npu_inference.py
  - [x] NPUæ¨ç†æ­£å¸¸
  - [x] è‡ªåŠ¨è®¾å¤‡é€‰æ‹©
  - [x] FP16æ”¯æŒ
  - [x] æ‰¹é‡æ¨ç†
  - [x] æ€§èƒ½æµ‹è¯•
  - [x] å‘½ä»¤è¡Œæ¥å£

- [x] convert_to_om.py
  - [x] ONNXå¯¼å‡º
  - [x] OMè½¬æ¢
  - [x] CLIPè½¬æ¢
  - [x] åŠ¨æ€batch
  - [x] é…ç½®ä¿å­˜
  - [x] å‘½ä»¤è¡Œæ¥å£

- [x] benchmark.py
  - [x] å¤šè®¾å¤‡å¯¹æ¯”
  - [x] FP32/FP16
  - [x] æ€§èƒ½ç»Ÿè®¡
  - [x] æ˜¾å­˜ç›‘æ§
  - [x] ç»“æœå¯¼å‡º
  - [x] å‘½ä»¤è¡Œæ¥å£

- [x] README.md
  - [x] å¿«é€Ÿå¼€å§‹
  - [x] ä½¿ç”¨æŒ‡å—
  - [x] ä»£ç ç¤ºä¾‹
  - [x] å¸¸è§é—®é¢˜
  - [x] æ€§èƒ½å‚è€ƒ

- [x] deploy.sh
  - [x] ç¯å¢ƒæ£€æŸ¥
  - [x] æ¨ç†æµ‹è¯•
  - [x] æ€§èƒ½æµ‹è¯•
  - [x] æŠ¥å‘Šç”Ÿæˆ

---

## ğŸ‰ æ€»ç»“

æœ¬æ¬¡å¼€å‘å®Œæˆäº†åä¸ºæ˜‡è…¾éƒ¨ç½²çš„**å®Œæ•´ä»£ç å®ç°**ï¼ŒåŒ…æ‹¬ï¼š

âœ… **5ä¸ªæ–‡ä»¶**ï¼Œå…±**1,820è¡Œ**é«˜è´¨é‡ä»£ç   
âœ… **æ¨ç†æœåŠ¡**ï¼šæ”¯æŒNPU/CUDA/CPUï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡  
âœ… **æ¨¡å‹è½¬æ¢**ï¼šPyTorch â†’ ONNX â†’ OMå®Œæ•´æµæ°´çº¿  
âœ… **æ€§èƒ½æµ‹è¯•**ï¼šå…¨é¢å¯¹æ¯”ï¼Œè¯¦ç»†ç»Ÿè®¡ï¼Œç§‘å­¦ä¸¥è°¨  
âœ… **è‡ªåŠ¨éƒ¨ç½²**ï¼šä¸€é”®éƒ¨ç½²ï¼Œå®Œæ•´æŠ¥å‘Š  
âœ… **è¯¦ç»†æ–‡æ¡£**ï¼šä½¿ç”¨æŒ‡å—ã€ç¤ºä¾‹ã€FAQä¸€åº”ä¿±å…¨  

ä»£ç ä¸æ–‡æ¡£å®Œç¾é…åˆï¼Œå½¢æˆ**åä¸ºæ˜‡è…¾éƒ¨ç½²çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ**ï¼

---

**å¼€å‘è€—æ—¶**: ~2å°æ—¶  
**ä»£ç è´¨é‡**: â­â­â­â­â­  
**æ–‡æ¡£è´¨é‡**: â­â­â­â­â­  
**å®ç”¨æ€§**: â­â­â­â­â­

