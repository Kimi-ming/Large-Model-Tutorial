# è§†è§‰å¤§æ¨¡å‹åŸºå‡†æµ‹è¯•å·¥å…·

æœ¬ç›®å½•åŒ…å«è§†è§‰å¤§æ¨¡å‹çš„æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·ï¼Œç”¨äºè¯„ä¼°ä¸åŒæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€æ˜¾å­˜å ç”¨å’Œå‡†ç¡®ç‡ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | åŠŸèƒ½ | ç”¨æ³• |
|------|------|------|
| `speed_test.py` | æ¨ç†é€Ÿåº¦æµ‹è¯• | æµ‹è¯•ä¸åŒbatch sizeä¸‹çš„ååé‡å’Œå»¶è¿Ÿ |
| `memory_test.py` | æ˜¾å­˜å ç”¨æµ‹è¯• | æµ‹é‡æ¨¡å‹åŠ è½½å’Œæ¨ç†çš„æ˜¾å­˜éœ€æ±‚ |
| `accuracy_test.py` | å‡†ç¡®ç‡æµ‹è¯• | è¯„ä¼°CLIPæ¨¡å‹çš„å›¾æ–‡æ£€ç´¢å‡†ç¡®ç‡ |
| `visualize_results.py` | ç»“æœå¯è§†åŒ– | ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ |
| `generate_report.py` | æŠ¥å‘Šç”Ÿæˆ | è‡ªåŠ¨ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸€é”®è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
./scripts/run_benchmarks.sh
```

### 2. å•ç‹¬è¿è¡Œæµ‹è¯•

**é€Ÿåº¦æµ‹è¯•**ï¼š
```bash
python code/01-model-evaluation/benchmark/speed_test.py \
    --model openai/clip-vit-base-patch32 \
    --batch_sizes 1 2 4 \
    --image_dir data/test_dataset \
    --output results/clip_speed.json
```

**æ˜¾å­˜æµ‹è¯•**ï¼š
```bash
python code/01-model-evaluation/benchmark/memory_test.py \
    --model openai/clip-vit-base-patch32 \
    --batch_size 1
```

**å‡†ç¡®ç‡æµ‹è¯•**ï¼š
```bash
# è¿è¡ŒCLIPå›¾æ–‡æ£€ç´¢æµ‹è¯•
python code/01-model-evaluation/benchmark/accuracy_test.py \
    --model openai/clip-vit-base-patch32

# è¿è¡Œå•å…ƒæµ‹è¯•ï¼ˆéªŒè¯Recall@Kè®¡ç®—é€»è¾‘ï¼‰
python code/01-model-evaluation/benchmark/accuracy_test.py --test
```

### 3. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

```bash
# å¯è§†åŒ–é€Ÿåº¦å¯¹æ¯”
python code/01-model-evaluation/benchmark/visualize_results.py \
    --speed_files results/clip_speed.json results/sam_speed.json \
    --output_dir results

# ç”ŸæˆMarkdownæŠ¥å‘Š
python code/01-model-evaluation/benchmark/generate_report.py \
    --results_dir results \
    --output results/benchmark_report.md
```

## ğŸ“Š è¾“å‡ºç¤ºä¾‹

### é€Ÿåº¦æµ‹è¯•ç»“æœï¼ˆJSONï¼‰

```json
{
  "model": "openai/clip-vit-base-patch32",
  "device": "cuda",
  "results": [
    {
      "batch_size": 1,
      "mean_time": 0.0198,
      "throughput": 50.5,
      "latency": 19.8
    }
  ]
}
```

### æ˜¾å­˜æµ‹è¯•ç»“æœ

```
=== Memory Benchmark Results ===
model: openai/clip-vit-base-patch32
batch_size: 1
initial_memory_gb: 0.0
model_size_gb: 0.59
peak_memory_gb: 2.48
current_memory_gb: 2.45
```

### å‡†ç¡®ç‡æµ‹è¯•ç»“æœ

```
=== CLIP Retrieval Accuracy ===
i2t_recall@1: 66.67%
i2t_recall@5: 100.0%
t2i_recall@1: 66.67%
t2i_recall@5: 100.0%
```

## ğŸ”§ ä¾èµ–è¦æ±‚

```bash
pip install torch transformers pillow numpy matplotlib seaborn pandas
```

å¯é€‰ä¾èµ–ï¼š
```bash
pip install GPUtil  # ç”¨äºæ›´è¯¦ç»†çš„GPUç›‘æ§
```

## ğŸ“ æµ‹è¯•æ•°æ®å‡†å¤‡

æµ‹è¯•éœ€è¦ä¸€äº›å›¾åƒæ•°æ®ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å‡†å¤‡ï¼š

1. **æ‰‹åŠ¨å‡†å¤‡**ï¼ˆæ¨èï¼‰ï¼šå°†æµ‹è¯•å›¾åƒï¼ˆJPGæ ¼å¼ï¼‰æ”¾å…¥ `data/test_dataset/` ç›®å½•
   - è‡³å°‘å‡†å¤‡10å¼ å›¾åƒå³å¯è¿›è¡Œæµ‹è¯•
   - å›¾åƒå†…å®¹ä¸é™ï¼Œä¸éœ€è¦æ ‡æ³¨

2. **ä»ç½‘ç»œä¸‹è½½ç¤ºä¾‹å›¾åƒ**ï¼š
   ```bash
   mkdir -p data/test_dataset
   wget -P data/test_dataset/ https://images.unsplash.com/photo-1574158622682-e40e69881006 -O data/test_dataset/cat.jpg
   wget -P data/test_dataset/ https://images.unsplash.com/photo-1587300003388-59208cc962cb -O data/test_dataset/dog.jpg
   ```

3. **ä½¿ç”¨å…¬å¼€æ•°æ®é›†**ï¼ˆéœ€è¦é¢å¤–å®ç°è„šæœ¬ï¼‰ï¼š
   ```bash
   # æ­¤è„šæœ¬éœ€è¦è‡ªè¡Œå®ç°
   python scripts/prepare_test_data.py --dataset coco --num_samples 100
   ```

## ğŸ¯ ä½¿ç”¨å»ºè®®

1. **é¦–æ¬¡ä½¿ç”¨**ï¼šå»ºè®®å…ˆç”¨å°batch sizeï¼ˆ1-2ï¼‰æµ‹è¯•ï¼Œç¡®ä¿ç¯å¢ƒæ­£å¸¸
2. **æ˜¾å­˜ä¸è¶³**ï¼šå‡å°batch sizeæˆ–ä½¿ç”¨é‡åŒ–æ¨¡å‹
3. **å¯¹æ¯”æµ‹è¯•**ï¼šä¿æŒç›¸åŒçš„æµ‹è¯•æ¡ä»¶ï¼ˆç¡¬ä»¶ã€æ•°æ®ã€å‚æ•°ï¼‰
4. **ç»“æœå‚è€ƒ**ï¼šè®ºæ–‡å’Œå®é™…ç»“æœå¯èƒ½æœ‰å·®å¼‚ï¼Œå…³æ³¨ç›¸å¯¹æ€§èƒ½æ¯”

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [åŸºå‡†æµ‹è¯•å®è·µæ–‡æ¡£](../../../docs/01-æ¨¡å‹è°ƒç ”ä¸é€‰å‹/04-åŸºå‡†æµ‹è¯•å®è·µ.md)
- [ç¯å¢ƒå®‰è£…æŒ‡å—](../../../docs/05-ä½¿ç”¨è¯´æ˜/01-ç¯å¢ƒå®‰è£…æŒ‡å—.md)

---

**ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¶é—´**: 2025-11-01

