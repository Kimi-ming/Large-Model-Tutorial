# æ¨¡å‹æ¨ç†ç¤ºä¾‹

æœ¬ç›®å½•åŒ…å«ä¸»æµè§†è§‰å¤§æ¨¡å‹çš„æ¨ç†ç¤ºä¾‹ä»£ç ã€‚

## ğŸ“¦ å·²æ”¯æŒæ¨¡å‹

| æ¨¡å‹ | æ–‡ä»¶ | ä¸»è¦åŠŸèƒ½ | è¯­è¨€æ”¯æŒ |
|------|------|---------|---------|
| **CLIP** | `clip_inference.py` | å›¾æ–‡åŒ¹é…ã€é›¶æ ·æœ¬åˆ†ç±» | è‹±æ–‡ä¸ºä¸» |
| **SAM** | `sam_inference.py` | å›¾åƒåˆ†å‰² | æ— æ–‡æœ¬ |
| **BLIP-2** | `blip_inference.py` | å›¾åƒæè¿°ã€VQA | è‹±æ–‡ä¸ºä¸» |
| **LLaVA** | `llava_inference.py` | å¤šæ¨¡æ€å¯¹è¯ | è‹±æ–‡ä¸ºä¸» |
| **Qwen-VL** âœ¨ | `qwen_vl_inference.py` | ä¸­æ–‡åœºæ™¯ã€OCRã€å¤šå›¾ç†è§£ | ä¸­æ–‡ä¼˜ç§€ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

```bash
# åŸºç¡€ä¾èµ–
pip install torch transformers pillow

# SAMé¢å¤–ä¾èµ–
pip install git+https://github.com/facebookresearch/segment-anything.git

# Qwen-VLé¢å¤–ä¾èµ–
pip install transformers>=4.32.0 transformers_stream_generator
```

### åŸºç¡€ä½¿ç”¨

```bash
# CLIPæ¨ç†
python clip_inference.py --image path/to/image.jpg --texts "a cat" "a dog"

# SAMåˆ†å‰²
python sam_inference.py --image path/to/image.jpg --prompt point --x 100 --y 150

# BLIP-2æè¿°ç”Ÿæˆ
python blip_inference.py --image path/to/image.jpg --task caption

# Qwen-VLä¸­æ–‡åœºæ™¯
python qwen_vl_inference.py --image path/to/image.jpg --demo all
```

## âœ¨ æ–°å¢ï¼šQwen-VLæ”¯æŒï¼ˆv1.1.0ï¼‰

### ä¸»è¦ç‰¹æ€§

1. **ä¸­æ–‡ä¼˜ç§€** ğŸ‡¨ğŸ‡³
   - ä¸­æ–‡VQAå‡†ç¡®ç‡ï¼š85.2%
   - æ”¯æŒä¸­è‹±æ–‡æ··åˆç†è§£
   - é’ˆå¯¹ä¸­æ–‡åœºæ™¯ä¼˜åŒ–

2. **å¤šå›¾ç†è§£** ğŸ–¼ï¸
   - åŒæ—¶å¤„ç†å¤šå¼ å›¾ç‰‡
   - ç†è§£å›¾ç‰‡é—´å…³ç³»
   - è·¨å›¾æ¨ç†èƒ½åŠ›

3. **ç»†ç²’åº¦è¯†åˆ«** ğŸ”
   - OCRæ–‡å­—è¯†åˆ«ï¼ˆF1: 89.3%ï¼‰
   - ç²¾ç¡®ç‰©ä½“å®šä½
   - è¾¹ç•Œæ¡†æ ‡æ³¨

4. **é•¿æ–‡æœ¬æ”¯æŒ** ğŸ“
   - æ”¯æŒ2048 tokensä¸Šä¸‹æ–‡
   - å¤šè½®å¯¹è¯èƒ½åŠ›
   - å›¾æ–‡æ··åˆç†è§£

### ä½¿ç”¨ç¤ºä¾‹

#### 1. å›¾åƒæè¿°ç”Ÿæˆ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen-VL-Chat",
    device_map="auto",
    trust_remote_code=True
).eval()

tokenizer = AutoTokenizer.from_pretrained(
    "Qwen/Qwen-VL-Chat",
    trust_remote_code=True
)

query = tokenizer.from_list_format([
    {'image': 'image.jpg'},
    {'text': 'è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡'},
])

response, _ = model.chat(tokenizer, query=query, history=None)
print(response)
```

#### 2. è§†è§‰é—®ç­”ï¼ˆVQAï¼‰

```bash
python qwen_vl_inference.py \
    --image image.jpg \
    --demo vqa
```

#### 3. OCRæ–‡å­—è¯†åˆ«

```bash
python qwen_vl_inference.py \
    --image document.jpg \
    --demo ocr
```

#### 4. å¤šå›¾ç†è§£

```bash
python qwen_vl_inference.py \
    --images img1.jpg img2.jpg \
    --demo multi_image
```

#### 5. å¤šè½®å¯¹è¯

```bash
python qwen_vl_inference.py \
    --image image.jpg \
    --demo chat
```

### æ€§èƒ½å¯¹æ¯”

| ä»»åŠ¡ | CLIP | BLIP-2 | LLaVA | Qwen-VL |
|------|------|--------|-------|---------|
| **ä¸­æ–‡VQA** | âŒ | â­ | â­â­ | â­â­â­â­â­ |
| **è‹±æ–‡VQA** | â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **OCRè¯†åˆ«** | âŒ | â­â­ | â­â­â­ | â­â­â­â­â­ |
| **å¤šå›¾ç†è§£** | âŒ | âŒ | â­â­ | â­â­â­â­ |
| **æ¨ç†é€Ÿåº¦** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ |
| **æ˜¾å­˜å ç”¨** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­ |

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- [CLIPæ¨¡å‹è¯¦è§£](../../../docs/01-æ¨¡å‹è°ƒç ”ä¸é€‰å‹/01-ä¸»æµè§†è§‰å¤§æ¨¡å‹æ¦‚è¿°.md#1-clip)
- [SAMæ¨¡å‹è¯¦è§£](../../../docs/01-æ¨¡å‹è°ƒç ”ä¸é€‰å‹/05-SAMæ¨¡å‹è¯¦è§£.md)
- [BLIP-2æ¨¡å‹è¯¦è§£](../../../docs/01-æ¨¡å‹è°ƒç ”ä¸é€‰å‹/06-BLIP2æ¨¡å‹è¯¦è§£.md)
- [Qwen-VLæ¨¡å‹è¯¦è§£](../../../docs/01-æ¨¡å‹è°ƒç ”ä¸é€‰å‹/07-Qwen-VLæ¨¡å‹è¯¦è§£.md) âœ¨æ–°å¢

## ğŸ”§ æ•…éšœæ’æŸ¥

### Qwen-VLç›¸å…³é—®é¢˜

#### Q1: trust_remote_codeé”™è¯¯

```python
# è§£å†³æ–¹æ¡ˆï¼šå¿…é¡»è®¾ç½®trust_remote_code=True
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen-VL-Chat",
    device_map="auto",
    trust_remote_code=True  # å¿…é¡»
)
```

#### Q2: æ˜¾å­˜ä¸è¶³

```bash
# ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬
python qwen_vl_inference.py --image image.jpg --model Qwen/Qwen-VL-Chat-Int8
```

#### Q3: ä¸­æ–‡è¾“å‡ºä¹±ç 

```python
# è®¾ç½®æ­£ç¡®çš„ç¼–ç 
import sys
sys.stdout.reconfigure(encoding='utf-8')
```

### é€šç”¨é—®é¢˜

#### Q1: æ¨¡å‹ä¸‹è½½æ…¢

```bash
# æ–¹å¼1: ä½¿ç”¨HuggingFaceé•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æ–¹å¼2: ä½¿ç”¨ModelScope
pip install modelscope
python -c "from modelscope import snapshot_download; snapshot_download('qwen/Qwen-VL-Chat')"
```

#### Q2: ä¾èµ–å®‰è£…å¤±è´¥

```bash
# å‡çº§pip
pip install --upgrade pip

# ä½¿ç”¨å›½å†…é•œåƒ
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple transformers
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®æ–°çš„æ¨¡å‹æ¨ç†ç¤ºä¾‹ï¼

### æ·»åŠ æ–°æ¨¡å‹æ­¥éª¤

1. åˆ›å»ºæ¨ç†è„šæœ¬ `{model_name}_inference.py`
2. å‚è€ƒç°æœ‰è„šæœ¬çš„ä»£ç ç»“æ„
3. æ·»åŠ è¯¦ç»†çš„æ³¨é‡Šå’Œä½¿ç”¨è¯´æ˜
4. æ›´æ–°æœ¬READMEæ–‡æ¡£
5. æäº¤Pull Request

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ç±»å‹æ³¨è§£
- æ·»åŠ è¯¦ç»†çš„docstring
- åŒ…å«é”™è¯¯å¤„ç†
- æä¾›å‘½ä»¤è¡Œæ¥å£
- æ”¯æŒå¤šç§ä½¿ç”¨åœºæ™¯

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.1.0 (2025-11-06)
- âœ¨ æ–°å¢Qwen-VLæ¨¡å‹æ”¯æŒ
- âœ¨ æ·»åŠ ä¸­æ–‡åœºæ™¯ç¤ºä¾‹
- âœ¨ æ”¯æŒå¤šå›¾ç†è§£
- âœ¨ OCRæ–‡å­—è¯†åˆ«åŠŸèƒ½
- ğŸ“š æ–°å¢Qwen-VLè¯¦ç»†æ–‡æ¡£

### v1.0.0 (2025-11-05)
- âœ¨ åˆå§‹ç‰ˆæœ¬
- âœ¨ æ”¯æŒCLIPã€SAMã€BLIP-2ã€LLaVA
- ğŸ“š å®Œæ•´çš„ä½¿ç”¨æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](../../../LICENSE)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.1.0  
**æœ€åæ›´æ–°**: 2025-11-06  
**ç»´æŠ¤è€…**: Large-Model-Tutorial Team

