"""
SAM (Segment Anything Model) æ¨ç†ç¤ºä¾‹

æœ¬è„šæœ¬å±•ç¤ºSAMæ¨¡å‹çš„å„ç§ä½¿ç”¨æ–¹å¼ï¼š
1. ç‚¹æç¤ºåˆ†å‰²
2. æ¡†æç¤ºåˆ†å‰²
3. æ©ç æç¤ºåˆ†å‰²
4. è‡ªåŠ¨åˆ†å‰²ï¼ˆæ•´å›¾ï¼‰
5. ä¸CLIPç»“åˆçš„è¯­ä¹‰åˆ†å‰²

ä½œè€…ï¼šLarge-Model-Tutorial
è®¸å¯ï¼šMIT
"""

import argparse
import os
import sys
import time
from pathlib import Path
from typing import List, Tuple, Optional

import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
from PIL import Image

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))


def check_sam_installation():
    """æ£€æŸ¥SAMæ˜¯å¦å·²å®‰è£…"""
    try:
        import segment_anything
        print("âœ… segment_anything å·²å®‰è£…")
        return True
    except ImportError:
        print("âŒ segment_anything æœªå®‰è£…")
        print("\nå®‰è£…æ–¹æ³•ï¼š")
        print("  pip install git+https://github.com/facebookresearch/segment-anything.git")
        print("æˆ–è€…:")
        print("  pip install segment-anything")
        return False


def download_checkpoint(model_type: str = "vit_b") -> str:
    """
    ä¸‹è½½SAMæ£€æŸ¥ç‚¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    
    Args:
        model_type: æ¨¡å‹ç±»å‹ï¼Œå¯é€‰ 'vit_b', 'vit_l', 'vit_h'
    
    Returns:
        æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
    """
    checkpoint_urls = {
        "vit_b": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth",
        "vit_l": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth",
        "vit_h": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
    }
    
    checkpoint_dir = project_root / "models" / "sam"
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    filename = f"sam_{model_type}_01ec64.pth"
    checkpoint_path = checkpoint_dir / filename
    
    if checkpoint_path.exists():
        print(f"âœ… æ£€æŸ¥ç‚¹å·²å­˜åœ¨: {checkpoint_path}")
        return str(checkpoint_path)
    
    print(f"ğŸ“¥ ä¸‹è½½SAMæ£€æŸ¥ç‚¹: {model_type}")
    print(f"   URL: {checkpoint_urls[model_type]}")
    print(f"   ä¿å­˜åˆ°: {checkpoint_path}")
    print("\nâ³ ä¸‹è½½ä¸­... (çº¦375MB-2.4GBï¼Œå–å†³äºæ¨¡å‹å¤§å°)")
    
    try:
        import urllib.request
        urllib.request.urlretrieve(
            checkpoint_urls[model_type],
            checkpoint_path,
        )
        print("âœ… ä¸‹è½½å®Œæˆï¼")
        return str(checkpoint_path)
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        print("\næ‰‹åŠ¨ä¸‹è½½æ–¹æ³•ï¼š")
        print(f"1. è®¿é—®: {checkpoint_urls[model_type]}")
        print(f"2. ä¸‹è½½æ–‡ä»¶å¹¶ä¿å­˜åˆ°: {checkpoint_path}")
        sys.exit(1)


class SAMInference:
    """SAMæ¨ç†åŒ…è£…ç±»"""
    
    def __init__(
        self,
        model_type: str = "vit_b",
        checkpoint_path: Optional[str] = None,
        device: str = "cuda"
    ):
        """
        åˆå§‹åŒ–SAMæ¨¡å‹
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('vit_b', 'vit_l', 'vit_h')
            checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
            device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
        """
        from segment_anything import sam_model_registry, SamPredictor
        
        self.device = device if torch.cuda.is_available() and device == "cuda" else "cpu"
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        if checkpoint_path is None:
            checkpoint_path = download_checkpoint(model_type)
        
        print(f"åŠ è½½SAMæ¨¡å‹: {model_type}")
        sam = sam_model_registry[model_type](checkpoint=checkpoint_path)
        sam.to(device=self.device)
        
        self.predictor = SamPredictor(sam)
        self.model_type = model_type
        print("âœ… SAMæ¨¡å‹åŠ è½½å®Œæˆ")
    
    def set_image(self, image: np.ndarray):
        """
        è®¾ç½®è¦åˆ†å‰²çš„å›¾åƒ
        
        Args:
            image: RGBå›¾åƒæ•°ç»„ (H, W, 3)
        """
        self.predictor.set_image(image)
        self.current_image = image
    
    def predict_with_points(
        self,
        points: np.ndarray,
        labels: np.ndarray,
        multimask_output: bool = True
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨ç‚¹æç¤ºè¿›è¡Œåˆ†å‰²
        
        Args:
            points: ç‚¹åæ ‡æ•°ç»„ (N, 2), æ ¼å¼ [[x1, y1], [x2, y2], ...]
            labels: ç‚¹æ ‡ç­¾æ•°ç»„ (N,), 1=å‰æ™¯, 0=èƒŒæ™¯
            multimask_output: æ˜¯å¦è¾“å‡ºå¤šä¸ªå€™é€‰æ©ç 
        
        Returns:
            masks: æ©ç æ•°ç»„ (N, H, W)
            scores: IoUåˆ†æ•° (N,)
            logits: ä½åˆ†è¾¨ç‡logits (N, 256, 256)
        """
        masks, scores, logits = self.predictor.predict(
            point_coords=points,
            point_labels=labels,
            multimask_output=multimask_output,
        )
        return masks, scores, logits
    
    def predict_with_box(
        self,
        box: np.ndarray,
        multimask_output: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨æ¡†æç¤ºè¿›è¡Œåˆ†å‰²
        
        Args:
            box: è¾¹ç•Œæ¡† [x_min, y_min, x_max, y_max]
            multimask_output: æ˜¯å¦è¾“å‡ºå¤šä¸ªå€™é€‰æ©ç 
        
        Returns:
            masks, scores, logits
        """
        masks, scores, logits = self.predictor.predict(
            point_coords=None,
            point_labels=None,
            box=box[None, :],
            multimask_output=multimask_output,
        )
        return masks, scores, logits
    
    def predict_with_box_and_points(
        self,
        box: np.ndarray,
        points: np.ndarray,
        labels: np.ndarray,
        multimask_output: bool = False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨æ¡†+ç‚¹æç¤ºè¿›è¡Œåˆ†å‰²
        
        Args:
            box: è¾¹ç•Œæ¡†
            points: ç‚¹åæ ‡
            labels: ç‚¹æ ‡ç­¾
            multimask_output: æ˜¯å¦è¾“å‡ºå¤šä¸ªå€™é€‰æ©ç 
        
        Returns:
            masks, scores, logits
        """
        masks, scores, logits = self.predictor.predict(
            point_coords=points,
            point_labels=labels,
            box=box[None, :],
            multimask_output=multimask_output,
        )
        return masks, scores, logits
    
    def automatic_mask_generation(
        self,
        image: np.ndarray,
        points_per_side: int = 32,
        pred_iou_thresh: float = 0.86,
        stability_score_thresh: float = 0.92,
        min_mask_region_area: int = 100,
    ) -> List[dict]:
        """
        è‡ªåŠ¨åˆ†å‰²æ•´å¼ å›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            points_per_side: æ¯è¾¹é‡‡æ ·ç‚¹æ•°
            pred_iou_thresh: IoUé˜ˆå€¼
            stability_score_thresh: ç¨³å®šæ€§é˜ˆå€¼
            min_mask_region_area: æœ€å°æ©ç åŒºåŸŸï¼ˆåƒç´ ï¼‰
        
        Returns:
            æ©ç åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸åŒ…å«:
                - segmentation: äºŒå€¼æ©ç 
                - area: æ©ç é¢ç§¯
                - bbox: è¾¹ç•Œæ¡†
                - predicted_iou: é¢„æµ‹çš„IoU
                - stability_score: ç¨³å®šæ€§åˆ†æ•°
        """
        from segment_anything import SamAutomaticMaskGenerator
        
        mask_generator = SamAutomaticMaskGenerator(
            model=self.predictor.model,
            points_per_side=points_per_side,
            pred_iou_thresh=pred_iou_thresh,
            stability_score_thresh=stability_score_thresh,
            crop_n_layers=1,
            crop_n_points_downscale_factor=2,
            min_mask_region_area=min_mask_region_area,
        )
        
        print("ğŸ” æ‰§è¡Œè‡ªåŠ¨åˆ†å‰²...")
        start_time = time.time()
        masks = mask_generator.generate(image)
        elapsed = time.time() - start_time
        print(f"âœ… åˆ†å‰²å®Œæˆï¼æ‰¾åˆ° {len(masks)} ä¸ªæ©ç ï¼Œè€—æ—¶ {elapsed:.2f}ç§’")
        
        return masks


def visualize_point_prompts(
    image: np.ndarray,
    masks: np.ndarray,
    scores: np.ndarray,
    points: np.ndarray,
    labels: np.ndarray,
    output_path: str
):
    """å¯è§†åŒ–ç‚¹æç¤ºåˆ†å‰²ç»“æœ"""
    n_masks = masks.shape[0]
    fig, axes = plt.subplots(1, n_masks + 1, figsize=(5 * (n_masks + 1), 5))
    
    if n_masks == 1:
        axes = [axes] if not isinstance(axes, np.ndarray) else axes
    
    # æ˜¾ç¤ºåŸå›¾+æç¤ºç‚¹
    axes[0].imshow(image)
    for i, (point, label) in enumerate(zip(points, labels)):
        color = 'green' if label == 1 else 'red'
        marker = 'o' if label == 1 else 'x'
        axes[0].plot(point[0], point[1], marker, markersize=15, color=color, markeredgewidth=3)
    axes[0].set_title("åŸå›¾ + æç¤ºç‚¹\nç»¿è‰²=å‰æ™¯, çº¢è‰²=èƒŒæ™¯")
    axes[0].axis('off')
    
    # æ˜¾ç¤ºæ¯ä¸ªæ©ç 
    for i, (mask, score) in enumerate(zip(masks, scores)):
        axes[i + 1].imshow(image)
        axes[i + 1].imshow(mask, alpha=0.5, cmap='jet')
        axes[i + 1].set_title(f"æ©ç  {i+1}\nIoUåˆ†æ•°: {score:.3f}")
        axes[i + 1].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ä¿å­˜å¯è§†åŒ–ç»“æœ: {output_path}")
    plt.close()


def visualize_box_prompt(
    image: np.ndarray,
    mask: np.ndarray,
    box: np.ndarray,
    score: float,
    output_path: str
):
    """å¯è§†åŒ–æ¡†æç¤ºåˆ†å‰²ç»“æœ"""
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    
    # æ˜¾ç¤ºåŸå›¾+æ¡†
    axes[0].imshow(image)
    x_min, y_min, x_max, y_max = box
    rect = plt.Rectangle(
        (x_min, y_min), x_max - x_min, y_max - y_min,
        fill=False, edgecolor='red', linewidth=3
    )
    axes[0].add_patch(rect)
    axes[0].set_title("åŸå›¾ + æ¡†æç¤º")
    axes[0].axis('off')
    
    # æ˜¾ç¤ºåˆ†å‰²ç»“æœ
    axes[1].imshow(image)
    axes[1].imshow(mask, alpha=0.5, cmap='jet')
    axes[1].set_title(f"åˆ†å‰²ç»“æœ\nIoUåˆ†æ•°: {score:.3f}")
    axes[1].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ä¿å­˜å¯è§†åŒ–ç»“æœ: {output_path}")
    plt.close()


def visualize_automatic_masks(
    image: np.ndarray,
    masks: List[dict],
    output_path: str,
    max_display: int = 20
):
    """å¯è§†åŒ–è‡ªåŠ¨åˆ†å‰²ç»“æœ"""
    # æŒ‰é¢ç§¯æ’åºï¼Œæ˜¾ç¤ºæœ€å¤§çš„å‡ ä¸ª
    sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)
    sorted_masks = sorted_masks[:max_display]
    
    # åˆ›å»ºåˆæˆçš„åˆ†å‰²å›¾
    segmentation = np.zeros(image.shape[:2], dtype=np.uint8)
    for i, mask_dict in enumerate(sorted_masks):
        mask = mask_dict['segmentation']
        segmentation[mask] = (i + 1)
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))
    
    # åŸå›¾
    axes[0].imshow(image)
    axes[0].set_title(f"åŸå›¾")
    axes[0].axis('off')
    
    # åˆ†å‰²ç»“æœ
    axes[1].imshow(image)
    axes[1].imshow(segmentation, alpha=0.6, cmap='tab20')
    axes[1].set_title(f"è‡ªåŠ¨åˆ†å‰²ç»“æœ\nå…± {len(masks)} ä¸ªæ©ç ï¼ˆæ˜¾ç¤ºå‰{min(max_display, len(masks))}ä¸ªï¼‰")
    axes[1].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ä¿å­˜å¯è§†åŒ–ç»“æœ: {output_path}")
    plt.close()


def example_point_prompts(sam: SAMInference, image_path: str, output_dir: str):
    """ç¤ºä¾‹1ï¼šç‚¹æç¤ºåˆ†å‰²"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1ï¼šç‚¹æç¤ºåˆ†å‰²")
    print("="*60)
    
    # åŠ è½½å›¾åƒ
    image = np.array(Image.open(image_path).convert("RGB"))
    sam.set_image(image)
    
    h, w = image.shape[:2]
    
    # åœºæ™¯1ï¼šå•ä¸ªå‰æ™¯ç‚¹
    print("\nåœºæ™¯1ï¼šå•ä¸ªå‰æ™¯ç‚¹ï¼ˆç‚¹å‡»å›¾åƒä¸­å¿ƒï¼‰")
    input_point = np.array([[w // 2, h // 2]])
    input_label = np.array([1])
    
    masks, scores, logits = sam.predict_with_points(
        input_point, input_label, multimask_output=True
    )
    
    visualize_point_prompts(
        image, masks, scores, input_point, input_label,
        os.path.join(output_dir, "01_single_point.png")
    )
    
    # åœºæ™¯2ï¼šå¤šä¸ªå‰æ™¯ç‚¹
    print("\nåœºæ™¯2ï¼šå¤šä¸ªå‰æ™¯ç‚¹")
    input_points = np.array([
        [w // 3, h // 3],
        [w // 2, h // 2],
        [2 * w // 3, 2 * h // 3],
    ])
    input_labels = np.array([1, 1, 1])
    
    masks, scores, logits = sam.predict_with_points(
        input_points, input_labels, multimask_output=False
    )
    
    visualize_point_prompts(
        image, masks, scores, input_points, input_labels,
        os.path.join(output_dir, "02_multiple_points.png")
    )
    
    # åœºæ™¯3ï¼šå‰æ™¯+èƒŒæ™¯ç‚¹
    print("\nåœºæ™¯3ï¼šå‰æ™¯ç‚¹+èƒŒæ™¯ç‚¹ï¼ˆç²¾ç»†åŒ–åˆ†å‰²ï¼‰")
    input_points = np.array([
        [w // 2, h // 2],      # å‰æ™¯
        [w // 10, h // 10],    # èƒŒæ™¯
        [9 * w // 10, 9 * h // 10],  # èƒŒæ™¯
    ])
    input_labels = np.array([1, 0, 0])
    
    masks, scores, logits = sam.predict_with_points(
        input_points, input_labels, multimask_output=False
    )
    
    visualize_point_prompts(
        image, masks, scores, input_points, input_labels,
        os.path.join(output_dir, "03_foreground_background_points.png")
    )


def example_box_prompt(sam: SAMInference, image_path: str, output_dir: str):
    """ç¤ºä¾‹2ï¼šæ¡†æç¤ºåˆ†å‰²"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2ï¼šæ¡†æç¤ºåˆ†å‰²")
    print("="*60)
    
    # åŠ è½½å›¾åƒ
    image = np.array(Image.open(image_path).convert("RGB"))
    sam.set_image(image)
    
    h, w = image.shape[:2]
    
    # å®šä¹‰ä¸€ä¸ªæ¡†ï¼ˆä¸­å¿ƒåŒºåŸŸï¼‰
    margin = 0.2
    input_box = np.array([
        int(w * margin),
        int(h * margin),
        int(w * (1 - margin)),
        int(h * (1 - margin))
    ])
    
    print(f"æ¡†åæ ‡: {input_box}")
    
    masks, scores, logits = sam.predict_with_box(input_box, multimask_output=False)
    
    visualize_box_prompt(
        image, masks[0], input_box, scores[0],
        os.path.join(output_dir, "04_box_prompt.png")
    )


def example_automatic_segmentation(sam: SAMInference, image_path: str, output_dir: str):
    """ç¤ºä¾‹3ï¼šè‡ªåŠ¨åˆ†å‰²æ•´å›¾"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3ï¼šè‡ªåŠ¨åˆ†å‰²æ•´å›¾")
    print("="*60)
    
    # åŠ è½½å›¾åƒ
    image = np.array(Image.open(image_path).convert("RGB"))
    
    # è‡ªåŠ¨åˆ†å‰²
    masks = sam.automatic_mask_generation(
        image,
        points_per_side=16,  # å‡å°‘é‡‡æ ·ç‚¹ä»¥åŠ å¿«é€Ÿåº¦ï¼ˆæ¼”ç¤ºç”¨ï¼‰
        pred_iou_thresh=0.86,
        stability_score_thresh=0.92,
        min_mask_region_area=100,
    )
    
    # æ‰“å°å‰5ä¸ªæ©ç çš„ä¿¡æ¯
    print("\nå‰5ä¸ªæ©ç ä¿¡æ¯ï¼š")
    for i, mask_dict in enumerate(masks[:5]):
        print(f"  æ©ç  {i+1}:")
        print(f"    é¢ç§¯: {mask_dict['area']} åƒç´ ")
        print(f"    è¾¹ç•Œæ¡†: {mask_dict['bbox']}")
        print(f"    é¢„æµ‹IoU: {mask_dict['predicted_iou']:.3f}")
        print(f"    ç¨³å®šæ€§åˆ†æ•°: {mask_dict['stability_score']:.3f}")
    
    visualize_automatic_masks(
        image, masks,
        os.path.join(output_dir, "05_automatic_segmentation.png")
    )


def example_iterative_refinement(sam: SAMInference, image_path: str, output_dir: str):
    """ç¤ºä¾‹4ï¼šè¿­ä»£ç²¾ç»†åŒ–"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4ï¼šè¿­ä»£ç²¾ç»†åŒ–ï¼ˆä½¿ç”¨æ©ç æç¤ºï¼‰")
    print("="*60)
    
    # åŠ è½½å›¾åƒ
    image = np.array(Image.open(image_path).convert("RGB"))
    sam.set_image(image)
    
    h, w = image.shape[:2]
    
    # ç¬¬ä¸€æ¬¡åˆ†å‰²ï¼šç²—ç•¥çš„ç‚¹
    print("ç¬¬ä¸€æ¬¡åˆ†å‰²ï¼šä½¿ç”¨å•ç‚¹æç¤º")
    point1 = np.array([[w // 2, h // 2]])
    label1 = np.array([1])
    
    masks1, scores1, logits1 = sam.predict_with_points(
        point1, label1, multimask_output=True
    )
    
    # é€‰æ‹©æœ€ä½³æ©ç 
    best_idx = np.argmax(scores1)
    
    # ç¬¬äºŒæ¬¡åˆ†å‰²ï¼šä½¿ç”¨å‰ä¸€æ¬¡çš„logitsä½œä¸ºæ©ç æç¤ºï¼Œæ·»åŠ æ–°çš„ç‚¹
    print("ç¬¬äºŒæ¬¡åˆ†å‰²ï¼šä½¿ç”¨æ©ç æç¤º+æ–°çš„ç‚¹æç¤ºè¿›è¡Œç²¾ç»†åŒ–")
    point2 = np.array([[w // 3, h // 3]])  # æ–°çš„ç‚¹
    label2 = np.array([1])
    
    masks2, scores2, logits2 = sam.predictor.predict(
        point_coords=point2,
        point_labels=label2,
        mask_input=logits1[best_idx:best_idx+1, :, :],  # ä½¿ç”¨ä¸Šæ¬¡çš„logits
        multimask_output=False,
    )
    
    # å¯è§†åŒ–å¯¹æ¯”
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    axes[0].imshow(image)
    axes[0].plot(point1[0, 0], point1[0, 1], 'go', markersize=15, markeredgewidth=3)
    axes[0].set_title("åŸå›¾ + ç¬¬1æ¬¡æç¤ºç‚¹")
    axes[0].axis('off')
    
    axes[1].imshow(image)
    axes[1].imshow(masks1[best_idx], alpha=0.5, cmap='jet')
    axes[1].set_title(f"ç¬¬1æ¬¡åˆ†å‰²ç»“æœ\nIoU: {scores1[best_idx]:.3f}")
    axes[1].axis('off')
    
    axes[2].imshow(image)
    axes[2].imshow(masks2[0], alpha=0.5, cmap='jet')
    axes[2].plot(point2[0, 0], point2[0, 1], 'go', markersize=15, markeredgewidth=3)
    axes[2].set_title(f"ç¬¬2æ¬¡ç²¾ç»†åŒ–ç»“æœ\nIoU: {scores2[0]:.3f}")
    axes[2].axis('off')
    
    plt.tight_layout()
    output_path = os.path.join(output_dir, "06_iterative_refinement.png")
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ä¿å­˜å¯è§†åŒ–ç»“æœ: {output_path}")
    plt.close()


def main():
    parser = argparse.ArgumentParser(description="SAMæ¨ç†ç¤ºä¾‹")
    parser.add_argument(
        "--image", type=str, required=True,
        help="è¾“å…¥å›¾åƒè·¯å¾„"
    )
    parser.add_argument(
        "--model_type", type=str, default="vit_b",
        choices=["vit_b", "vit_l", "vit_h"],
        help="SAMæ¨¡å‹ç±»å‹ (é»˜è®¤: vit_b)"
    )
    parser.add_argument(
        "--checkpoint", type=str, default=None,
        help="SAMæ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚ä¸æä¾›å°†è‡ªåŠ¨ä¸‹è½½ï¼‰"
    )
    parser.add_argument(
        "--output_dir", type=str, default="outputs/sam_inference",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--device", type=str, default="cuda",
        choices=["cuda", "cpu"],
        help="è®¾å¤‡ (é»˜è®¤: cuda)"
    )
    parser.add_argument(
        "--examples", type=str, nargs='+',
        default=["points", "box", "automatic", "iterative"],
        choices=["points", "box", "automatic", "iterative"],
        help="è¦è¿è¡Œçš„ç¤ºä¾‹ï¼ˆé»˜è®¤: å…¨éƒ¨ï¼‰"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥SAMæ˜¯å¦å®‰è£…
    if not check_sam_installation():
        sys.exit(1)
    
    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.image):
        print(f"âŒ å›¾åƒä¸å­˜åœ¨: {args.image}")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # åˆå§‹åŒ–SAM
    print("\n" + "="*60)
    print("åˆå§‹åŒ–SAMæ¨¡å‹")
    print("="*60)
    
    sam = SAMInference(
        model_type=args.model_type,
        checkpoint_path=args.checkpoint,
        device=args.device
    )
    
    # è¿è¡Œç¤ºä¾‹
    if "points" in args.examples:
        example_point_prompts(sam, args.image, args.output_dir)
    
    if "box" in args.examples:
        example_box_prompt(sam, args.image, args.output_dir)
    
    if "automatic" in args.examples:
        example_automatic_segmentation(sam, args.image, args.output_dir)
    
    if "iterative" in args.examples:
        example_iterative_refinement(sam, args.image, args.output_dir)
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    print("="*60)


if __name__ == "__main__":
    main()

