# åä¸ºæ˜‡è…¾éƒ¨ç½²ä»£ç 

æœ¬ç›®å½•åŒ…å«åä¸ºæ˜‡è…¾NPUéƒ¨ç½²çš„å®Œæ•´ä»£ç å’Œå·¥å…·ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
huawei/
â”œâ”€â”€ pytorch_npu_inference.py  # PyTorch-NPUæ¨ç†æœåŠ¡
â”œâ”€â”€ convert_to_om.py           # æ¨¡å‹è½¬æ¢å·¥å…·ï¼ˆONNXâ†’OMï¼‰
â”œâ”€â”€ benchmark.py               # æ€§èƒ½æµ‹è¯•å·¥å…·
â”œâ”€â”€ deploy.sh                  # è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
â””â”€â”€ README.md                  # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- æ˜‡è…¾AIå¤„ç†å™¨ï¼ˆAtlas 300/500/800ç­‰ï¼‰
- CANNå·¥å…·é“¾ â‰¥ 5.1.RC2
- Python â‰¥ 3.7
- PyTorchï¼ˆæ˜‡è…¾é€‚é…ç‰ˆï¼‰

### å®‰è£…ä¾èµ–

```bash
# 1. å®‰è£…CANNï¼ˆå‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼‰
# https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/softwareinstall

# 2. é…ç½®æ˜‡è…¾PyTorchæº
pip config set global.index-url https://repo.huaweicloud.com/repository/pypi/simple

# 3. å®‰è£…PyTorchå’Œtorch-npu
pip install torch==1.11.0
pip install torch-npu==1.11.0 -i https://repo.huaweicloud.com/repository/pypi/simple

# 4. å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers pillow numpy
```

## ğŸ“– ä½¿ç”¨æŒ‡å—

### 1. PyTorch-NPUæ¨ç†

ç›´æ¥ä½¿ç”¨PyTorchæ¨¡å‹åœ¨NPUä¸Šæ¨ç†ï¼š

```bash
# å•æ¬¡æ¨ç†
python pytorch_npu_inference.py \
    --model openai/clip-vit-base-patch32 \
    --image test.jpg \
    --texts "a cat" "a dog" "a bird" \
    --device auto \
    --fp16

# æ€§èƒ½æµ‹è¯•
python pytorch_npu_inference.py \
    --model openai/clip-vit-base-patch32 \
    --image test.jpg \
    --texts "a cat" "a dog" \
    --device npu \
    --fp16 \
    --benchmark
```

**è®¾å¤‡é€‰æ‹©**ï¼š
- `auto`: è‡ªåŠ¨é€‰æ‹©ï¼ˆNPU > CUDA > CPUï¼‰
- `npu`: å¼ºåˆ¶ä½¿ç”¨NPU
- `cuda`: ä½¿ç”¨CUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰
- `cpu`: ä½¿ç”¨CPU

### 2. æ¨¡å‹è½¬æ¢ï¼ˆONNXâ†’OMï¼‰

å°†æ¨¡å‹è½¬æ¢ä¸ºæ˜‡è…¾ä¼˜åŒ–çš„OMæ ¼å¼ä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼š

#### è½¬æ¢CLIPæ¨¡å‹

```bash
python convert_to_om.py clip \
    --model openai/clip-vit-base-patch32 \
    --output-dir ./models/clip_om \
    --batch-size 1 \
    --soc-version Ascend910
```

#### è½¬æ¢è‡ªå®šä¹‰ONNXæ¨¡å‹

```bash
python convert_to_om.py onnx \
    --model model.onnx \
    --output model_om \
    --input-shape "input1:1,3,224,224;input2:1,512" \
    --soc-version Ascend910
```

**åŠ¨æ€batchæ”¯æŒ**ï¼š

```bash
python convert_to_om.py clip \
    --model openai/clip-vit-base-patch32 \
    --output-dir ./models/clip_om \
    --dynamic-batch \
    --soc-version Ascend910

# å°†æ”¯æŒbatch size: 1, 2, 4, 8
```

### 3. æ€§èƒ½æµ‹è¯•

å¯¹æ¯”NPUã€CUDAã€CPUçš„æ¨ç†æ€§èƒ½ï¼š

```bash
python benchmark.py \
    --model openai/clip-vit-base-patch32 \
    --image test.jpg \
    --texts "a cat" "a dog" "a bird" \
    --num-runs 100 \
    --output benchmark_results.json
```

**åªæµ‹è¯•ç‰¹å®šè®¾å¤‡**ï¼š

```bash
python benchmark.py \
    --image test.jpg \
    --devices npu cuda \
    --num-runs 100
```

### 4. è‡ªåŠ¨åŒ–éƒ¨ç½²

ä½¿ç”¨éƒ¨ç½²è„šæœ¬ä¸€é”®éƒ¨ç½²ï¼š

```bash
bash deploy.sh \
    --model openai/clip-vit-base-patch32 \
    --output-dir /opt/models/clip \
    --soc-version Ascend910
```

## ğŸ’¡ ä»£ç ç¤ºä¾‹

### Python APIä½¿ç”¨

```python
from pytorch_npu_inference import CLIPInferenceService

# åˆå§‹åŒ–æœåŠ¡
service = CLIPInferenceService(
    model_path="openai/clip-vit-base-patch32",
    device="auto",  # è‡ªåŠ¨é€‰æ‹©NPU
    use_fp16=True
)

# å•å¼ å›¾åƒæ¨ç†
result = service.predict(
    image="test.jpg",
    texts=["a cat", "a dog", "a bird"]
)

print(f"æœ€ä½³åŒ¹é…: {result['best_match']}")
print(f"ç½®ä¿¡åº¦: {result['best_score']:.4f}")
print(f"è®¾å¤‡: {result['device']}")
print(f"å»¶è¿Ÿ: {result['inference_time_ms']:.2f}ms")

# æ‰¹é‡æ¨ç†
results = service.batch_predict(
    images=["img1.jpg", "img2.jpg", "img3.jpg"],
    texts=["a cat", "a dog"],
    batch_size=4
)

# æ€§èƒ½æµ‹è¯•
stats = service.benchmark(
    image="test.jpg",
    texts=["a cat", "a dog"],
    num_runs=100
)

print(f"å¹³å‡å»¶è¿Ÿ: {stats['mean_ms']:.2f}ms")
print(f"ååé‡: {stats['throughput_per_sec']:.2f} images/sec")
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: torch_npuå¯¼å…¥å¤±è´¥

**é”™è¯¯**ï¼š`ModuleNotFoundError: No module named 'torch_npu'`

**è§£å†³**ï¼š
```bash
# ç¡®ä¿ä»æ˜‡è…¾æºå®‰è£…
pip uninstall torch-npu -y
pip install torch-npu==1.11.0 -i https://repo.huaweicloud.com/repository/pypi/simple
```

### Q2: NPUä¸å¯ç”¨

**é”™è¯¯**ï¼š`torch.npu.is_available()` è¿”å› `False`

**æ’æŸ¥**ï¼š
```bash
# 1. æ£€æŸ¥NPUè®¾å¤‡
npu-smi info

# 2. æ£€æŸ¥CANNç¯å¢ƒ
source /usr/local/Ascend/ascend-toolkit/set_env.sh

# 3. éªŒè¯torch-npu
python -c "import torch; import torch_npu; print(torch.npu.is_available())"
```

### Q3: ATCè½¬æ¢å¤±è´¥

**é”™è¯¯**ï¼š`atc: command not found`

**è§£å†³**ï¼š
```bash
# è®¾ç½®CANNç¯å¢ƒå˜é‡
source /usr/local/Ascend/ascend-toolkit/set_env.sh

# éªŒè¯ATC
atc --help
```

### Q4: æ€§èƒ½ä¸å¦‚é¢„æœŸ

**ä¼˜åŒ–å»ºè®®**ï¼š

1. **ä½¿ç”¨FP16**ï¼š
   ```python
   service = CLIPInferenceService(use_fp16=True)
   ```

2. **è½¬æ¢ä¸ºOMæ ¼å¼**ï¼š
   ```bash
   python convert_to_om.py clip --model your_model --output-dir ./om
   ```

3. **ä½¿ç”¨æ‰¹é‡æ¨ç†**ï¼š
   ```python
   results = service.batch_predict(images, texts, batch_size=8)
   ```

4. **æ£€æŸ¥NPUåˆ©ç”¨ç‡**ï¼š
   ```bash
   npu-smi info -l
   ```

## ğŸ“Š æ€§èƒ½å‚è€ƒ

æµ‹è¯•ç¯å¢ƒï¼šAtlas 800 (Ascend 910)ï¼ŒCANN 6.0.1

| æ¨¡å‹ | è®¾å¤‡ | ç²¾åº¦ | å»¶è¿Ÿ | ååé‡ |
|------|------|------|------|--------|
| CLIP ViT-B/32 | NPU | FP32 | 4.5ms | 222 img/s |
| CLIP ViT-B/32 | NPU | FP16 | 3.0ms | 333 img/s |
| CLIP ViT-B/32 | OM | FP16 | 2.5ms | 400 img/s |

> å®é™…æ€§èƒ½å–å†³äºç¡¬ä»¶é…ç½®å’Œworkload

## ğŸ”— ç›¸å…³èµ„æº

- [æ˜‡è…¾éƒ¨ç½²æ–‡æ¡£](../../../docs/04-å¤šå¹³å°éƒ¨ç½²/03-åä¸ºæ˜‡è…¾éƒ¨ç½².md)
- [å¤šå¹³å°å¯¹æ¯”](../../../docs/04-å¤šå¹³å°éƒ¨ç½²/04-å¤šå¹³å°å¯¹æ¯”.md)
- [æ˜‡è…¾ç¤¾åŒº](https://www.hiascend.com/)
- [CANNæ–‡æ¡£](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition)

## ğŸ“ è®¸å¯

MIT License

