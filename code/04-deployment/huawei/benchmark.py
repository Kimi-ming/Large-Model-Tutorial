"""
åä¸ºæ˜‡è…¾æ€§èƒ½æµ‹è¯•å·¥å…·

å¯¹æ¯”NPUã€CUDAã€CPUçš„æ¨ç†æ€§èƒ½
"""

import time
import argparse
import json
from pathlib import Path
from typing import Dict, List
import numpy as np

try:
    import torch
    import torch_npu
    from transformers import CLIPModel, CLIPProcessor
    from PIL import Image
except ImportError as e:
    print(f"Error: {e}")
    print("Please install required packages:")
    print("pip install torch transformers pillow")
    exit(1)


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def __init__(self, model_path: str = "openai/clip-vit-base-patch32"):
        """
        åˆå§‹åŒ–åŸºå‡†æµ‹è¯•
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
        """
        self.model_path = model_path
        self.results = {}
    
    def benchmark_device(
        self,
        device: str,
        image_path: str,
        texts: List[str],
        num_runs: int = 100,
        warmup_runs: int = 10,
        use_fp16: bool = False
    ) -> Dict:
        """
        åœ¨æŒ‡å®šè®¾å¤‡ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•
        
        Args:
            device: è®¾å¤‡åç§° ('npu', 'cuda', 'cpu')
            image_path: æµ‹è¯•å›¾åƒè·¯å¾„
            texts: æµ‹è¯•æ–‡æœ¬åˆ—è¡¨
            num_runs: è¿è¡Œæ¬¡æ•°
            warmup_runs: é¢„çƒ­æ¬¡æ•°
            use_fp16: æ˜¯å¦ä½¿ç”¨FP16
            
        Returns:
            æ€§èƒ½ç»Ÿè®¡å­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•è®¾å¤‡: {device.upper()}")
        print(f"FP16: {use_fp16}")
        print(f"{'='*60}")
        
        # æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§
        if device == 'npu':
            if not torch.npu.is_available():
                print(f"âš ï¸  NPUä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
                return None
            device_obj = torch.device('npu:0')
        elif device == 'cuda':
            if not torch.cuda.is_available():
                print(f"âš ï¸  CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
                return None
            device_obj = torch.device('cuda:0')
        else:
            device_obj = torch.device('cpu')
        
        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¥ åŠ è½½æ¨¡å‹...")
        model = CLIPModel.from_pretrained(self.model_path)
        processor = CLIPProcessor.from_pretrained(self.model_path)
        
        model = model.to(device_obj)
        
        if use_fp16 and device in ['npu', 'cuda']:
            model = model.half()
        
        model.eval()
        
        # å‡†å¤‡è¾“å…¥
        image = Image.open(image_path).convert('RGB')
        inputs = processor(text=texts, images=image, return_tensors="pt", padding=True)
        inputs = {k: v.to(device_obj) for k, v in inputs.items()}
        
        if use_fp16 and device in ['npu', 'cuda']:
            if 'pixel_values' in inputs:
                inputs['pixel_values'] = inputs['pixel_values'].half()
        
        # é¢„çƒ­
        print(f"ğŸ”¥ é¢„çƒ­ä¸­... ({warmup_runs}æ¬¡)")
        for _ in range(warmup_runs):
            with torch.no_grad():
                _ = model(**inputs)
            
            if device == 'npu':
                torch.npu.synchronize()
            elif device == 'cuda':
                torch.cuda.synchronize()
        
        # åŸºå‡†æµ‹è¯•
        print(f"â±ï¸  è¿è¡ŒåŸºå‡†æµ‹è¯•... ({num_runs}æ¬¡)")
        times = []
        
        for i in range(num_runs):
            # åŒæ­¥
            if device == 'npu':
                torch.npu.synchronize()
            elif device == 'cuda':
                torch.cuda.synchronize()
            
            start_time = time.time()
            
            with torch.no_grad():
                outputs = model(**inputs)
            
            # åŒæ­¥
            if device == 'npu':
                torch.npu.synchronize()
            elif device == 'cuda':
                torch.cuda.synchronize()
            
            elapsed = time.time() - start_time
            times.append(elapsed * 1000)  # è½¬æ¢ä¸ºms
            
            if (i + 1) % 20 == 0:
                print(f"   è¿›åº¦: {i + 1}/{num_runs}")
        
        times = np.array(times)
        
        # ç»Ÿè®¡
        stats = {
            'device': device,
            'fp16': use_fp16,
            'num_runs': num_runs,
            'mean_ms': float(times.mean()),
            'std_ms': float(times.std()),
            'min_ms': float(times.min()),
            'max_ms': float(times.max()),
            'p50_ms': float(np.percentile(times, 50)),
            'p95_ms': float(np.percentile(times, 95)),
            'p99_ms': float(np.percentile(times, 99)),
            'throughput_per_sec': float(1000.0 / times.mean())
        }
        
        # æ˜¾å­˜ç»Ÿè®¡
        if device == 'npu':
            stats['memory_allocated_mb'] = torch.npu.memory_allocated() / 1024 / 1024
            stats['memory_reserved_mb'] = torch.npu.memory_reserved() / 1024 / 1024
        elif device == 'cuda':
            stats['memory_allocated_mb'] = torch.cuda.memory_allocated() / 1024 / 1024
            stats['memory_reserved_mb'] = torch.cuda.memory_reserved() / 1024 / 1024
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡å»¶è¿Ÿ: {stats['mean_ms']:.2f}ms (Â±{stats['std_ms']:.2f}ms)")
        print(f"   ä¸­ä½æ•°: {stats['p50_ms']:.2f}ms")
        print(f"   P95: {stats['p95_ms']:.2f}ms")
        print(f"   P99: {stats['p99_ms']:.2f}ms")
        print(f"   æœ€å°/æœ€å¤§: {stats['min_ms']:.2f}ms / {stats['max_ms']:.2f}ms")
        print(f"   ååé‡: {stats['throughput_per_sec']:.2f} images/sec")
        
        if 'memory_allocated_mb' in stats:
            print(f"   æ˜¾å­˜å ç”¨: {stats['memory_allocated_mb']:.2f}MB")
            print(f"   æ˜¾å­˜å³°å€¼: {stats['memory_reserved_mb']:.2f}MB")
        
        # æ¸…ç†
        del model
        if device == 'npu':
            torch.npu.empty_cache()
        elif device == 'cuda':
            torch.cuda.empty_cache()
        
        return stats
    
    def run_comparison(
        self,
        image_path: str,
        texts: List[str],
        devices: List[str] = None,
        num_runs: int = 100,
        test_fp16: bool = True
    ) -> Dict:
        """
        è¿è¡Œå¤šè®¾å¤‡å¯¹æ¯”æµ‹è¯•
        
        Args:
            image_path: æµ‹è¯•å›¾åƒè·¯å¾„
            texts: æµ‹è¯•æ–‡æœ¬åˆ—è¡¨
            devices: è®¾å¤‡åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæµ‹è¯•æ‰€æœ‰å¯ç”¨è®¾å¤‡
            num_runs: æ¯ä¸ªè®¾å¤‡çš„è¿è¡Œæ¬¡æ•°
            test_fp16: æ˜¯å¦æµ‹è¯•FP16
            
        Returns:
            æ‰€æœ‰æµ‹è¯•ç»“æœ
        """
        if devices is None:
            devices = []
            if torch.npu.is_available():
                devices.append('npu')
            if torch.cuda.is_available():
                devices.append('cuda')
            devices.append('cpu')  # CPUæ€»æ˜¯å¯ç”¨
        
        results = {}
        
        for device in devices:
            # FP32æµ‹è¯•
            result_fp32 = self.benchmark_device(
                device=device,
                image_path=image_path,
                texts=texts,
                num_runs=num_runs,
                warmup_runs=10,
                use_fp16=False
            )
            
            if result_fp32:
                results[f"{device}_fp32"] = result_fp32
            
            # FP16æµ‹è¯•ï¼ˆä»…NPUå’ŒCUDAï¼‰
            if test_fp16 and device in ['npu', 'cuda']:
                result_fp16 = self.benchmark_device(
                    device=device,
                    image_path=image_path,
                    texts=texts,
                    num_runs=num_runs,
                    warmup_runs=10,
                    use_fp16=True
                )
                
                if result_fp16:
                    results[f"{device}_fp16"] = result_fp16
        
        self.results = results
        return results
    
    def print_comparison_table(self):
        """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
        if not self.results:
            print("æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        print(f"\n{'='*80}")
        print("æ€§èƒ½å¯¹æ¯”è¡¨")
        print(f"{'='*80}")
        print(f"{'é…ç½®':<20} {'å¹³å‡å»¶è¿Ÿ':<15} {'ååé‡':<15} {'æ˜¾å­˜å ç”¨':<15} {'ç›¸å¯¹æ€§èƒ½'}")
        print(f"{'-'*80}")
        
        # æ‰¾å‡ºåŸºå‡†ï¼ˆæœ€å¿«çš„ï¼‰
        baseline_throughput = max(
            r['throughput_per_sec'] for r in self.results.values()
        )
        
        for config, result in sorted(self.results.items()):
            device = config.split('_')[0].upper()
            precision = config.split('_')[1].upper()
            config_name = f"{device} ({precision})"
            
            mean_ms = result['mean_ms']
            throughput = result['throughput_per_sec']
            memory = result.get('memory_allocated_mb', 0)
            relative_perf = (throughput / baseline_throughput) * 100
            
            print(f"{config_name:<20} {mean_ms:>8.2f}ms {throughput:>10.2f}/s "
                  f"{memory:>10.2f}MB {relative_perf:>10.1f}%")
        
        print(f"{'='*80}\n")
    
    def save_results(self, output_path: str):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        with open(output_path, 'w') as f:
            json.dump(self.results, f, indent=2)
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='åä¸ºæ˜‡è…¾æ€§èƒ½åŸºå‡†æµ‹è¯•')
    parser.add_argument('--model', type=str, default='openai/clip-vit-base-patch32',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--image', type=str, required=True,
                        help='æµ‹è¯•å›¾åƒè·¯å¾„')
    parser.add_argument('--texts', type=str, nargs='+',
                        default=['a photo of a cat', 'a photo of a dog'],
                        help='æµ‹è¯•æ–‡æœ¬')
    parser.add_argument('--devices', type=str, nargs='+',
                        choices=['npu', 'cuda', 'cpu'],
                        help='æµ‹è¯•è®¾å¤‡åˆ—è¡¨ï¼ˆé»˜è®¤æµ‹è¯•æ‰€æœ‰å¯ç”¨è®¾å¤‡ï¼‰')
    parser.add_argument('--num-runs', type=int, default=100,
                        help='æ¯ä¸ªè®¾å¤‡çš„è¿è¡Œæ¬¡æ•°')
    parser.add_argument('--no-fp16', action='store_true',
                        help='è·³è¿‡FP16æµ‹è¯•')
    parser.add_argument('--output', type=str, default='benchmark_results.json',
                        help='ç»“æœè¾“å‡ºè·¯å¾„')
    
    args = parser.parse_args()
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark = PerformanceBenchmark(model_path=args.model)
    
    results = benchmark.run_comparison(
        image_path=args.image,
        texts=args.texts,
        devices=args.devices,
        num_runs=args.num_runs,
        test_fp16=not args.no_fp16
    )
    
    # æ‰“å°å¯¹æ¯”è¡¨
    benchmark.print_comparison_table()
    
    # ä¿å­˜ç»“æœ
    benchmark.save_results(args.output)


if __name__ == '__main__':
    main()

