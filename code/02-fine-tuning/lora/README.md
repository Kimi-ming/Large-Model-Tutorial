# LoRAå¾®è°ƒç¤ºä¾‹ä»£ç 

ä½¿ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰æ–¹æ³•å¾®è°ƒCLIPæ¨¡å‹è¿›è¡ŒçŠ¬ç§åˆ†ç±»ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
code/02-fine-tuning/lora/
â”œâ”€â”€ __init__.py           # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ config.yaml           # é…ç½®æ–‡ä»¶
â”œâ”€â”€ dataset.py            # æ•°æ®é›†ç±»
â”œâ”€â”€ train.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ evaluate.py           # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ inference.py          # æ¨ç†è„šæœ¬
â””â”€â”€ README.md             # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®é›†

```bash
# åˆ›å»ºæ•°æ®é›†ç›®å½•ç»“æ„
python scripts/prepare_dog_dataset.py --output_dir data/dogs --num_classes 10

# æ‰‹åŠ¨æ·»åŠ å›¾åƒåˆ°å¯¹åº”ç›®å½•
# data/dogs/train/golden_retriever/*.jpg
# data/dogs/train/labrador/*.jpg
# ...
```

**æ•°æ®é›†ç»“æ„**:
```
data/dogs/
â”œâ”€â”€ train/          # è®­ç»ƒé›†
â”‚   â”œâ”€â”€ golden_retriever/
â”‚   â”œâ”€â”€ labrador/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/            # éªŒè¯é›†
â””â”€â”€ test/           # æµ‹è¯•é›†
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python code/02-fine-tuning/lora/train.py

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python code/02-fine-tuning/lora/train.py \
    --config code/02-fine-tuning/lora/config.yaml \
    --data_dir data/dogs \
    --output_dir outputs/my_model
```

**è®­ç»ƒç›‘æ§**:
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir logs/lora_finetuning
```

### 3. è¯„ä¼°æ¨¡å‹

```bash
# è¯„ä¼°æµ‹è¯•é›†
python code/02-fine-tuning/lora/evaluate.py \
    --checkpoint outputs/lora_finetuning/checkpoint-epoch-10 \
    --data_dir data/dogs \
    --split test \
    --output_dir outputs/evaluation
```

**è¯„ä¼°è¾“å‡º**:
- `evaluation_report.txt` - è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
- `evaluation_results.json` - JSONæ ¼å¼ç»“æœ
- `confusion_matrix.png` - æ··æ·†çŸ©é˜µå¯è§†åŒ–
- `class_performance.png` - å„ç±»åˆ«æ€§èƒ½å›¾

### 4. æ¨ç†é¢„æµ‹

**å•å¼ å›¾åƒ**:
```bash
python code/02-fine-tuning/lora/inference.py \
    --checkpoint outputs/lora_finetuning/checkpoint-epoch-10 \
    --image path/to/dog.jpg \
    --top_k 5
```

**æ‰¹é‡æ¨ç†**:
```bash
python code/02-fine-tuning/lora/inference.py \
    --checkpoint outputs/lora_finetuning/checkpoint-epoch-10 \
    --image_dir path/to/images/ \
    --output predictions.txt
```

## âš™ï¸ é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ `config.yaml` åŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š

### æ¨¡å‹é…ç½®
```yaml
model:
  name: "openai/clip-vit-base-patch32"
  cache_dir: "models/"
```

### LoRAé…ç½®
```yaml
lora:
  r: 8                    # LoRAç§©ï¼ˆè¶Šå¤§å‚æ•°è¶Šå¤šï¼‰
  lora_alpha: 32          # ç¼©æ”¾ç³»æ•°
  target_modules:         # åº”ç”¨LoRAçš„æ¨¡å—
    - "q_proj"
    - "v_proj"
  lora_dropout: 0.1       # Dropoutç‡
```

**å‚æ•°è°ƒä¼˜å»ºè®®**:
- `r`: é€šå¸¸ 4-16ï¼Œè¶Šå¤§æ•ˆæœè¶Šå¥½ä½†å‚æ•°è¶Šå¤š
- `lora_alpha`: é€šå¸¸è®¾ä¸º `r * 2` æˆ– `r * 4`
- `target_modules`: å¯é€‰ `["q_proj", "v_proj", "k_proj", "out_proj"]`

### è®­ç»ƒé…ç½®
```yaml
training:
  num_epochs: 10
  learning_rate: 5.0e-4
  batch_size: 32
  warmup_ratio: 0.1
  early_stopping:
    enabled: true
    patience: 3
```

**è¶…å‚æ•°å»ºè®®**:
- å­¦ä¹ ç‡: LoRAé€šå¸¸æ¯”å…¨å‚æ•°å¾®è°ƒé«˜ (1e-4 ~ 5e-4)
- Batch size: æ ¹æ®æ˜¾å­˜è°ƒæ•´ (8GBæ˜¾å­˜â†’16-32)
- Warmup: å»ºè®® 10% çš„è®­ç»ƒæ­¥æ•°

## ğŸ“Š æ€§èƒ½åŸºå‡†

### ç¡¬ä»¶è¦æ±‚

| é…ç½® | æœ€ä½ | æ¨è |
|------|------|------|
| GPU | 8GB (RTX 3070) | 16GB+ (RTX 4080) |
| å†…å­˜ | 16GB | 32GB |
| ç¡¬ç›˜ | 10GB | 20GB (SSD) |

### è®­ç»ƒæ—¶é—´ä¼°ç®—

| æ•°æ®é›†å¤§å° | GPU | è®­ç»ƒæ—¶é—´ (10 epochs) |
|-----------|-----|---------------------|
| 1K å›¾åƒ | RTX 3070 | ~15åˆ†é’Ÿ |
| 5K å›¾åƒ | RTX 3070 | ~1å°æ—¶ |
| 10K å›¾åƒ | RTX 4080 | ~1.5å°æ—¶ |

### é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | é¢„è®­ç»ƒCLIP | LoRAå¾®è°ƒ |
|------|-----------|---------|
| Top-1å‡†ç¡®ç‡ | ~60% | ~85%+ |
| Top-5å‡†ç¡®ç‡ | ~85% | ~95%+ |
| å¯è®­ç»ƒå‚æ•° | 100% | <1% |

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. CUDAå†…å­˜ä¸è¶³

**é—®é¢˜**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å‡å°batch_size
data:
  batch_size: 16  # æˆ– 8

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
training:
  gradient_accumulation_steps: 2
```

### 2. æ•°æ®é›†åŠ è½½å¤±è´¥

**é—®é¢˜**: `ValueError: åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# éªŒè¯æ•°æ®é›†ç»“æ„
python scripts/prepare_dog_dataset.py --output_dir data/dogs --validate

# ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®ï¼ˆJPG/PNGï¼‰
# ç¡®ä¿ç›®å½•ç»“æ„ç¬¦åˆè¦æ±‚
```

### 3. è®­ç»ƒä¸æ”¶æ•›

**é—®é¢˜**: éªŒè¯å‡†ç¡®ç‡ä¸æå‡

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥å­¦ä¹ ç‡ï¼ˆå°è¯• 1e-4 ~ 1e-3ï¼‰
- å¢åŠ è®­ç»ƒè½®æ•°
- æ£€æŸ¥æ•°æ®è´¨é‡å’Œæ ‡æ³¨
- å°è¯•å¢å¤§ LoRA rank (`r: 16`)

### 4. æ¨ç†é€Ÿåº¦æ…¢

**é—®é¢˜**: æ¨ç†æ—¶é—´è¿‡é•¿

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨æ‰¹é‡æ¨ç†
predictor.predict_batch(images, top_k=5)

# ä½¿ç”¨æ··åˆç²¾åº¦
# åœ¨config.yamlä¸­å¯ç”¨
hardware:
  mixed_precision: true
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LoRAå¾®è°ƒå®è·µæ•™ç¨‹](../../../docs/02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/02-LoRAå¾®è°ƒå®è·µ.md)
- [å¾®è°ƒç†è®ºåŸºç¡€](../../../docs/02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/01-å¾®è°ƒç†è®ºåŸºç¡€.md)
- [PEFTåº“æ–‡æ¡£](https://huggingface.co/docs/peft)

## ğŸ¤ è´¡çŒ®

å¦‚æœæ‚¨å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿æäº¤Issueæˆ–Pull Requestã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

