"""
LoRAå¾®è°ƒæ¨¡å‹æ¨ç†è„šæœ¬

ä½¿ç”¨å¾®è°ƒåçš„CLIPæ¨¡å‹è¿›è¡Œå•å¼ å›¾åƒæˆ–æ‰¹é‡å›¾åƒçš„æ¨ç†
"""

import os
import sys
import argparse
from pathlib import Path
from typing import List, Tuple, Union
import time

import torch
import torch.nn as nn
from PIL import Image
from transformers import CLIPProcessor
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œå½“å‰ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
current_dir = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(current_dir))

# å¯¼å…¥å½“å‰ç›®å½•çš„æ¨¡å—
from train import CLIPClassifier
from evaluate import load_model


class DogBreedPredictor:
    """çŠ¬ç§é¢„æµ‹å™¨"""
    
    def __init__(
        self,
        checkpoint_dir: str,
        device: torch.device = None
    ):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            checkpoint_dir: æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•
            device: è®¡ç®—è®¾å¤‡
        """
        self.checkpoint_dir = checkpoint_dir
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½å¤„ç†å™¨
        print("ğŸ“¦ åŠ è½½å¤„ç†å™¨...")
        self.processor = CLIPProcessor.from_pretrained(checkpoint_dir)
        
        # åŠ è½½ç±»åˆ«åç§°
        classes_file = Path(checkpoint_dir).parent.parent / 'data' / 'dogs' / 'classes.txt'
        if classes_file.exists():
            with open(classes_file, 'r', encoding='utf-8') as f:
                self.class_names = [line.strip() for line in f]
        else:
            # å¦‚æœæ²¡æœ‰classes.txtï¼Œå°è¯•ä»æ•°æ®ç›®å½•è¯»å–
            data_dir = Path('data/dogs/train')
            if data_dir.exists():
                self.class_names = sorted([d.name for d in data_dir.iterdir() if d.is_dir()])
            else:
                print("âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½ç±»åˆ«åç§°")
                self.class_names = [f"class_{i}" for i in range(10)]
        
        num_classes = len(self.class_names)
        print(f"   ç±»åˆ«æ•°: {num_classes}")
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ¤– åŠ è½½æ¨¡å‹...")
        self.model = load_model(checkpoint_dir, num_classes, self.device)
        self.model.eval()
        
        print("âœ… é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    @torch.no_grad()
    def predict(
        self,
        image: Union[str, Image.Image],
        top_k: int = 5
    ) -> List[Tuple[str, float]]:
        """
        é¢„æµ‹å•å¼ å›¾åƒ
        
        Args:
            image: å›¾åƒè·¯å¾„æˆ–PILå›¾åƒå¯¹è±¡
            top_k: è¿”å›å‰kä¸ªé¢„æµ‹ç»“æœ
            
        Returns:
            [(ç±»åˆ«å, ç½®ä¿¡åº¦), ...] åˆ—è¡¨
        """
        # åŠ è½½å›¾åƒ
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        elif not isinstance(image, Image.Image):
            raise ValueError("imageå¿…é¡»æ˜¯æ–‡ä»¶è·¯å¾„æˆ–PIL.Imageå¯¹è±¡")
        
        # é¢„å¤„ç†
        inputs = self.processor(images=image, return_tensors="pt")
        pixel_values = inputs['pixel_values'].to(self.device)
        
        # æ¨ç†
        start_time = time.time()
        logits = self.model(pixel_values)
        inference_time = time.time() - start_time
        
        # è®¡ç®—æ¦‚ç‡
        probs = torch.softmax(logits, dim=1)[0]
        
        # è·å–top-kç»“æœ
        top_probs, top_indices = torch.topk(probs, min(top_k, len(self.class_names)))
        
        results = [
            (self.class_names[idx.item()], prob.item())
            for idx, prob in zip(top_indices, top_probs)
        ]
        
        return results, inference_time
    
    @torch.no_grad()
    def predict_batch(
        self,
        images: List[Union[str, Image.Image]],
        top_k: int = 5
    ) -> List[List[Tuple[str, float]]]:
        """
        æ‰¹é‡é¢„æµ‹
        
        Args:
            images: å›¾åƒè·¯å¾„æˆ–PILå›¾åƒå¯¹è±¡åˆ—è¡¨
            top_k: è¿”å›å‰kä¸ªé¢„æµ‹ç»“æœ
            
        Returns:
            æ¯å¼ å›¾åƒçš„é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        # åŠ è½½å›¾åƒ
        pil_images = []
        for img in images:
            if isinstance(img, str):
                pil_images.append(Image.open(img).convert('RGB'))
            elif isinstance(img, Image.Image):
                pil_images.append(img)
            else:
                raise ValueError("imageå¿…é¡»æ˜¯æ–‡ä»¶è·¯å¾„æˆ–PIL.Imageå¯¹è±¡")
        
        # é¢„å¤„ç†
        inputs = self.processor(images=pil_images, return_tensors="pt")
        pixel_values = inputs['pixel_values'].to(self.device)
        
        # æ¨ç†
        start_time = time.time()
        logits = self.model(pixel_values)
        inference_time = time.time() - start_time
        
        # è®¡ç®—æ¦‚ç‡
        probs = torch.softmax(logits, dim=1)
        
        # è·å–top-kç»“æœ
        all_results = []
        for prob in probs:
            top_probs, top_indices = torch.topk(prob, min(top_k, len(self.class_names)))
            results = [
                (self.class_names[idx.item()], p.item())
                for idx, p in zip(top_indices, top_probs)
            ]
            all_results.append(results)
        
        avg_time = inference_time / len(images)
        print(f"â±ï¸  æ‰¹é‡æ¨ç†: {len(images)}å¼ å›¾åƒ, æ€»è€—æ—¶{inference_time:.3f}s, å¹³å‡{avg_time:.3f}s/å¼ ")
        
        return all_results


def print_predictions(
    image_path: str,
    predictions: List[Tuple[str, float]],
    inference_time: float
):
    """
    æ‰“å°é¢„æµ‹ç»“æœ
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        predictions: é¢„æµ‹ç»“æœ
        inference_time: æ¨ç†æ—¶é—´
    """
    print("\n" + "=" * 60)
    print(f"å›¾åƒ: {image_path}")
    print("-" * 60)
    print(f"æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")
    print("\né¢„æµ‹ç»“æœ:")
    for i, (class_name, confidence) in enumerate(predictions, 1):
        bar_length = int(confidence * 40)
        bar = "â–ˆ" * bar_length + "â–‘" * (40 - bar_length)
        print(f"  {i}. {class_name:20s} {bar} {confidence*100:5.2f}%")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description="LoRAå¾®è°ƒæ¨¡å‹æ¨ç†")
    parser.add_argument(
        '--checkpoint',
        type=str,
        required=True,
        help='æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•'
    )
    parser.add_argument(
        '--image',
        type=str,
        help='å•å¼ å›¾åƒè·¯å¾„'
    )
    parser.add_argument(
        '--image_dir',
        type=str,
        help='å›¾åƒç›®å½•ï¼ˆæ‰¹é‡æ¨ç†ï¼‰'
    )
    parser.add_argument(
        '--top_k',
        type=int,
        default=5,
        help='è¿”å›å‰kä¸ªé¢„æµ‹ç»“æœ'
    )
    parser.add_argument(
        '--output',
        type=str,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜é¢„æµ‹ç»“æœï¼‰'
    )
    
    args = parser.parse_args()
    
    if not args.image and not args.image_dir:
        parser.error("å¿…é¡»æŒ‡å®š --image æˆ– --image_dir")
    
    print("=" * 60)
    print("LoRAå¾®è°ƒæ¨¡å‹æ¨ç†")
    print("=" * 60)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = DogBreedPredictor(args.checkpoint)
    
    # å•å¼ å›¾åƒæ¨ç†
    if args.image:
        print(f"\nğŸ–¼ï¸  æ¨ç†å•å¼ å›¾åƒ: {args.image}")
        predictions, inference_time = predictor.predict(args.image, args.top_k)
        print_predictions(args.image, predictions, inference_time)
        
        # ä¿å­˜ç»“æœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(f"Image: {args.image}\n")
                f.write(f"Inference Time: {inference_time*1000:.2f}ms\n\n")
                f.write("Predictions:\n")
                for i, (class_name, confidence) in enumerate(predictions, 1):
                    f.write(f"{i}. {class_name}: {confidence*100:.2f}%\n")
            print(f"\nâœ… ç»“æœå·²ä¿å­˜: {args.output}")
    
    # æ‰¹é‡æ¨ç†
    elif args.image_dir:
        print(f"\nğŸ“ æ‰¹é‡æ¨ç†ç›®å½•: {args.image_dir}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒ
        image_dir = Path(args.image_dir)
        image_paths = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
            image_paths.extend(image_dir.glob(ext))
        
        if len(image_paths) == 0:
            print(f"âŒ åœ¨ {args.image_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
        
        print(f"   æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
        
        # æ‰¹é‡æ¨ç†
        all_predictions = predictor.predict_batch(
            [str(p) for p in image_paths],
            args.top_k
        )
        
        # æ‰“å°ç»“æœ
        for image_path, predictions in zip(image_paths, all_predictions):
            print(f"\n{image_path.name}:")
            for i, (class_name, confidence) in enumerate(predictions[:3], 1):
                print(f"  {i}. {class_name}: {confidence*100:.2f}%")
        
        # ä¿å­˜ç»“æœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                for image_path, predictions in zip(image_paths, all_predictions):
                    f.write(f"\nImage: {image_path.name}\n")
                    f.write("Predictions:\n")
                    for i, (class_name, confidence) in enumerate(predictions, 1):
                        f.write(f"  {i}. {class_name}: {confidence*100:.2f}%\n")
            print(f"\nâœ… ç»“æœå·²ä¿å­˜: {args.output}")
    
    print("\nâœ… æ¨ç†å®Œæˆï¼")


if __name__ == '__main__':
    main()

