"""
LoRAå¾®è°ƒè®­ç»ƒè„šæœ¬

ä½¿ç”¨LoRAæ–¹æ³•å¾®è°ƒCLIPæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»
"""

import os
import sys
import argparse
import yaml
from pathlib import Path
from typing import Dict, Any
import random
import numpy as np

import torch
import torch.nn as nn
from torch.utils.tensorboard import SummaryWriter
from transformers import CLIPModel, CLIPProcessor
from peft import LoraConfig, get_peft_model, PeftModel
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from code.utils.model_loader import ModelLoader
from dataset import DogBreedDataset, create_dataloaders


def set_seed(seed: int):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯å¤ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


class CLIPClassifier(nn.Module):
    """
    CLIPåˆ†ç±»å™¨
    
    åœ¨CLIPè§†è§‰ç¼–ç å™¨åŸºç¡€ä¸Šæ·»åŠ åˆ†ç±»å¤´
    """
    
    def __init__(self, clip_model: CLIPModel, num_classes: int):
        super().__init__()
        self.clip_model = clip_model
        self.vision_model = clip_model.vision_model
        
        # è·å–è§†è§‰ç¼–ç å™¨çš„è¾“å‡ºç»´åº¦
        hidden_size = self.vision_model.config.hidden_size
        
        # æ·»åŠ åˆ†ç±»å¤´
        self.classifier = nn.Linear(hidden_size, num_classes)
        
        # åˆå§‹åŒ–åˆ†ç±»å¤´
        nn.init.normal_(self.classifier.weight, std=0.02)
        nn.init.zeros_(self.classifier.bias)
    
    def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:
        # é€šè¿‡CLIPè§†è§‰ç¼–ç å™¨
        vision_outputs = self.vision_model(pixel_values=pixel_values)
        
        # è·å–[CLS] tokençš„è¾“å‡º
        pooled_output = vision_outputs.pooler_output
        
        # åˆ†ç±»
        logits = self.classifier(pooled_output)
        
        return logits


class Trainer:
    """è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: torch.utils.data.DataLoader,
        val_loader: torch.utils.data.DataLoader,
        config: Dict[str, Any],
        device: torch.device
    ):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=config['training']['learning_rate'],
            weight_decay=config['training']['weight_decay']
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        total_steps = len(train_loader) * config['training']['num_epochs']
        warmup_steps = int(total_steps * config['training']['warmup_ratio'])
        
        if config['training']['lr_scheduler']['type'] == 'cosine':
            from torch.optim.lr_scheduler import CosineAnnealingLR
            self.scheduler = CosineAnnealingLR(
                self.optimizer,
                T_max=total_steps - warmup_steps
            )
        elif config['training']['lr_scheduler']['type'] == 'linear':
            from torch.optim.lr_scheduler import LinearLR
            self.scheduler = LinearLR(self.optimizer)
        else:
            self.scheduler = None
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()
        
        # TensorBoard
        log_dir = config['output']['log_dir']
        os.makedirs(log_dir, exist_ok=True)
        self.writer = SummaryWriter(log_dir)
        
        # è¾“å‡ºç›®å½•
        self.output_dir = config['output']['output_dir']
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        self.best_val_acc = 0.0
        self.patience_counter = 0
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_amp = config['hardware']['mixed_precision'] and torch.cuda.is_available()
        if self.use_amp:
            self.scaler = torch.cuda.amp.GradScaler()
            print("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰")
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch}")
        
        for batch_idx, (pixel_values, labels) in enumerate(pbar):
            pixel_values = pixel_values.to(self.device)
            labels = labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            if self.use_amp:
                with torch.cuda.amp.autocast():
                    logits = self.model(pixel_values)
                    loss = self.criterion(logits, labels)
            else:
                logits = self.model(pixel_values)
                loss = self.criterion(logits, labels)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            
            if self.use_amp:
                self.scaler.scale(loss).backward()
                
                # æ¢¯åº¦è£å‰ª
                if self.config['training']['max_grad_norm'] > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.config['training']['max_grad_norm']
                    )
                
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                if self.config['training']['max_grad_norm'] > 0:
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.config['training']['max_grad_norm']
                    )
                
                self.optimizer.step()
            
            if self.scheduler:
                self.scheduler.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = torch.max(logits, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{100.0 * correct / total:.2f}%'
            })
            
            # è®°å½•æ—¥å¿—
            if self.global_step % self.config['evaluation']['logging_steps'] == 0:
                self.writer.add_scalar('train/loss', loss.item(), self.global_step)
                self.writer.add_scalar('train/accuracy', 100.0 * correct / total, self.global_step)
                self.writer.add_scalar('train/learning_rate', self.optimizer.param_groups[0]['lr'], self.global_step)
            
            self.global_step += 1
        
        avg_loss = total_loss / len(self.train_loader)
        accuracy = 100.0 * correct / total
        
        return {'loss': avg_loss, 'accuracy': accuracy}
    
    @torch.no_grad()
    def evaluate(self) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        
        total_loss = 0.0
        correct = 0
        total = 0
        
        for pixel_values, labels in tqdm(self.val_loader, desc="Evaluating"):
            pixel_values = pixel_values.to(self.device)
            labels = labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            logits = self.model(pixel_values)
            loss = self.criterion(logits, labels)
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = torch.max(logits, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        
        avg_loss = total_loss / len(self.val_loader)
        accuracy = 100.0 * correct / total
        
        return {'loss': avg_loss, 'accuracy': accuracy}
    
    def save_checkpoint(self, epoch: int, val_metrics: Dict[str, float]):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_dir = os.path.join(self.output_dir, f'checkpoint-epoch-{epoch}')
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # ä¿å­˜LoRAæƒé‡
        self.model.clip_model.save_pretrained(checkpoint_dir)
        
        # ä¿å­˜åˆ†ç±»å¤´
        torch.save(
            self.model.classifier.state_dict(),
            os.path.join(checkpoint_dir, 'classifier.pt')
        )
        
        # ä¿å­˜è®­ç»ƒçŠ¶æ€
        torch.save({
            'epoch': epoch,
            'global_step': self.global_step,
            'best_val_acc': self.best_val_acc,
            'optimizer_state_dict': self.optimizer.state_dict(),
            'val_metrics': val_metrics,
        }, os.path.join(checkpoint_dir, 'training_state.pt'))
        
        print(f"âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_dir}")
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("\n" + "=" * 60)
        print("å¼€å§‹è®­ç»ƒ")
        print("=" * 60)
        
        num_epochs = self.config['training']['num_epochs']
        early_stopping_patience = self.config['training']['early_stopping']['patience']
        
        for epoch in range(1, num_epochs + 1):
            print(f"\nğŸ“Š Epoch {epoch}/{num_epochs}")
            
            # è®­ç»ƒ
            train_metrics = self.train_epoch(epoch)
            print(f"   è®­ç»ƒ - Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.2f}%")
            
            # è¯„ä¼°
            val_metrics = self.evaluate()
            print(f"   éªŒè¯ - Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.2f}%")
            
            # è®°å½•åˆ°TensorBoard
            self.writer.add_scalar('val/loss', val_metrics['loss'], epoch)
            self.writer.add_scalar('val/accuracy', val_metrics['accuracy'], epoch)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['accuracy'] > self.best_val_acc:
                self.best_val_acc = val_metrics['accuracy']
                self.save_checkpoint(epoch, val_metrics)
                self.patience_counter = 0
                print(f"   ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.2f}%")
            else:
                self.patience_counter += 1
            
            # æ—©åœ
            if self.config['training']['early_stopping']['enabled']:
                if self.patience_counter >= early_stopping_patience:
                    print(f"\nâš ï¸  æ—©åœè§¦å‘ï¼éªŒè¯å‡†ç¡®ç‡å·² {early_stopping_patience} è½®æœªæå‡")
                    break
        
        print("\n" + "=" * 60)
        print(f"âœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.2f}%")
        print("=" * 60)
        
        self.writer.close()


def main():
    parser = argparse.ArgumentParser(description="LoRAå¾®è°ƒè®­ç»ƒè„šæœ¬")
    parser.add_argument(
        '--config',
        type=str,
        default='code/02-fine-tuning/lora/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--data_dir',
        type=str,
        help='æ•°æ®é›†ç›®å½•ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        help='è¾“å‡ºç›®å½•ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.data_dir:
        config['data']['data_dir'] = args.data_dir
    if args.output_dir:
        config['output']['output_dir'] = args.output_dir
    
    # è®¾ç½®éšæœºç§å­
    set_seed(config['seed'])
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(config['hardware']['device'] if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½å¤„ç†å™¨
    print("\nğŸ“¦ åŠ è½½CLIPå¤„ç†å™¨...")
    processor = CLIPProcessor.from_pretrained(
        config['model']['name'],
        cache_dir=config['model']['cache_dir']
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“Š å‡†å¤‡æ•°æ®...")
    train_loader, val_loader, test_loader = create_dataloaders(
        data_dir=config['data']['data_dir'],
        processor=processor,
        batch_size=config['data']['batch_size'],
        num_workers=config['data']['num_workers'],
        pin_memory=config['data']['pin_memory']
    )
    
    # è·å–ç±»åˆ«æ•°
    num_classes = len(train_loader.dataset.classes)
    print(f"   ç±»åˆ«æ•°: {num_classes}")
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    print("\nğŸ¤– åŠ è½½é¢„è®­ç»ƒCLIPæ¨¡å‹...")
    clip_model = CLIPModel.from_pretrained(
        config['model']['name'],
        cache_dir=config['model']['cache_dir']
    )
    
    # é…ç½®LoRA
    print("\nâš™ï¸  é…ç½®LoRA...")
    lora_config = LoraConfig(
        r=config['lora']['r'],
        lora_alpha=config['lora']['lora_alpha'],
        target_modules=config['lora']['target_modules'],
        lora_dropout=config['lora']['lora_dropout'],
        bias=config['lora']['bias'],
        task_type="FEATURE_EXTRACTION"
    )
    
    # åº”ç”¨LoRA
    clip_model.vision_model = get_peft_model(clip_model.vision_model, lora_config)
    
    # æ‰“å°å¯è®­ç»ƒå‚æ•°
    trainable_params = sum(p.numel() for p in clip_model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in clip_model.parameters())
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)")
    
    # åˆ›å»ºåˆ†ç±»å™¨
    model = CLIPClassifier(clip_model, num_classes)
    model = model.to(device)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config,
        device=device
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()


if __name__ == '__main__':
    main()

