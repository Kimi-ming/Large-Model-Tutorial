{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ LoRAå¾®è°ƒå®æˆ˜æ•™ç¨‹\n",
    "\n",
    "**æ¬¢è¿æ¥åˆ°LoRAå¾®è°ƒå®æˆ˜æ•™ç¨‹ï¼**\n",
    "\n",
    "æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨ä½¿ç”¨LoRAæŠ€æœ¯å¾®è°ƒCLIPæ¨¡å‹ï¼Œå®ŒæˆçŠ¬ç§è¯†åˆ«ä»»åŠ¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "- âœ… ç†è§£LoRAå¾®è°ƒçš„åŸç†å’Œä¼˜åŠ¿\n",
    "- âœ… æŒæ¡æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†æµç¨‹\n",
    "- âœ… å­¦ä¼šé…ç½®å’Œè®­ç»ƒLoRAæ¨¡å‹\n",
    "- âœ… è¯„ä¼°å’Œä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹\n",
    "\n",
    "---\n",
    "\n",
    "## â±ï¸ é¢„è®¡å­¦ä¹ æ—¶é—´\n",
    "\n",
    "- å®Œæ•´è¿è¡Œï¼šçº¦ 30-45 åˆ†é’Ÿ\n",
    "- å¿«é€Ÿæµè§ˆï¼šçº¦ 10-15 åˆ†é’Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä»»åŠ¡è¯´æ˜\n",
    "\n",
    "**ä»»åŠ¡**ï¼šçŠ¬ç§è¯†åˆ«\n",
    "\n",
    "- **æ•°æ®é›†**ï¼šStanford Dogsï¼ˆ10ä¸ªçŠ¬ç§ï¼‰\n",
    "- **åŸºç¡€æ¨¡å‹**ï¼šCLIP-ViT-B/32\n",
    "- **å¾®è°ƒæ–¹æ³•**ï¼šLoRAï¼ˆr=8ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ å‰ç½®è¦æ±‚\n",
    "\n",
    "```bash\n",
    "# 1. å‡†å¤‡æ•°æ®\n",
    "python scripts/prepare_dog_dataset.py --output_dir data/dogs --num_classes 10\n",
    "\n",
    "# 2. å®‰è£…ä¾èµ–\n",
    "pip install jupyter torch transformers peft pillow matplotlib tqdm scikit-learn seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "## 1.1 å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºç¡€åº“\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ·±åº¦å­¦ä¹ \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# HuggingFace\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼\")\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 é…ç½®å‚æ•°\n",
    "\n",
    "ğŸ’¡ **æç¤º**ï¼šæ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„ç¡¬ä»¶æ¡ä»¶è°ƒæ•´è¿™äº›å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®ç±»\n",
    "class Config:\n",
    "    # æ¨¡å‹é…ç½®\n",
    "    model_name = \"openai/clip-vit-base-patch32\"\n",
    "    num_classes = 10\n",
    "    \n",
    "    # LoRAé…ç½®\n",
    "    lora_r = 8\n",
    "    lora_alpha = 32\n",
    "    lora_dropout = 0.1\n",
    "    target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    \n",
    "    # è®­ç»ƒé…ç½®\n",
    "    batch_size = 16\n",
    "    num_epochs = 5\n",
    "    learning_rate = 5e-4\n",
    "    \n",
    "    # æ•°æ®å’Œè®¾å¤‡\n",
    "    data_dir = \"../data/dogs\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    output_dir = \"../outputs/lora_notebook\"\n",
    "\n",
    "config = Config()\n",
    "print(f\"ğŸ“‹ è®¾å¤‡: {config.device}\")\n",
    "print(f\"ğŸ“‹ LoRAç§©: {config.lora_r}\")\n",
    "print(f\"ğŸ“‹ æ‰¹æ¬¡å¤§å°: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ç¬¬äºŒéƒ¨åˆ†ï¼šä½¿ç”¨è®­ç»ƒè„šæœ¬\n",
    "\n",
    "## ğŸ’¡ æ¨èæ–¹å¼ï¼šä½¿ç”¨ç°æœ‰çš„è®­ç»ƒè„šæœ¬\n",
    "\n",
    "æˆ‘ä»¬å·²ç»æä¾›äº†å®Œæ•´çš„è®­ç»ƒè„šæœ¬ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š\n",
    "\n",
    "### æ–¹æ³•1ï¼šå‘½ä»¤è¡Œè®­ç»ƒï¼ˆæ¨èï¼‰\n",
    "\n",
    "```bash\n",
    "# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ\n",
    "python code/02-fine-tuning/lora/train.py\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®\n",
    "python code/02-fine-tuning/lora/train.py --config code/02-fine-tuning/lora/config.yaml\n",
    "```\n",
    "\n",
    "### æ–¹æ³•2ï¼šåœ¨Notebookä¸­è°ƒç”¨è„šæœ¬\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼æ¥å¯åŠ¨è®­ç»ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨Notebookä¸­è¿è¡Œè®­ç»ƒè„šæœ¬\n",
    "!python ../code/02-fine-tuning/lora/train.py \\\n",
    "    --config ../code/02-fine-tuning/lora/config.yaml \\\n",
    "    --output_dir {config.output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¯„ä¼°æ¨¡å‹\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œè®©æˆ‘ä»¬è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œè¯„ä¼°è„šæœ¬\n",
    "!python ../code/02-fine-tuning/lora/evaluate.py \\\n",
    "    --model_path {config.output_dir}/best_model \\\n",
    "    --data_dir {config.data_dir} \\\n",
    "    --output_dir {config.output_dir}/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹æ¨ç†\n",
    "\n",
    "## 4.1 å•å¼ å›¾åƒæ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€‰æ‹©ä¸€å¼ æµ‹è¯•å›¾åƒ\n",
    "test_image = \"path/to/your/test/image.jpg\"  # ä¿®æ”¹ä¸ºå®é™…è·¯å¾„\n",
    "\n",
    "# è¿è¡Œæ¨ç†\n",
    "!python ../code/02-fine-tuning/lora/inference.py \\\n",
    "    --model_path {config.output_dir}/best_model \\\n",
    "    --image_path {test_image} \\\n",
    "    --top_k 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 æ‰¹é‡æ¨ç†å’Œå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹é‡æ¨ç†\n",
    "!python ../code/02-fine-tuning/lora/inference.py \\\n",
    "    --model_path {config.output_dir}/best_model \\\n",
    "    --image_dir {config.data_dir}/test \\\n",
    "    --output_dir {config.output_dir}/predictions \\\n",
    "    --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ æ€»ç»“\n",
    "\n",
    "## âœ… å®Œæˆçš„å†…å®¹\n",
    "\n",
    "1. âœ… é…ç½®LoRAå¾®è°ƒå‚æ•°\n",
    "2. âœ… è®­ç»ƒCLIPæ¨¡å‹\n",
    "3. âœ… è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "4. âœ… è¿›è¡Œæ¨¡å‹æ¨ç†\n",
    "\n",
    "## ğŸ”‘ å…³é”®è¦ç‚¹\n",
    "\n",
    "- **LoRAä¼˜åŠ¿**ï¼šåªè®­ç»ƒ1-2%çš„å‚æ•°ï¼Œå¤§å¹…é™ä½è®¡ç®—æˆæœ¬\n",
    "- **è¶…å‚æ•°**ï¼šrå’Œalphaæ˜¯æœ€é‡è¦çš„è¶…å‚æ•°\n",
    "- **åº”ç”¨åœºæ™¯**ï¼šé€‚åˆèµ„æºå—é™æˆ–éœ€è¦å¿«é€Ÿè¿­ä»£çš„åœºæ™¯\n",
    "\n",
    "## ğŸš€ è¿›é˜¶æ–¹å‘\n",
    "\n",
    "1. å°è¯•ä¸åŒçš„LoRAé…ç½®ï¼ˆr, alpha, target_modulesï¼‰\n",
    "2. ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†\n",
    "3. å°è¯•QLoRAï¼ˆé‡åŒ–LoRAï¼‰\n",
    "4. éƒ¨ç½²ä¸ºAPIæœåŠ¡\n",
    "\n",
    "## ğŸ“š å‚è€ƒèµ„æº\n",
    "\n",
    "- [LoRAè®ºæ–‡](https://arxiv.org/abs/2106.09685)\n",
    "- [å®Œæ•´æ–‡æ¡£](../docs/02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/02-LoRAå¾®è°ƒå®è·µ.md)\n",
    "- [ä»£ç ç¤ºä¾‹](../code/02-fine-tuning/lora/)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆæœ¬æ•™ç¨‹ï¼**\n",
    "\n",
    "å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨GitHubä¸ŠæIssueã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
