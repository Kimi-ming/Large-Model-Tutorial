{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç«¯åˆ°ç«¯è§†è§‰AIé¡¹ç›®å®æˆ˜\n",
    "\n",
    "## ğŸ“‹ æ•™ç¨‹æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹å°†å¸¦æ‚¨æ„å»ºä¸€ä¸ªå®Œæ•´çš„è§†è§‰AIåº”ç”¨,æ¶µç›–ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹ã€‚\n",
    "\n",
    "**é¡¹ç›®ç›®æ ‡**: æ„å»ºä¸€ä¸ªæ™ºèƒ½å›¾åƒåˆ†æç³»ç»Ÿ,èƒ½å¤Ÿ:\n",
    "- ğŸ“¸ è‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°\n",
    "- ğŸ” å›ç­”å…³äºå›¾åƒçš„é—®é¢˜\n",
    "- ğŸ“ æå–å›¾åƒä¸­çš„æ–‡å­—(OCR)\n",
    "- ğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬æ•™ç¨‹å,æ‚¨å°†å­¦ä¼š:\n",
    "1. âœ… è®¾è®¡ç«¯åˆ°ç«¯çš„è§†è§‰AIåº”ç”¨æ¶æ„\n",
    "2. âœ… é›†æˆå¤šä¸ªè§†è§‰è¯­è¨€æ¨¡å‹\n",
    "3. âœ… å¤„ç†å®é™…ä¸šåŠ¡åœºæ™¯çš„æ•°æ®\n",
    "4. âœ… æ„å»ºæ¨¡å‹ç®¡é“(Pipeline)\n",
    "5. âœ… å®ç°æ‰¹é‡å¤„ç†å’Œç»“æœä¿å­˜\n",
    "6. âœ… è¿›è¡Œæ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š å‰ç½®è¦æ±‚\n",
    "\n",
    "- Python 3.8+\n",
    "- PyTorch 2.0+\n",
    "- Transformers 4.30+\n",
    "- 16GB+ GPUæ˜¾å­˜(æ¨è)\n",
    "- ç†è§£è§†è§‰è¯­è¨€æ¨¡å‹åŸºç¡€\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– æ•™ç¨‹ç»“æ„\n",
    "\n",
    "1. **é¡¹ç›®è§„åˆ’** - éœ€æ±‚åˆ†æå’Œæ¶æ„è®¾è®¡\n",
    "2. **ç¯å¢ƒå‡†å¤‡** - ä¾èµ–å®‰è£…å’Œé…ç½®\n",
    "3. **æ•°æ®å‡†å¤‡** - æµ‹è¯•æ•°æ®é›†æ„å»º\n",
    "4. **æ¨¡å‹åŠ è½½** - å¤šæ¨¡å‹é›†æˆ\n",
    "5. **åŠŸèƒ½å®ç°** - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘\n",
    "6. **æ‰¹é‡å¤„ç†** - å¹¶å‘å’Œä¼˜åŒ–\n",
    "7. **ç»“æœåˆ†æ** - å¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ\n",
    "8. **éƒ¨ç½²å‡†å¤‡** - æ‰“åŒ…å’Œéƒ¨ç½²å»ºè®®\n",
    "\n",
    "**é¢„è®¡å®Œæˆæ—¶é—´**: 60-90åˆ†é’Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. é¡¹ç›®è§„åˆ’\n",
    "\n",
    "### 1.1 éœ€æ±‚åˆ†æ\n",
    "\n",
    "**åº”ç”¨åœºæ™¯**: ç”µå•†å›¾åƒæ™ºèƒ½åˆ†æç³»ç»Ÿ\n",
    "\n",
    "**æ ¸å¿ƒéœ€æ±‚**:\n",
    "1. è‡ªåŠ¨ç”Ÿæˆå•†å“å›¾åƒæè¿°\n",
    "2. æ”¯æŒå•†å“å±æ€§é—®ç­”(é¢œè‰²ã€å°ºå¯¸ç­‰)\n",
    "3. æå–å•†å“å›¾ç‰‡ä¸­çš„æ–‡å­—ä¿¡æ¯\n",
    "4. ç”Ÿæˆç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š\n",
    "\n",
    "### 1.2 ç³»ç»Ÿæ¶æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¶æ„è®¾è®¡\n",
    "architecture = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚      è§†è§‰AIåˆ†æç³»ç»Ÿæ¶æ„               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "è¾“å…¥å±‚:\n",
    "  â”œâ”€ å›¾åƒæ–‡ä»¶ (JPEG/PNG)\n",
    "  â”œâ”€ æ‰¹é‡ç›®å½•\n",
    "  â””â”€ URLåˆ—è¡¨\n",
    "\n",
    "å¤„ç†å±‚:\n",
    "  â”œâ”€ å›¾åƒé¢„å¤„ç†æ¨¡å—\n",
    "  â”‚   â”œâ”€ æ ¼å¼éªŒè¯\n",
    "  â”‚   â”œâ”€ å°ºå¯¸è°ƒæ•´\n",
    "  â”‚   â””â”€ è´¨é‡æ£€æŸ¥\n",
    "  â”‚\n",
    "  â”œâ”€ æ¨¡å‹æ¨ç†æ¨¡å—\n",
    "  â”‚   â”œâ”€ InternVL (ä¸»æ¨¡å‹)\n",
    "  â”‚   â”œâ”€ Qwen-VL (å¤‡ç”¨æ¨¡å‹)\n",
    "  â”‚   â””â”€ æ¨¡å‹é€‰æ‹©å™¨\n",
    "  â”‚\n",
    "  â””â”€ ä»»åŠ¡è°ƒåº¦æ¨¡å—\n",
    "      â”œâ”€ å¹¶å‘æ§åˆ¶\n",
    "      â”œâ”€ é”™è¯¯å¤„ç†\n",
    "      â””â”€ è¿›åº¦è·Ÿè¸ª\n",
    "\n",
    "è¾“å‡ºå±‚:\n",
    "  â”œâ”€ JSONç»“æœ\n",
    "  â”œâ”€ å¯è§†åŒ–æŠ¥å‘Š\n",
    "  â””â”€ ç»Ÿè®¡åˆ†æ\n",
    "\"\"\"\n",
    "\n",
    "print(architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "### 2.1 å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…æ ¸å¿ƒä¾èµ–\n",
    "!pip install torch torchvision transformers pillow requests matplotlib pandas tqdm -q\n",
    "\n",
    "print(\"âœ… ä¾èµ–å®‰è£…å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 å¯¼å…¥åº“å’Œé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer, AutoProcessor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ä¸­æ–‡å­—ä½“é…ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… åº“å¯¼å…¥å®Œæˆ\")\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 é¡¹ç›®é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProjectConfig:\n",
    "    \"\"\"é¡¹ç›®é…ç½®\"\"\"\n",
    "    # æ¨¡å‹é…ç½®\n",
    "    primary_model: str = \"OpenGVLab/InternVL2-8B\"  # ä¸»æ¨¡å‹\n",
    "    fallback_model: str = \"Qwen/Qwen-VL-Chat\"     # å¤‡ç”¨æ¨¡å‹\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype: str = \"bfloat16\" if torch.cuda.is_available() else \"float32\"\n",
    "    \n",
    "    # å¤„ç†é…ç½®\n",
    "    batch_size: int = 4\n",
    "    max_workers: int = 2\n",
    "    timeout: int = 60  # ç§’\n",
    "    \n",
    "    # è·¯å¾„é…ç½®\n",
    "    data_dir: str = \"./demo_images\"\n",
    "    output_dir: str = \"./outputs\"\n",
    "    report_dir: str = \"./reports\"\n",
    "    \n",
    "    # ä»»åŠ¡é…ç½®\n",
    "    tasks: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.tasks is None:\n",
    "            self.tasks = [\"caption\", \"vqa\", \"ocr\"]\n",
    "        \n",
    "        # åˆ›å»ºç›®å½•\n",
    "        for dir_path in [self.data_dir, self.output_dir, self.report_dir]:\n",
    "            Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# åˆå§‹åŒ–é…ç½®\n",
    "config = ProjectConfig()\n",
    "print(\"âœ… é¡¹ç›®é…ç½®å®Œæˆ\")\n",
    "print(f\"è®¾å¤‡: {config.device}\")\n",
    "print(f\"ç²¾åº¦: {config.torch_dtype}\")\n",
    "print(f\"ä»»åŠ¡: {', '.join(config.tasks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®å‡†å¤‡\n",
    "\n",
    "### 3.1 å‡†å¤‡æµ‹è¯•å›¾åƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è½½ç¤ºä¾‹å›¾åƒ\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# ç¤ºä¾‹å›¾åƒURLåˆ—è¡¨\n",
    "sample_images = [\n",
    "    {\n",
    "        \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\",\n",
    "        \"name\": \"product_1.jpg\",\n",
    "        \"category\": \"food\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg\",\n",
    "        \"name\": \"product_2.jpg\",\n",
    "        \"category\": \"vehicle\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def download_image(url: str, save_path: str) -> bool:\n",
    "    \"\"\"ä¸‹è½½å›¾åƒ\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(save_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¸‹è½½å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "# ä¸‹è½½ç¤ºä¾‹å›¾åƒ\n",
    "print(\"ğŸ“¥ ä¸‹è½½æµ‹è¯•å›¾åƒ...\")\n",
    "for img_info in tqdm(sample_images, desc=\"ä¸‹è½½å›¾åƒ\"):\n",
    "    save_path = os.path.join(config.data_dir, img_info[\"name\"])\n",
    "    if not os.path.exists(save_path):\n",
    "        download_image(img_info[\"url\"], save_path)\n",
    "\n",
    "# æ£€æŸ¥å›¾åƒ\n",
    "image_files = list(Path(config.data_dir).glob(\"*.jpg\")) + list(Path(config.data_dir).glob(\"*.png\"))\n",
    "print(f\"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ\")\n",
    "\n",
    "# æ˜¾ç¤ºç¤ºä¾‹å›¾åƒ\n",
    "if image_files:\n",
    "    fig, axes = plt.subplots(1, min(3, len(image_files)), figsize=(15, 5))\n",
    "    if len(image_files) == 1:\n",
    "        axes = [axes]\n",
    "    for idx, img_path in enumerate(image_files[:3]):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(img_path.name)\n",
    "        axes[idx].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ•°æ®ç»“æ„å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageAnalysisResult:\n",
    "    \"\"\"å›¾åƒåˆ†æç»“æœ\"\"\"\n",
    "    image_path: str\n",
    "    timestamp: str\n",
    "    \n",
    "    # ä»»åŠ¡ç»“æœ\n",
    "    caption: Optional[str] = None\n",
    "    vqa_results: Optional[Dict[str, str]] = None\n",
    "    ocr_text: Optional[str] = None\n",
    "    \n",
    "    # å…ƒæ•°æ®\n",
    "    image_size: Optional[Tuple[int, int]] = None\n",
    "    processing_time: Optional[float] = None\n",
    "    model_used: Optional[str] = None\n",
    "    success: bool = True\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"è½¬æ¢ä¸ºå­—å…¸\"\"\"\n",
    "        return asdict(self)\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"è½¬æ¢ä¸ºJSON\"\"\"\n",
    "        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… æ•°æ®ç»“æ„å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ¨¡å‹åŠ è½½\n",
    "\n",
    "### 4.1 æ¨¡å‹ç®¡ç†å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"æ¨¡å‹ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ProjectConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        self.model_name = None\n",
    "    \n",
    "    def load_model(self, model_name: Optional[str] = None) -> bool:\n",
    "        \"\"\"åŠ è½½æ¨¡å‹\"\"\"\n",
    "        model_name = model_name or self.config.primary_model\n",
    "        \n",
    "        try:\n",
    "            print(f\"ğŸ”„ åŠ è½½æ¨¡å‹: {model_name}\")\n",
    "            \n",
    "            # è®¾ç½®ç²¾åº¦\n",
    "            dtype = self._get_dtype()\n",
    "            \n",
    "            # åŠ è½½æ¨¡å‹\n",
    "            if \"InternVL\" in model_name:\n",
    "                from transformers import AutoModelForImageTextToText\n",
    "                self.model = AutoModelForImageTextToText.from_pretrained(\n",
    "                    model_name,\n",
    "                    torch_dtype=dtype,\n",
    "                    trust_remote_code=True\n",
    "                ).to(self.config.device)\n",
    "                self.processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "            else:\n",
    "                # Qwen-VL\n",
    "                from transformers import AutoModelForCausalLM\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    torch_dtype=dtype,\n",
    "                    trust_remote_code=True\n",
    "                ).to(self.config.device)\n",
    "                self.processor = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "            \n",
    "            self.model.eval()\n",
    "            self.model_name = model_name\n",
    "            \n",
    "            print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _get_dtype(self) -> torch.dtype:\n",
    "        \"\"\"è·å–æ•°æ®ç±»å‹\"\"\"\n",
    "        if self.config.device == \"cpu\":\n",
    "            return torch.float32\n",
    "        \n",
    "        if self.config.torch_dtype == \"bfloat16\":\n",
    "            if torch.cuda.is_bf16_supported():\n",
    "                return torch.bfloat16\n",
    "            else:\n",
    "                return torch.float16\n",
    "        elif self.config.torch_dtype == \"float16\":\n",
    "            return torch.float16\n",
    "        else:\n",
    "            return torch.float32\n",
    "    \n",
    "    def generate(self, image_path: str, prompt: str) -> str:\n",
    "        \"\"\"ç”Ÿæˆæ–‡æœ¬\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            if \"InternVL\" in self.model_name:\n",
    "                # InternVLæ¨ç†\n",
    "                inputs = self.processor(images=image, text=prompt, return_tensors=\"pt\")\n",
    "                inputs = {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model.generate(**inputs, max_new_tokens=512)\n",
    "                \n",
    "                result = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "            else:\n",
    "                # Qwen-VLæ¨ç†\n",
    "                query = self.processor.from_list_format([\n",
    "                    {'image': image_path},\n",
    "                    {'text': prompt}\n",
    "                ])\n",
    "                \n",
    "                inputs = self.processor(query, return_tensors='pt')\n",
    "                inputs = inputs.to(self.config.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model.generate(**inputs, max_new_tokens=512)\n",
    "                \n",
    "                result = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "print(\"âœ… æ¨¡å‹ç®¡ç†å™¨å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨\n",
    "model_manager = ModelManager(config)\n",
    "\n",
    "# åŠ è½½ä¸»æ¨¡å‹\n",
    "success = model_manager.load_model()\n",
    "\n",
    "if not success:\n",
    "    print(\"âš ï¸ ä¸»æ¨¡å‹åŠ è½½å¤±è´¥,å°è¯•å¤‡ç”¨æ¨¡å‹...\")\n",
    "    success = model_manager.load_model(config.fallback_model)\n",
    "\n",
    "if success:\n",
    "    print(f\"âœ… ä½¿ç”¨æ¨¡å‹: {model_manager.model_name}\")\n",
    "else:\n",
    "    print(\"âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥,è¯·æ£€æŸ¥é…ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. åŠŸèƒ½å®ç°\n",
    "\n",
    "### 5.1 æ ¸å¿ƒåˆ†æå¼•æ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalysisEngine:\n",
    "    \"\"\"å›¾åƒåˆ†æå¼•æ“\"\"\"\n",
    "    \n",
    "    def __init__(self, model_manager: ModelManager, config: ProjectConfig):\n",
    "        self.model_manager = model_manager\n",
    "        self.config = config\n",
    "    \n",
    "    def analyze_image(self, image_path: str) -> ImageAnalysisResult:\n",
    "        \"\"\"åˆ†æå•å¼ å›¾åƒ\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        result = ImageAnalysisResult(\n",
    "            image_path=str(image_path),\n",
    "            timestamp=start_time.isoformat()\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # è·å–å›¾åƒä¿¡æ¯\n",
    "            img = Image.open(image_path)\n",
    "            result.image_size = img.size\n",
    "            \n",
    "            # æ‰§è¡Œå„é¡¹ä»»åŠ¡\n",
    "            if \"caption\" in self.config.tasks:\n",
    "                result.caption = self._generate_caption(image_path)\n",
    "            \n",
    "            if \"vqa\" in self.config.tasks:\n",
    "                result.vqa_results = self._visual_question_answering(image_path)\n",
    "            \n",
    "            if \"ocr\" in self.config.tasks:\n",
    "                result.ocr_text = self._ocr_recognition(image_path)\n",
    "            \n",
    "            result.model_used = self.model_manager.model_name\n",
    "            result.success = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            result.success = False\n",
    "            result.error_message = str(e)\n",
    "            print(f\"âŒ åˆ†æå¤±è´¥: {e}\")\n",
    "        \n",
    "        # è®¡ç®—å¤„ç†æ—¶é—´\n",
    "        end_time = datetime.now()\n",
    "        result.processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _generate_caption(self, image_path: str) -> str:\n",
    "        \"\"\"ç”Ÿæˆå›¾åƒæè¿°\"\"\"\n",
    "        prompt = \"Please provide a detailed description of this image.\"\n",
    "        return self.model_manager.generate(image_path, prompt)\n",
    "    \n",
    "    def _visual_question_answering(self, image_path: str) -> Dict[str, str]:\n",
    "        \"\"\"è§†è§‰é—®ç­”\"\"\"\n",
    "        questions = [\n",
    "            \"What is the main subject of this image?\",\n",
    "            \"What colors are prominent in this image?\",\n",
    "            \"Describe the setting or environment.\"\n",
    "        ]\n",
    "        \n",
    "        results = {}\n",
    "        for question in questions:\n",
    "            answer = self.model_manager.generate(image_path, question)\n",
    "            results[question] = answer\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _ocr_recognition(self, image_path: str) -> str:\n",
    "        \"\"\"OCRæ–‡å­—è¯†åˆ«\"\"\"\n",
    "        prompt = \"Extract all visible text from this image.\"\n",
    "        return self.model_manager.generate(image_path, prompt)\n",
    "\n",
    "print(\"âœ… åˆ†æå¼•æ“å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 å•å›¾åƒåˆ†æç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–åˆ†æå¼•æ“\n",
    "analysis_engine = ImageAnalysisEngine(model_manager, config)\n",
    "\n",
    "# åˆ†æç¬¬ä¸€å¼ å›¾åƒ\n",
    "if image_files:\n",
    "    print(f\"ğŸ” åˆ†æå›¾åƒ: {image_files[0].name}\")\n",
    "    result = analysis_engine.analyze_image(str(image_files[0]))\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    print(\"\\nğŸ“Š åˆ†æç»“æœ:\")\n",
    "    print(f\"å›¾åƒå°ºå¯¸: {result.image_size}\")\n",
    "    print(f\"å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’\")\n",
    "    print(f\"ä½¿ç”¨æ¨¡å‹: {result.model_used}\")\n",
    "    print(f\"\\næè¿°: {result.caption}\")\n",
    "    print(f\"\\nOCR: {result.ocr_text}\")\n",
    "    \n",
    "    if result.vqa_results:\n",
    "        print(\"\\né—®ç­”ç»“æœ:\")\n",
    "        for question, answer in result.vqa_results.items():\n",
    "            print(f\"Q: {question}\")\n",
    "            print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ‰¹é‡å¤„ç†\n",
    "\n",
    "### 6.1 æ‰¹å¤„ç†ç®¡ç†å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchProcessor:\n",
    "    \"\"\"æ‰¹å¤„ç†ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_engine: ImageAnalysisEngine, config: ProjectConfig):\n",
    "        self.analysis_engine = analysis_engine\n",
    "        self.config = config\n",
    "        self.results: List[ImageAnalysisResult] = []\n",
    "    \n",
    "    def process_directory(self, directory: str) -> List[ImageAnalysisResult]:\n",
    "        \"\"\"å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ\"\"\"\n",
    "        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶\n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "            image_files.extend(Path(directory).glob(ext))\n",
    "        \n",
    "        print(f\"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ\")\n",
    "        \n",
    "        # æ‰¹é‡å¤„ç†\n",
    "        self.results = []\n",
    "        for img_path in tqdm(image_files, desc=\"å¤„ç†å›¾åƒ\"):\n",
    "            result = self.analysis_engine.analyze_image(str(img_path))\n",
    "            self.results.append(result)\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def save_results(self, output_path: Optional[str] = None):\n",
    "        \"\"\"ä¿å­˜ç»“æœ\"\"\"\n",
    "        if output_path is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = os.path.join(self.config.output_dir, f\"results_{timestamp}.json\")\n",
    "        \n",
    "        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼\n",
    "        results_dict = [result.to_dict() for result in self.results]\n",
    "        \n",
    "        # ä¿å­˜JSON\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results_dict, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    def generate_summary(self) -> Dict:\n",
    "        \"\"\"ç”Ÿæˆç»Ÿè®¡æ‘˜è¦\"\"\"\n",
    "        total = len(self.results)\n",
    "        success = sum(1 for r in self.results if r.success)\n",
    "        failed = total - success\n",
    "        avg_time = sum(r.processing_time for r in self.results if r.processing_time) / total if total > 0 else 0\n",
    "        \n",
    "        summary = {\n",
    "            \"total_images\": total,\n",
    "            \"successful\": success,\n",
    "            \"failed\": failed,\n",
    "            \"success_rate\": f\"{(success/total*100):.2f}%\" if total > 0 else \"0%\",\n",
    "            \"average_processing_time\": f\"{avg_time:.2f}s\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "print(\"âœ… æ‰¹å¤„ç†ç®¡ç†å™¨å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 æ‰§è¡Œæ‰¹é‡å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–æ‰¹å¤„ç†å™¨\n",
    "batch_processor = BatchProcessor(analysis_engine, config)\n",
    "\n",
    "# å¤„ç†æ‰€æœ‰å›¾åƒ\n",
    "results = batch_processor.process_directory(config.data_dir)\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "output_file = batch_processor.save_results()\n",
    "\n",
    "# æ˜¾ç¤ºæ‘˜è¦\n",
    "summary = batch_processor.generate_summary()\n",
    "print(\"\\nğŸ“Š å¤„ç†æ‘˜è¦:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç»“æœåˆ†æ\n",
    "\n",
    "### 7.1 æ•°æ®å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è½¬æ¢ä¸ºDataFrame\n",
    "df = pd.DataFrame([r.to_dict() for r in results])\n",
    "\n",
    "# ç»Ÿè®¡å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. æˆåŠŸç‡\n",
    "success_counts = df['success'].value_counts()\n",
    "axes[0, 0].pie(success_counts, labels=['æˆåŠŸ', 'å¤±è´¥'], autopct='%1.1f%%', colors=['#90EE90', '#FFB6C1'])\n",
    "axes[0, 0].set_title('å¤„ç†æˆåŠŸç‡')\n",
    "\n",
    "# 2. å¤„ç†æ—¶é—´åˆ†å¸ƒ\n",
    "df['processing_time'].hist(bins=20, ax=axes[0, 1], color='skyblue', edgecolor='black')\n",
    "axes[0, 1].set_title('å¤„ç†æ—¶é—´åˆ†å¸ƒ')\n",
    "axes[0, 1].set_xlabel('æ—¶é—´(ç§’)')\n",
    "axes[0, 1].set_ylabel('é¢‘æ¬¡')\n",
    "\n",
    "# 3. å›¾åƒå°ºå¯¸åˆ†å¸ƒ\n",
    "if 'image_size' in df.columns and df['image_size'].notna().any():\n",
    "    sizes = df['image_size'].dropna()\n",
    "    widths = [s[0] for s in sizes]\n",
    "    heights = [s[1] for s in sizes]\n",
    "    axes[1, 0].scatter(widths, heights, alpha=0.6, c='coral')\n",
    "    axes[1, 0].set_title('å›¾åƒå°ºå¯¸åˆ†å¸ƒ')\n",
    "    axes[1, 0].set_xlabel('å®½åº¦')\n",
    "    axes[1, 0].set_ylabel('é«˜åº¦')\n",
    "\n",
    "# 4. å¤„ç†æ—¶é—´è¶‹åŠ¿\n",
    "axes[1, 1].plot(range(len(df)), df['processing_time'], marker='o', color='green')\n",
    "axes[1, 1].set_title('å¤„ç†æ—¶é—´è¶‹åŠ¿')\n",
    "axes[1, 1].set_xlabel('å›¾åƒç´¢å¼•')\n",
    "axes[1, 1].set_ylabel('æ—¶é—´(ç§’)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.report_dir, 'analysis_visualization.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… å¯è§†åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 ç”ŸæˆæŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_report(results: List[ImageAnalysisResult], summary: Dict, output_path: str):\n",
    "    \"\"\"ç”ŸæˆHTMLæŠ¥å‘Š\"\"\"\n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>è§†è§‰AIåˆ†ææŠ¥å‘Š</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "            h1 {{ color: #333; }}\n",
    "            .summary {{ background: #f0f0f0; padding: 15px; border-radius: 5px; margin: 20px 0; }}\n",
    "            .result {{ border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px; }}\n",
    "            .success {{ background: #e8f5e9; }}\n",
    "            .failed {{ background: #ffebee; }}\n",
    "            table {{ border-collapse: collapse; width: 100%; }}\n",
    "            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "            th {{ background-color: #4CAF50; color: white; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>ğŸ¨ è§†è§‰AIåˆ†ææŠ¥å‘Š</h1>\n",
    "        \n",
    "        <div class=\"summary\">\n",
    "            <h2>ğŸ“Š ç»Ÿè®¡æ‘˜è¦</h2>\n",
    "            <table>\n",
    "                <tr><th>æŒ‡æ ‡</th><th>æ•°å€¼</th></tr>\n",
    "                <tr><td>æ€»å›¾åƒæ•°</td><td>{summary['total_images']}</td></tr>\n",
    "                <tr><td>æˆåŠŸå¤„ç†</td><td>{summary['successful']}</td></tr>\n",
    "                <tr><td>å¤±è´¥æ•°é‡</td><td>{summary['failed']}</td></tr>\n",
    "                <tr><td>æˆåŠŸç‡</td><td>{summary['success_rate']}</td></tr>\n",
    "                <tr><td>å¹³å‡å¤„ç†æ—¶é—´</td><td>{summary['average_processing_time']}</td></tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        \n",
    "        <h2>ğŸ“ è¯¦ç»†ç»“æœ</h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx, result in enumerate(results, 1):\n",
    "        status_class = \"success\" if result.success else \"failed\"\n",
    "        status_text = \"âœ… æˆåŠŸ\" if result.success else \"âŒ å¤±è´¥\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "        <div class=\"result {status_class}\">\n",
    "            <h3>å›¾åƒ #{idx}: {os.path.basename(result.image_path)}</h3>\n",
    "            <p><strong>çŠ¶æ€:</strong> {status_text}</p>\n",
    "            <p><strong>å°ºå¯¸:</strong> {result.image_size}</p>\n",
    "            <p><strong>å¤„ç†æ—¶é—´:</strong> {result.processing_time:.2f}ç§’</p>\n",
    "            <p><strong>ä½¿ç”¨æ¨¡å‹:</strong> {result.model_used}</p>\n",
    "            \n",
    "            {f'<p><strong>æè¿°:</strong> {result.caption}</p>' if result.caption else ''}\n",
    "            {f'<p><strong>OCR:</strong> {result.ocr_text}</p>' if result.ocr_text else ''}\n",
    "            {f'<p><strong>é”™è¯¯:</strong> {result.error_message}</p>' if result.error_message else ''}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html)\n",
    "    \n",
    "    print(f\"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}\")\n",
    "\n",
    "# ç”ŸæˆæŠ¥å‘Š\n",
    "report_path = os.path.join(config.report_dir, 'analysis_report.html')\n",
    "generate_html_report(results, summary, report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. éƒ¨ç½²å‡†å¤‡\n",
    "\n",
    "### 8.1 å¯¼å‡ºé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºé¡¹ç›®é…ç½®\n",
    "config_export = asdict(config)\n",
    "config_path = os.path.join(config.output_dir, 'project_config.json')\n",
    "\n",
    "with open(config_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_export, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… é…ç½®å·²å¯¼å‡º: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 éƒ¨ç½²å»ºè®®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_guide = \"\"\"\n",
    "## ğŸš€ éƒ¨ç½²å»ºè®®\n",
    "\n",
    "### 1. Dockeréƒ¨ç½²\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime\n",
    "\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### 2. APIæœåŠ¡\n",
    "\n",
    "ä½¿ç”¨FastAPIæ„å»ºREST API:\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/analyze\")\n",
    "async def analyze_image(file: UploadFile = File(...)):\n",
    "    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶\n",
    "    # æ‰§è¡Œåˆ†æ\n",
    "    # è¿”å›ç»“æœ\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 3. æ€§èƒ½ä¼˜åŒ–\n",
    "\n",
    "- ä½¿ç”¨æ¨¡å‹é‡åŒ–(INT8/FP16)\n",
    "- å®ç°è¯·æ±‚æ‰¹å¤„ç†\n",
    "- æ·»åŠ ç»“æœç¼“å­˜\n",
    "- ä½¿ç”¨å¼‚æ­¥å¤„ç†\n",
    "\n",
    "### 4. ç›‘æ§å’Œæ—¥å¿—\n",
    "\n",
    "- æ·»åŠ PrometheusæŒ‡æ ‡\n",
    "- å®ç°ç»“æ„åŒ–æ—¥å¿—\n",
    "- è®¾ç½®å‘Šè­¦æœºåˆ¶\n",
    "\n",
    "### 5. æ‰©å±•å»ºè®®\n",
    "\n",
    "- æ·»åŠ ç”¨æˆ·è®¤è¯\n",
    "- å®ç°ä»»åŠ¡é˜Ÿåˆ—(Celery)\n",
    "- æ”¯æŒå¤šæ¨¡å‹çƒ­åˆ‡æ¢\n",
    "- æ·»åŠ Webç•Œé¢\n",
    "\"\"\"\n",
    "\n",
    "print(deployment_guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ€»ç»“\n",
    "\n",
    "### 9.1 é¡¹ç›®æˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "ğŸ‰ ç«¯åˆ°ç«¯è§†è§‰AIé¡¹ç›®å®Œæˆ!\n",
    "\n",
    "âœ… å®Œæˆå†…å®¹:\n",
    "1. å®Œæ•´çš„é¡¹ç›®æ¶æ„è®¾è®¡\n",
    "2. å¤šæ¨¡å‹é›†æˆå’Œç®¡ç†\n",
    "3. æ ¸å¿ƒä¸šåŠ¡åŠŸèƒ½å®ç°\n",
    "4. æ‰¹é‡å¤„ç†å’Œä¼˜åŒ–\n",
    "5. ç»“æœå¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ\n",
    "6. éƒ¨ç½²æ–¹æ¡ˆå’Œå»ºè®®\n",
    "\n",
    "ğŸ“Š é¡¹ç›®ç»Ÿè®¡:\n",
    "- ä»£ç æ¨¡å—: 5ä¸ªæ ¸å¿ƒç±»\n",
    "- æ”¯æŒä»»åŠ¡: å›¾åƒæè¿°ã€VQAã€OCR\n",
    "- è¾“å‡ºæ ¼å¼: JSONã€HTMLã€å¯è§†åŒ–å›¾è¡¨\n",
    "\n",
    "ğŸš€ ä¸‹ä¸€æ­¥:\n",
    "1. æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´é…ç½®\n",
    "2. æ·»åŠ æ›´å¤šä¸šåŠ¡é€»è¾‘\n",
    "3. ä¼˜åŒ–æ€§èƒ½å’Œå¯é æ€§\n",
    "4. è¿›è¡Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²\n",
    "\n",
    "ğŸ’¡ å­¦ä¹ è¦ç‚¹:\n",
    "- æ¨¡å—åŒ–è®¾è®¡å’Œä»£ç ç»„ç»‡\n",
    "- é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•\n",
    "- æ‰¹å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–\n",
    "- ç»“æœå¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:\")\n",
    "print(f\"- åˆ†æç»“æœ: {output_file}\")\n",
    "print(f\"- HTMLæŠ¥å‘Š: {report_path}\")\n",
    "print(f\"- å¯è§†åŒ–å›¾è¡¨: {os.path.join(config.report_dir, 'analysis_visualization.png')}\")\n",
    "print(f\"- é¡¹ç›®é…ç½®: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 ç»ƒä¹ ä»»åŠ¡\n",
    "\n",
    "å®Œæˆä»¥ä¸‹ç»ƒä¹ ,å·©å›ºæ‰€å­¦çŸ¥è¯†:\n",
    "\n",
    "1. **åŸºç¡€ç»ƒä¹ **:\n",
    "   - æ·»åŠ æ–°çš„åˆ†æä»»åŠ¡(å¦‚æƒ…æ„Ÿåˆ†æ)\n",
    "   - è‡ªå®šä¹‰VQAé—®é¢˜åˆ—è¡¨\n",
    "   - ä¿®æ”¹HTMLæŠ¥å‘Šæ ·å¼\n",
    "\n",
    "2. **è¿›é˜¶ç»ƒä¹ **:\n",
    "   - å®ç°å¤šæ¨¡å‹ç»“æœå¯¹æ¯”\n",
    "   - æ·»åŠ å¼‚æ­¥æ‰¹å¤„ç†\n",
    "   - å®ç°ç»“æœç¼“å­˜æœºåˆ¶\n",
    "\n",
    "3. **é«˜çº§ç»ƒä¹ **:\n",
    "   - æ„å»ºFastAPIæœåŠ¡\n",
    "   - æ·»åŠ Webå‰ç«¯ç•Œé¢\n",
    "   - å®ç°åˆ†å¸ƒå¼å¤„ç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š å‚è€ƒèµ„æº\n",
    "\n",
    "- [Transformersæ–‡æ¡£](https://huggingface.co/docs/transformers)\n",
    "- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)\n",
    "- [Dockeræ–‡æ¡£](https://docs.docker.com/)\n",
    "- [é¡¹ç›®å®Œæ•´ä»£ç ](../code/)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“ æ­å–œå®Œæˆç«¯åˆ°ç«¯é¡¹ç›®å®æˆ˜æ•™ç¨‹!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
