#!/usr/bin/env python3
"""
ç”ŸæˆJupyter Notebookæ•™ç¨‹

æ­¤è„šæœ¬è‡ªåŠ¨ç”ŸæˆLoRAå’Œå…¨å‚æ•°å¾®è°ƒçš„Notebookæ•™ç¨‹
"""

import json
import os
from pathlib import Path


def create_lora_notebook():
    """åˆ›å»ºLoRAå¾®è°ƒNotebook"""
    
    cells = []
    
    # æ ‡é¢˜å’Œä»‹ç»
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# ğŸ¯ LoRAå¾®è°ƒå®æˆ˜æ•™ç¨‹\n",
            "\n",
            "**æ¬¢è¿æ¥åˆ°LoRAå¾®è°ƒå®æˆ˜æ•™ç¨‹ï¼**\n",
            "\n",
            "æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨ä½¿ç”¨LoRAæŠ€æœ¯å¾®è°ƒCLIPæ¨¡å‹ï¼Œå®ŒæˆçŠ¬ç§è¯†åˆ«ä»»åŠ¡ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
            "\n",
            "- âœ… ç†è§£LoRAå¾®è°ƒçš„åŸç†å’Œä¼˜åŠ¿\n",
            "- âœ… æŒæ¡æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†æµç¨‹\n",
            "- âœ… å­¦ä¼šé…ç½®å’Œè®­ç»ƒLoRAæ¨¡å‹\n",
            "- âœ… è¯„ä¼°å’Œä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹\n",
            "\n",
            "---\n",
            "\n",
            "## â±ï¸ é¢„è®¡å­¦ä¹ æ—¶é—´\n",
            "\n",
            "- å®Œæ•´è¿è¡Œï¼šçº¦ 30-45 åˆ†é’Ÿ\n",
            "- å¿«é€Ÿæµè§ˆï¼šçº¦ 10-15 åˆ†é’Ÿ\n",
            "\n",
            "---\n",
            "\n",
            "## ğŸ¯ ä»»åŠ¡è¯´æ˜\n",
            "\n",
            "**ä»»åŠ¡**ï¼šçŠ¬ç§è¯†åˆ«\n",
            "\n",
            "- **æ•°æ®é›†**ï¼šStanford Dogsï¼ˆ10ä¸ªçŠ¬ç§ï¼‰\n",
            "- **åŸºç¡€æ¨¡å‹**ï¼šCLIP-ViT-B/32\n",
            "- **å¾®è°ƒæ–¹æ³•**ï¼šLoRAï¼ˆr=8ï¼‰\n",
            "\n",
            "---\n",
            "\n",
            "## ğŸ“Œ å‰ç½®è¦æ±‚\n",
            "\n",
            "```bash\n",
            "# 1. å‡†å¤‡æ•°æ®\n",
            "python scripts/prepare_dog_dataset.py --output_dir data/dogs --num_classes 10\n",
            "\n",
            "# 2. å®‰è£…ä¾èµ–\n",
            "pip install jupyter torch transformers peft pillow matplotlib tqdm scikit-learn seaborn\n",
            "```"
        ]
    })
    
    # å¯¼å…¥åº“
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡\n",
            "\n",
            "## 1.1 å¯¼å…¥å¿…è¦çš„åº“"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# åŸºç¡€åº“\n",
            "import os\n",
            "import sys\n",
            "import random\n",
            "import numpy as np\n",
            "from pathlib import Path\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "# æ·±åº¦å­¦ä¹ \n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "\n",
            "# HuggingFace\n",
            "from transformers import CLIPModel, CLIPProcessor\n",
            "from peft import LoraConfig, get_peft_model\n",
            "\n",
            "# å¯è§†åŒ–\n",
            "import matplotlib.pyplot as plt\n",
            "from PIL import Image\n",
            "from tqdm.auto import tqdm\n",
            "\n",
            "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼\")\n",
            "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
            "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")"
        ]
    })
    
    # é…ç½®å‚æ•°
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## 1.2 é…ç½®å‚æ•°\n",
            "\n",
            "ğŸ’¡ **æç¤º**ï¼šæ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„ç¡¬ä»¶æ¡ä»¶è°ƒæ•´è¿™äº›å‚æ•°"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# é…ç½®ç±»\n",
            "class Config:\n",
            "    # æ¨¡å‹é…ç½®\n",
            "    model_name = \"openai/clip-vit-base-patch32\"\n",
            "    num_classes = 10\n",
            "    \n",
            "    # LoRAé…ç½®\n",
            "    lora_r = 8\n",
            "    lora_alpha = 32\n",
            "    lora_dropout = 0.1\n",
            "    target_modules = [\"q_proj\", \"v_proj\"]\n",
            "    \n",
            "    # è®­ç»ƒé…ç½®\n",
            "    batch_size = 16\n",
            "    num_epochs = 5\n",
            "    learning_rate = 5e-4\n",
            "    \n",
            "    # æ•°æ®å’Œè®¾å¤‡\n",
            "    data_dir = \"../data/dogs\"\n",
            "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
            "    output_dir = \"../outputs/lora_notebook\"\n",
            "\n",
            "config = Config()\n",
            "print(f\"ğŸ“‹ è®¾å¤‡: {config.device}\")\n",
            "print(f\"ğŸ“‹ LoRAç§©: {config.lora_r}\")\n",
            "print(f\"ğŸ“‹ æ‰¹æ¬¡å¤§å°: {config.batch_size}\")"
        ]
    })
    
    # æ•°æ®å‡†å¤‡è¯´æ˜
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬äºŒéƒ¨åˆ†ï¼šä½¿ç”¨è®­ç»ƒè„šæœ¬\n",
            "\n",
            "## ğŸ’¡ æ¨èæ–¹å¼ï¼šä½¿ç”¨ç°æœ‰çš„è®­ç»ƒè„šæœ¬\n",
            "\n",
            "æˆ‘ä»¬å·²ç»æä¾›äº†å®Œæ•´çš„è®­ç»ƒè„šæœ¬ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š\n",
            "\n",
            "### æ–¹æ³•1ï¼šå‘½ä»¤è¡Œè®­ç»ƒï¼ˆæ¨èï¼‰\n",
            "\n",
            "```bash\n",
            "# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ\n",
            "python code/02-fine-tuning/lora/train.py\n",
            "\n",
            "# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®\n",
            "python code/02-fine-tuning/lora/train.py --config code/02-fine-tuning/lora/config.yaml\n",
            "```\n",
            "\n",
            "### æ–¹æ³•2ï¼šåœ¨Notebookä¸­è°ƒç”¨è„šæœ¬\n",
            "\n",
            "è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼æ¥å¯åŠ¨è®­ç»ƒï¼š"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# åœ¨Notebookä¸­è¿è¡Œè®­ç»ƒè„šæœ¬\n",
            "!python ../code/02-fine-tuning/lora/train.py \\\n",
            "    --config ../code/02-fine-tuning/lora/config.yaml \\\n",
            "    --output_dir {config.output_dir}"
        ]
    })
    
    # è¯„ä¼°æ¨¡å‹
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¯„ä¼°æ¨¡å‹\n",
            "\n",
            "è®­ç»ƒå®Œæˆåï¼Œè®©æˆ‘ä»¬è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼š"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# è¿è¡Œè¯„ä¼°è„šæœ¬\n",
            "!python ../code/02-fine-tuning/lora/evaluate.py \\\n",
            "    --model_path {config.output_dir}/best_model \\\n",
            "    --data_dir {config.data_dir} \\\n",
            "    --output_dir {config.output_dir}/evaluation"
        ]
    })
    
    # æ¨ç†ç¤ºä¾‹
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹æ¨ç†\n",
            "\n",
            "## 4.1 å•å¼ å›¾åƒæ¨ç†"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# é€‰æ‹©ä¸€å¼ æµ‹è¯•å›¾åƒ\n",
            "test_image = \"path/to/your/test/image.jpg\"  # ä¿®æ”¹ä¸ºå®é™…è·¯å¾„\n",
            "\n",
            "# è¿è¡Œæ¨ç†\n",
            "!python ../code/02-fine-tuning/lora/inference.py \\\n",
            "    --model_path {config.output_dir}/best_model \\\n",
            "    --image_path {test_image} \\\n",
            "    --top_k 5"
        ]
    })
    
    # å¯è§†åŒ–ç»“æœ
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## 4.2 æ‰¹é‡æ¨ç†å’Œå¯è§†åŒ–"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# æ‰¹é‡æ¨ç†\n",
            "!python ../code/02-fine-tuning/lora/inference.py \\\n",
            "    --model_path {config.output_dir}/best_model \\\n",
            "    --image_dir {config.data_dir}/test \\\n",
            "    --output_dir {config.output_dir}/predictions \\\n",
            "    --batch_size 32"
        ]
    })
    
    # æ€»ç»“
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ğŸ“ æ€»ç»“\n",
            "\n",
            "## âœ… å®Œæˆçš„å†…å®¹\n",
            "\n",
            "1. âœ… é…ç½®LoRAå¾®è°ƒå‚æ•°\n",
            "2. âœ… è®­ç»ƒCLIPæ¨¡å‹\n",
            "3. âœ… è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
            "4. âœ… è¿›è¡Œæ¨¡å‹æ¨ç†\n",
            "\n",
            "## ğŸ”‘ å…³é”®è¦ç‚¹\n",
            "\n",
            "- **LoRAä¼˜åŠ¿**ï¼šåªè®­ç»ƒ1-2%çš„å‚æ•°ï¼Œå¤§å¹…é™ä½è®¡ç®—æˆæœ¬\n",
            "- **è¶…å‚æ•°**ï¼šrå’Œalphaæ˜¯æœ€é‡è¦çš„è¶…å‚æ•°\n",
            "- **åº”ç”¨åœºæ™¯**ï¼šé€‚åˆèµ„æºå—é™æˆ–éœ€è¦å¿«é€Ÿè¿­ä»£çš„åœºæ™¯\n",
            "\n",
            "## ğŸš€ è¿›é˜¶æ–¹å‘\n",
            "\n",
            "1. å°è¯•ä¸åŒçš„LoRAé…ç½®ï¼ˆr, alpha, target_modulesï¼‰\n",
            "2. ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†\n",
            "3. å°è¯•QLoRAï¼ˆé‡åŒ–LoRAï¼‰\n",
            "4. éƒ¨ç½²ä¸ºAPIæœåŠ¡\n",
            "\n",
            "## ğŸ“š å‚è€ƒèµ„æº\n",
            "\n",
            "- [LoRAè®ºæ–‡](https://arxiv.org/abs/2106.09685)\n",
            "- [å®Œæ•´æ–‡æ¡£](../docs/02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/02-LoRAå¾®è°ƒå®è·µ.md)\n",
            "- [ä»£ç ç¤ºä¾‹](../code/02-fine-tuning/lora/)\n",
            "\n",
            "---\n",
            "\n",
            "**ğŸ‰ æ­å–œå®Œæˆæœ¬æ•™ç¨‹ï¼**\n",
            "\n",
            "å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨GitHubä¸ŠæIssueã€‚"
        ]
    })
    
    # åˆ›å»ºnotebookç»“æ„
    notebook = {
        "cells": cells,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "codemirror_mode": {
                    "name": "ipython",
                    "version": 3
                },
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3",
                "version": "3.8.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    return notebook


def create_full_finetuning_notebook():
    """åˆ›å»ºå…¨å‚æ•°å¾®è°ƒNotebook"""
    
    cells = []
    
    # æ ‡é¢˜
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# ğŸ¯ å…¨å‚æ•°å¾®è°ƒè¿›é˜¶æ•™ç¨‹\n",
            "\n",
            "**æ¬¢è¿æ¥åˆ°å…¨å‚æ•°å¾®è°ƒè¿›é˜¶æ•™ç¨‹ï¼**\n",
            "\n",
            "æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨è¿›è¡ŒCLIPæ¨¡å‹çš„å…¨å‚æ•°å¾®è°ƒï¼Œå¹¶å­¦ä¹ é«˜çº§è®­ç»ƒæŠ€å·§ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
            "\n",
            "- âœ… ç†è§£å…¨å‚æ•°å¾®è°ƒçš„åŸç†\n",
            "- âœ… æŒæ¡åˆ†å±‚å­¦ä¹ ç‡æŠ€æœ¯\n",
            "- âœ… å­¦ä¹ æ¸è¿›è§£å†»ç­–ç•¥\n",
            "- âœ… å¯¹æ¯”LoRAå’Œå…¨å‚æ•°å¾®è°ƒ\n",
            "\n",
            "---\n",
            "\n",
            "## âš ï¸ èµ„æºè¦æ±‚\n",
            "\n",
            "- **GPUæ˜¾å­˜**ï¼šè‡³å°‘ 24GBï¼ˆæ¨è A100 40GBï¼‰\n",
            "- **è®­ç»ƒæ—¶é—´**ï¼šçº¦ 1-2 å°æ—¶\n",
            "- **å‰ç½®çŸ¥è¯†**ï¼šå®ŒæˆLoRAå¾®è°ƒæ•™ç¨‹\n",
            "\n",
            "---\n",
            "\n",
            "## ğŸ¯ ä»»åŠ¡è¯´æ˜\n",
            "\n",
            "**ä»»åŠ¡**ï¼šçŠ¬ç§è¯†åˆ«ï¼ˆå…¨å‚æ•°å¾®è°ƒï¼‰\n",
            "\n",
            "- **æ•°æ®é›†**ï¼šStanford Dogsï¼ˆ10ä¸ªçŠ¬ç§ï¼‰\n",
            "- **åŸºç¡€æ¨¡å‹**ï¼šCLIP-ViT-B/32\n",
            "- **å¾®è°ƒæ–¹æ³•**ï¼šå…¨å‚æ•° + åˆ†å±‚å­¦ä¹ ç‡ + æ¸è¿›è§£å†»"
        ]
    })
    
    # é…ç½®
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬ä¸€éƒ¨åˆ†ï¼šé…ç½®å‚æ•°\n",
            "\n",
            "å…¨å‚æ•°å¾®è°ƒéœ€è¦æ›´ç²¾ç»†çš„é…ç½®ï¼š"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "class FullFinetuningConfig:\n",
            "    # æ¨¡å‹é…ç½®\n",
            "    model_name = \"openai/clip-vit-base-patch32\"\n",
            "    num_classes = 10\n",
            "    \n",
            "    # è®­ç»ƒé…ç½®\n",
            "    batch_size = 16\n",
            "    num_epochs = 20\n",
            "    base_learning_rate = 1e-5\n",
            "    \n",
            "    # åˆ†å±‚å­¦ä¹ ç‡\n",
            "    layerwise_lr_decay = 0.95\n",
            "    \n",
            "    # æ¸è¿›è§£å†»\n",
            "    unfreeze_epochs = [2, 4, 6]  # åœ¨è¿™äº›epochè§£å†»å±‚\n",
            "    \n",
            "    # æ•°æ®å’Œè®¾å¤‡\n",
            "    data_dir = \"../data/dogs\"\n",
            "    device = \"cuda\"\n",
            "    output_dir = \"../outputs/full_finetuning_notebook\"\n",
            "\n",
            "config = FullFinetuningConfig()\n",
            "print(f\"ğŸ“‹ åŸºç¡€å­¦ä¹ ç‡: {config.base_learning_rate}\")\n",
            "print(f\"ğŸ“‹ åˆ†å±‚è¡°å‡ç‡: {config.layerwise_lr_decay}\")"
        ]
    })
    
    # ä½¿ç”¨è®­ç»ƒè„šæœ¬
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬äºŒéƒ¨åˆ†ï¼šå…¨å‚æ•°å¾®è°ƒ\n",
            "\n",
            "## ä½¿ç”¨è®­ç»ƒè„šæœ¬"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# è¿è¡Œå…¨å‚æ•°å¾®è°ƒ\n",
            "!python ../code/02-fine-tuning/full-finetuning/train.py \\\n",
            "    --config ../code/02-fine-tuning/full-finetuning/config.yaml \\\n",
            "    --output_dir {config.output_dir}"
        ]
    })
    
    # æ€§èƒ½å¯¹æ¯”
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ€§èƒ½å¯¹æ¯”\n",
            "\n",
            "## 3.1 LoRA vs å…¨å‚æ•°å¾®è°ƒ"
        ]
    })
    
    cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# å¯¹æ¯”æ•°æ®ï¼ˆç¤ºä¾‹ï¼‰\n",
            "comparison = pd.DataFrame({\n",
            "    'æ–¹æ³•': ['LoRA', 'å…¨å‚æ•°å¾®è°ƒ'],\n",
            "    'å‡†ç¡®ç‡(%)': [85.2, 88.5],\n",
            "    'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)': [15, 45],\n",
            "    'æ˜¾å­˜å ç”¨(GB)': [8, 24],\n",
            "    'å¯è®­ç»ƒå‚æ•°(%)': [1.2, 100]\n",
            "})\n",
            "\n",
            "print(comparison)\n",
            "\n",
            "# å¯è§†åŒ–å¯¹æ¯”\n",
            "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
            "\n",
            "metrics = ['å‡†ç¡®ç‡(%)', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)', 'æ˜¾å­˜å ç”¨(GB)', 'å¯è®­ç»ƒå‚æ•°(%)']\n",
            "for idx, metric in enumerate(metrics):\n",
            "    ax = axes[idx // 2, idx % 2]\n",
            "    comparison.plot(x='æ–¹æ³•', y=metric, kind='bar', ax=ax, legend=False)\n",
            "    ax.set_title(metric)\n",
            "    ax.set_xlabel('')\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()"
        ]
    })
    
    # æ€»ç»“
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "# ğŸ“ æ€»ç»“\n",
            "\n",
            "## âœ… å…³é”®å‘ç°\n",
            "\n",
            "| æ–¹æ³• | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |\n",
            "|------|------|------|----------|\n",
            "| **LoRA** | å¿«é€Ÿã€ä½æˆæœ¬ | æ€§èƒ½ç•¥ä½ | èµ„æºå—é™ã€å¿«é€Ÿè¿­ä»£ |\n",
            "| **å…¨å‚æ•°** | æ€§èƒ½æœ€ä¼˜ | æˆæœ¬é«˜ã€æ…¢ | è¿½æ±‚æè‡´æ€§èƒ½ |\n",
            "\n",
            "## ğŸ”‘ æœ€ä½³å®è·µ\n",
            "\n",
            "1. **å…ˆç”¨LoRAæ¢ç´¢**ï¼šå¿«é€ŸéªŒè¯æƒ³æ³•\n",
            "2. **å†ç”¨å…¨å‚æ•°ä¼˜åŒ–**ï¼šè¿½æ±‚æœ€ä½³æ€§èƒ½\n",
            "3. **æ ¹æ®åœºæ™¯é€‰æ‹©**ï¼šæƒè¡¡æˆæœ¬å’Œæ€§èƒ½\n",
            "\n",
            "## ğŸ“š å‚è€ƒèµ„æº\n",
            "\n",
            "- [å…¨å‚æ•°å¾®è°ƒæ–‡æ¡£](../docs/02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/03-å…¨å‚æ•°å¾®è°ƒ.md)\n",
            "- [ä»£ç ç¤ºä¾‹](../code/02-fine-tuning/full-finetuning/)\n",
            "\n",
            "---\n",
            "\n",
            "**ğŸ‰ æ­å–œå®Œæˆè¿›é˜¶æ•™ç¨‹ï¼**"
        ]
    })
    
    notebook = {
        "cells": cells,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "codemirror_mode": {
                    "name": "ipython",
                    "version": 3
                },
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3",
                "version": "3.8.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    return notebook


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    notebooks_dir = Path("notebooks")
    notebooks_dir.mkdir(exist_ok=True)
    
    print("ğŸ“ ç”ŸæˆJupyter Notebookæ•™ç¨‹...")
    
    # ç”ŸæˆLoRA Notebook
    print("\n1ï¸âƒ£ ç”ŸæˆLoRAå¾®è°ƒæ•™ç¨‹...")
    lora_notebook = create_lora_notebook()
    lora_path = notebooks_dir / "01_lora_finetuning_tutorial.ipynb"
    with open(lora_path, 'w', encoding='utf-8') as f:
        json.dump(lora_notebook, f, ensure_ascii=False, indent=1)
    print(f"   âœ… å·²ä¿å­˜åˆ°: {lora_path}")
    
    # ç”Ÿæˆå…¨å‚æ•°å¾®è°ƒNotebook
    print("\n2ï¸âƒ£ ç”Ÿæˆå…¨å‚æ•°å¾®è°ƒæ•™ç¨‹...")
    full_notebook = create_full_finetuning_notebook()
    full_path = notebooks_dir / "02_full_finetuning_tutorial.ipynb"
    with open(full_path, 'w', encoding='utf-8') as f:
        json.dump(full_notebook, f, ensure_ascii=False, indent=1)
    print(f"   âœ… å·²ä¿å­˜åˆ°: {full_path}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰Notebookæ•™ç¨‹ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ“š ä½¿ç”¨æ–¹æ³•ï¼š")
    print("  1. å¯åŠ¨Jupyter: jupyter notebook")
    print("  2. æ‰“å¼€notebooksç›®å½•")
    print("  3. é€‰æ‹©æ•™ç¨‹æ–‡ä»¶å¼€å§‹å­¦ä¹ ")
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - å…ˆå®Œæˆ01_loraæ•™ç¨‹")
    print("  - å†å°è¯•02_full_finetuningæ•™ç¨‹")
    print("  - è¯¦ç»†è¯´æ˜è§ notebooks/README.md")


if __name__ == "__main__":
    main()

