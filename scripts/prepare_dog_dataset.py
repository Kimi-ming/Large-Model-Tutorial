#!/usr/bin/env python3
"""
Stanford Dogs Dataset å‡†å¤‡è„šæœ¬

è‡ªåŠ¨ä¸‹è½½å¹¶å‡†å¤‡çŠ¬ç§åˆ†ç±»æ•°æ®é›†ï¼Œç”¨äºLoRAå¾®è°ƒç¤ºä¾‹ã€‚
"""

import os
import argparse
import shutil
import tarfile
import random
from pathlib import Path
from typing import List
import urllib.request
from tqdm import tqdm


class DownloadProgressBar(tqdm):
    """ä¸‹è½½è¿›åº¦æ¡"""
    def update_to(self, b=1, bsize=1, tsize=None):
        if tsize is not None:
            self.total = tsize
        self.update(b * bsize - self.n)


def download_file(url: str, output_path: str):
    """
    ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
    
    Args:
        url: ä¸‹è½½URL
        output_path: è¾“å‡ºè·¯å¾„
    """
    with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=output_path) as t:
        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)


def download_and_prepare_dataset(
    output_dir: str,
    num_classes: int = 10,
    train_ratio: float = 0.8,
    download: bool = True
):
    """
    ä¸‹è½½å¹¶å‡†å¤‡Stanford Dogsæ•°æ®é›†
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        num_classes: ä½¿ç”¨çš„ç±»åˆ«æ•°é‡ï¼ˆ1-120ï¼‰
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        download: æ˜¯å¦ä¸‹è½½æ•°æ®é›†ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡ï¼‰
    """
    print("=" * 70)
    print("Stanford Dogs Dataset å‡†å¤‡å·¥å…·")
    print("=" * 70)
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Stanford Dogs æ•°æ®é›†URL
    dataset_url = "http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar"
    annotations_url = "http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar"
    lists_url = "http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar"
    
    # ä¸‹è½½è·¯å¾„
    download_dir = output_dir / "downloads"
    download_dir.mkdir(exist_ok=True)
    
    images_tar = download_dir / "images.tar"
    annotations_tar = download_dir / "annotation.tar"
    lists_tar = download_dir / "lists.tar"
    
    # è§£å‹è·¯å¾„
    extract_dir = output_dir / "raw"
    extract_dir.mkdir(exist_ok=True)
    
    # 1. ä¸‹è½½æ•°æ®é›†
    if download:
        print("\nğŸ“¥ æ­¥éª¤ 1/4: ä¸‹è½½æ•°æ®é›†")
        print("-" * 70)
        
        if not images_tar.exists():
            print(f"æ­£åœ¨ä¸‹è½½å›¾åƒæ•°æ®é›† (~750MB)...")
            try:
                download_file(dataset_url, str(images_tar))
                print("âœ… å›¾åƒæ•°æ®é›†ä¸‹è½½å®Œæˆ")
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                print("\nğŸ’¡ å¤‡é€‰æ–¹æ¡ˆ:")
                print("   1. æ‰‹åŠ¨ä¸‹è½½: http://vision.stanford.edu/aditya86/ImageNetDogs/")
                print(f"   2. å°† images.tar æ”¾åˆ°: {download_dir}")
                print("   3. é‡æ–°è¿è¡Œæ­¤è„šæœ¬ï¼Œä½¿ç”¨ --no-download å‚æ•°")
                return False
        else:
            print("âœ… å›¾åƒæ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        
        if not lists_tar.exists():
            print(f"\næ­£åœ¨ä¸‹è½½æ•°æ®é›†åˆ—è¡¨...")
            try:
                download_file(lists_url, str(lists_tar))
                print("âœ… æ•°æ®é›†åˆ—è¡¨ä¸‹è½½å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸  åˆ—è¡¨ä¸‹è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†å‰²")
        else:
            print("âœ… æ•°æ®é›†åˆ—è¡¨å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
    
    # 2. è§£å‹æ•°æ®é›†
    print("\nğŸ“¦ æ­¥éª¤ 2/4: è§£å‹æ•°æ®é›†")
    print("-" * 70)
    
    images_dir = extract_dir / "Images"
    if not images_dir.exists():
        print("æ­£åœ¨è§£å‹å›¾åƒæ•°æ®é›†...")
        try:
            with tarfile.open(images_tar, 'r') as tar:
                tar.extractall(extract_dir)
            print("âœ… è§£å‹å®Œæˆ")
        except Exception as e:
            print(f"âŒ è§£å‹å¤±è´¥: {e}")
            return False
    else:
        print("âœ… æ•°æ®é›†å·²è§£å‹ï¼Œè·³è¿‡")
    
    # 3. ç»„ç»‡æ•°æ®é›†
    print("\nğŸ“‚ æ­¥éª¤ 3/4: ç»„ç»‡æ•°æ®é›†")
    print("-" * 70)
    
    # è·å–æ‰€æœ‰çŠ¬ç§ç±»åˆ«
    all_breeds = sorted([d.name for d in images_dir.iterdir() if d.is_dir()])
    
    if num_classes > len(all_breeds):
        print(f"âš ï¸  è¯·æ±‚çš„ç±»åˆ«æ•° ({num_classes}) è¶…è¿‡å¯ç”¨ç±»åˆ«æ•° ({len(all_breeds)})")
        num_classes = len(all_breeds)
    
    # é€‰æ‹©æŒ‡å®šæ•°é‡çš„ç±»åˆ«
    selected_breeds = all_breeds[:num_classes]
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"   æ€»ç±»åˆ«æ•°: {len(all_breeds)}")
    print(f"   ä½¿ç”¨ç±»åˆ«æ•°: {num_classes}")
    print(f"   è®­ç»ƒ/æµ‹è¯•æ¯”ä¾‹: {train_ratio:.0%} / {1-train_ratio:.0%}")
    
    # åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•ç›®å½•
    train_dir = output_dir / "train"
    test_dir = output_dir / "test"
    train_dir.mkdir(exist_ok=True)
    test_dir.mkdir(exist_ok=True)
    
    # å¤„ç†æ¯ä¸ªç±»åˆ«
    print(f"\næ­£åœ¨å¤„ç† {num_classes} ä¸ªçŠ¬ç§ç±»åˆ«...")
    
    total_train = 0
    total_test = 0
    
    for breed in tqdm(selected_breeds, desc="å¤„ç†ç±»åˆ«"):
        breed_dir = images_dir / breed
        
        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒ
        image_files = list(breed_dir.glob("*.jpg"))
        
        if not image_files:
            print(f"âš ï¸  {breed} æ²¡æœ‰æ‰¾åˆ°å›¾åƒï¼Œè·³è¿‡")
            continue
        
        # éšæœºæ‰“ä¹±
        random.shuffle(image_files)
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•
        split_idx = int(len(image_files) * train_ratio)
        train_files = image_files[:split_idx]
        test_files = image_files[split_idx:]
        
        # åˆ›å»ºç±»åˆ«ç›®å½•
        train_breed_dir = train_dir / breed
        test_breed_dir = test_dir / breed
        train_breed_dir.mkdir(exist_ok=True)
        test_breed_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶è®­ç»ƒé›†å›¾åƒ
        for img_file in train_files:
            shutil.copy2(img_file, train_breed_dir / img_file.name)
        
        # å¤åˆ¶æµ‹è¯•é›†å›¾åƒ
        for img_file in test_files:
            shutil.copy2(img_file, test_breed_dir / img_file.name)
        
        total_train += len(train_files)
        total_test += len(test_files)
    
    # 4. éªŒè¯æ•°æ®é›†
    print("\nâœ… æ­¥éª¤ 4/4: éªŒè¯æ•°æ®é›†")
    print("-" * 70)
    
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   è®­ç»ƒæ ·æœ¬: {total_train}")
    print(f"   æµ‹è¯•æ ·æœ¬: {total_test}")
    print(f"   æ€»æ ·æœ¬æ•°: {total_train + total_test}")
    print(f"\nğŸ“ æ•°æ®é›†ä½ç½®:")
    print(f"   è®­ç»ƒé›†: {train_dir}")
    print(f"   æµ‹è¯•é›†: {test_dir}")
    
    # æ˜¾ç¤ºç±»åˆ«åˆ—è¡¨
    print(f"\nğŸ• çŠ¬ç§ç±»åˆ«:")
    for i, breed in enumerate(selected_breeds, 1):
        breed_name = breed.split('-', 1)[-1].replace('_', ' ').title()
        train_count = len(list((train_dir / breed).glob("*.jpg")))
        test_count = len(list((test_dir / breed).glob("*.jpg")))
        print(f"   {i:2d}. {breed_name:30s} (è®­ç»ƒ: {train_count:3d}, æµ‹è¯•: {test_count:3d})")
    
    print("\n" + "=" * 70)
    print("âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼")
    print("=" * 70)
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("   1. æŸ¥çœ‹æ•°æ®é›†: ls", train_dir)
    print("   2. å¼€å§‹è®­ç»ƒ: python code/02-fine-tuning/lora/train.py")
    print("   3. æˆ–ä½¿ç”¨Notebook: jupyter notebook notebooks/01_lora_finetuning_tutorial.ipynb")
    
    return True


def validate_dataset(data_dir: str):
    """
    éªŒè¯æ•°æ®é›†æ˜¯å¦å‡†å¤‡æ­£ç¡®
    
    Args:
        data_dir: æ•°æ®é›†ç›®å½•
    """
    data_dir = Path(data_dir)
    
    print("\nğŸ” éªŒè¯æ•°æ®é›†...")
    print("-" * 70)
    
    train_dir = data_dir / "train"
    test_dir = data_dir / "test"
    
    if not train_dir.exists():
        print(f"âŒ è®­ç»ƒé›†ç›®å½•ä¸å­˜åœ¨: {train_dir}")
        return False
    
    if not test_dir.exists():
        print(f"âŒ æµ‹è¯•é›†ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return False
    
    train_classes = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])
    test_classes = sorted([d.name for d in test_dir.iterdir() if d.is_dir()])
    
    if not train_classes:
        print(f"âŒ è®­ç»ƒé›†ä¸ºç©º")
        return False
    
    if train_classes != test_classes:
        print(f"âš ï¸  è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç±»åˆ«ä¸ä¸€è‡´")
    
    print(f"âœ… éªŒè¯é€šè¿‡")
    print(f"   ç±»åˆ«æ•°: {len(train_classes)}")
    
    total_train = sum(len(list((train_dir / c).glob("*.jpg"))) for c in train_classes)
    total_test = sum(len(list((test_dir / c).glob("*.jpg"))) for c in test_classes)
    
    print(f"   è®­ç»ƒæ ·æœ¬: {total_train}")
    print(f"   æµ‹è¯•æ ·æœ¬: {total_test}")
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description="Stanford Dogs Dataset å‡†å¤‡å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä¸‹è½½å¹¶å‡†å¤‡10ä¸ªç±»åˆ«çš„æ•°æ®é›†
  python scripts/prepare_dog_dataset.py --output_dir data/dogs --num_classes 10
  
  # ä½¿ç”¨å·²ä¸‹è½½çš„æ•°æ®é›†ï¼ˆè·³è¿‡ä¸‹è½½ï¼‰
  python scripts/prepare_dog_dataset.py --output_dir data/dogs --no-download
  
  # éªŒè¯æ•°æ®é›†
  python scripts/prepare_dog_dataset.py --output_dir data/dogs --validate
        """
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="data/dogs",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: data/dogs)"
    )
    
    parser.add_argument(
        "--num_classes",
        type=int,
        default=10,
        help="ä½¿ç”¨çš„ç±»åˆ«æ•°é‡ (é»˜è®¤: 10, æœ€å¤§: 120)"
    )
    
    parser.add_argument(
        "--train_ratio",
        type=float,
        default=0.8,
        help="è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.8)"
    )
    
    parser.add_argument(
        "--no-download",
        action="store_true",
        help="è·³è¿‡ä¸‹è½½ï¼Œä½¿ç”¨å·²å­˜åœ¨çš„æ•°æ®é›†"
    )
    
    parser.add_argument(
        "--validate",
        action="store_true",
        help="éªŒè¯æ•°æ®é›†æ˜¯å¦å‡†å¤‡æ­£ç¡®"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­ (é»˜è®¤: 42)"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    
    # éªŒè¯æ¨¡å¼
    if args.validate:
        validate_dataset(args.output_dir)
        return
    
    # å‡†å¤‡æ•°æ®é›†
    success = download_and_prepare_dataset(
        output_dir=args.output_dir,
        num_classes=args.num_classes,
        train_ratio=args.train_ratio,
        download=not args.no_download
    )
    
    if not success:
        print("\nâŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥")
        print("\nğŸ’¡ å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œæ‚¨å¯ä»¥:")
        print("   1. æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†:")
        print("      - è®¿é—®: http://vision.stanford.edu/aditya86/ImageNetDogs/")
        print("      - ä¸‹è½½ images.tar")
        print(f"      - æ”¾åˆ°: {args.output_dir}/downloads/")
        print("   2. ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†:")
        print("      - æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡:")
        print("        data/dogs/")
        print("          â”œâ”€â”€ train/")
        print("          â”‚   â”œâ”€â”€ breed1/")
        print("          â”‚   â”‚   â”œâ”€â”€ img1.jpg")
        print("          â”‚   â”‚   â””â”€â”€ ...")
        print("          â”‚   â””â”€â”€ breed2/")
        print("          â””â”€â”€ test/")
        print("              â”œâ”€â”€ breed1/")
        print("              â””â”€â”€ breed2/")
        exit(1)


if __name__ == "__main__":
    main()
