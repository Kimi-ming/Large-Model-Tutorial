# APIæ–‡æ¡£

æœ¬æ–‡æ¡£æä¾›é¡¹ç›®ä¸­æ‰€æœ‰å·¥å…·å‡½æ•°å’Œå‘½ä»¤è¡Œå·¥å…·çš„è¯¦ç»†APIè¯´æ˜ã€‚

---

## ğŸ“‹ ç›®å½•

1. [å·¥å…·å‡½æ•°API](#å·¥å…·å‡½æ•°api)
2. [å‘½ä»¤è¡Œå·¥å…·](#å‘½ä»¤è¡Œå·¥å…·)
3. [é…ç½®æ–‡ä»¶](#é…ç½®æ–‡ä»¶)
4. [REST API](#rest-api)

---

## å·¥å…·å‡½æ•°API

### æ¨¡å‹åŠ è½½å™¨ (utils/model_loader.py)

#### `load_model`

åŠ è½½é¢„è®­ç»ƒçš„CLIPæ¨¡å‹ã€‚

**ç­¾å**:
```python
def load_model(
    model_name: str = "openai/clip-vit-base-patch32",
    device: str = "cuda",
    **kwargs
) -> Tuple[nn.Module, Callable]
```

**å‚æ•°**:
- `model_name` (str): æ¨¡å‹åç§°æˆ–è·¯å¾„
  - é¢„å®šä¹‰: `"openai/clip-vit-base-patch32"`, `"openai/clip-vit-large-patch14"`
  - è‡ªå®šä¹‰: æœ¬åœ°è·¯å¾„
- `device` (str): è®¾å¤‡ï¼Œ`"cuda"` æˆ– `"cpu"`
- `**kwargs`: ä¼ é€’ç»™æ¨¡å‹çš„é¢å¤–å‚æ•°

**è¿”å›**:
- `model` (nn.Module): åŠ è½½çš„æ¨¡å‹
- `preprocess` (Callable): é¢„å¤„ç†å‡½æ•°

**ç¤ºä¾‹**:
```python
from utils.model_loader import load_model

# åŠ è½½é»˜è®¤æ¨¡å‹
model, preprocess = load_model()

# åŠ è½½ç‰¹å®šæ¨¡å‹
model, preprocess = load_model(
    model_name="openai/clip-vit-large-patch14",
    device="cuda:0"
)

# åŠ è½½æœ¬åœ°æ¨¡å‹
model, preprocess = load_model(
    model_name="models/my_finetuned_model",
    device="cpu"
)
```

**å¼‚å¸¸**:
- `FileNotFoundError`: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨
- `RuntimeError`: CUDAä¸å¯ç”¨ä½†æŒ‡å®šäº†cudaè®¾å¤‡

---

#### `save_model`

ä¿å­˜æ¨¡å‹æƒé‡ã€‚

**ç­¾å**:
```python
def save_model(
    model: nn.Module,
    save_path: str,
    save_optimizer: bool = False,
    optimizer: Optional[torch.optim.Optimizer] = None,
    **metadata
) -> None
```

**å‚æ•°**:
- `model` (nn.Module): è¦ä¿å­˜çš„æ¨¡å‹
- `save_path` (str): ä¿å­˜è·¯å¾„
- `save_optimizer` (bool): æ˜¯å¦ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
- `optimizer` (Optional[Optimizer]): ä¼˜åŒ–å™¨å®ä¾‹
- `**metadata`: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå¦‚epoch, metricsç­‰ï¼‰

**ç¤ºä¾‹**:
```python
from utils.model_loader import save_model

# åªä¿å­˜æ¨¡å‹
save_model(model, "checkpoints/model.pth")

# ä¿å­˜æ¨¡å‹å’Œä¼˜åŒ–å™¨
save_model(
    model,
    "checkpoints/checkpoint.pth",
    save_optimizer=True,
    optimizer=optimizer,
    epoch=10,
    val_acc=0.95
)
```

---

### æ•°æ®å¤„ç†å™¨ (utils/data_processor.py)

#### `create_dataloader`

åˆ›å»ºPyTorch DataLoaderã€‚

**ç­¾å**:
```python
def create_dataloader(
    data_dir: str,
    batch_size: int = 32,
    shuffle: bool = True,
    num_workers: int = 4,
    transform: Optional[Callable] = None,
    **kwargs
) -> DataLoader
```

**å‚æ•°**:
- `data_dir` (str): æ•°æ®ç›®å½•è·¯å¾„
- `batch_size` (int): æ‰¹å¤§å°ï¼Œé»˜è®¤32
- `shuffle` (bool): æ˜¯å¦æ‰“ä¹±æ•°æ®
- `num_workers` (int): æ•°æ®åŠ è½½è¿›ç¨‹æ•°
- `transform` (Optional[Callable]): æ•°æ®å˜æ¢å‡½æ•°
- `**kwargs`: ä¼ é€’ç»™DataLoaderçš„é¢å¤–å‚æ•°

**è¿”å›**:
- `DataLoader`: PyTorchæ•°æ®åŠ è½½å™¨

**ç¤ºä¾‹**:
```python
from utils.data_processor import create_dataloader
from torchvision import transforms

# åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor()
])

train_loader = create_dataloader(
    "data/train",
    batch_size=64,
    shuffle=True,
    num_workers=8,
    transform=transform
)

# åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨
val_loader = create_dataloader(
    "data/val",
    batch_size=32,
    shuffle=False,
    transform=transform
)
```

---

#### `preprocess_image`

é¢„å¤„ç†å•å¼ å›¾ç‰‡ã€‚

**ç­¾å**:
```python
def preprocess_image(
    image: Union[str, Path, PIL.Image.Image, np.ndarray],
    size: Tuple[int, int] = (224, 224),
    normalize: bool = True
) -> torch.Tensor
```

**å‚æ•°**:
- `image`: è¾“å…¥å›¾ç‰‡
  - `str/Path`: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
  - `PIL.Image`: PILå›¾ç‰‡å¯¹è±¡
  - `np.ndarray`: NumPyæ•°ç»„
- `size` (Tuple[int, int]): ç›®æ ‡å°ºå¯¸
- `normalize` (bool): æ˜¯å¦å½’ä¸€åŒ–

**è¿”å›**:
- `torch.Tensor`: é¢„å¤„ç†åçš„å¼ é‡ `[C, H, W]`

**ç¤ºä¾‹**:
```python
from utils.data_processor import preprocess_image

# ä»æ–‡ä»¶è·¯å¾„
tensor = preprocess_image("path/to/image.jpg")

# ä»PIL Image
from PIL import Image
img = Image.open("image.jpg")
tensor = preprocess_image(img, size=(256, 256))

# ä»NumPyæ•°ç»„
import numpy as np
img_array = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
tensor = preprocess_image(img_array, normalize=False)
```

---

### é…ç½®è§£æå™¨ (utils/config_parser.py)

#### `load_config`

åŠ è½½YAMLé…ç½®æ–‡ä»¶ã€‚

**ç­¾å**:
```python
def load_config(
    config_path: str,
    override: Optional[Dict] = None
) -> Dict
```

**å‚æ•°**:
- `config_path` (str): é…ç½®æ–‡ä»¶è·¯å¾„
- `override` (Optional[Dict]): è¦†ç›–é…ç½®é¡¹

**è¿”å›**:
- `Dict`: é…ç½®å­—å…¸

**ç¤ºä¾‹**:
```python
from utils.config_parser import load_config

# åŠ è½½é…ç½®
config = load_config("configs/base.yaml")

# è¦†ç›–éƒ¨åˆ†é…ç½®
config = load_config(
    "configs/base.yaml",
    override={
        "training.batch_size": 64,
        "training.learning_rate": 2e-5
    }
)

# è®¿é—®é…ç½®
batch_size = config['training']['batch_size']
lr = config['training']['learning_rate']
```

---

#### `save_config`

ä¿å­˜é…ç½®åˆ°YAMLæ–‡ä»¶ã€‚

**ç­¾å**:
```python
def save_config(
    config: Dict,
    save_path: str
) -> None
```

**å‚æ•°**:
- `config` (Dict): é…ç½®å­—å…¸
- `save_path` (str): ä¿å­˜è·¯å¾„

**ç¤ºä¾‹**:
```python
from utils.config_parser import save_config

config = {
    'model': {
        'name': 'openai/clip-vit-base-patch32',
        'num_classes': 10
    },
    'training': {
        'batch_size': 32,
        'learning_rate': 1e-5
    }
}

save_config(config, "configs/my_experiment.yaml")
```

---

### æ—¥å¿—è®°å½•å™¨ (utils/logger.py)

#### `setup_logger`

è®¾ç½®æ—¥å¿—ç³»ç»Ÿã€‚

**ç­¾å**:
```python
def setup_logger(
    name: str = __name__,
    log_dir: str = "logs",
    level: int = logging.INFO,
    console: bool = True
) -> logging.Logger
```

**å‚æ•°**:
- `name` (str): Loggeråç§°
- `log_dir` (str): æ—¥å¿—ç›®å½•
- `level` (int): æ—¥å¿—çº§åˆ«
- `console` (bool): æ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°

**è¿”å›**:
- `logging.Logger`: é…ç½®å¥½çš„Loggerå®ä¾‹

**ç¤ºä¾‹**:
```python
from utils.logger import setup_logger

# è®¾ç½®logger
logger = setup_logger(
    name="my_experiment",
    log_dir="logs/exp1",
    level=logging.DEBUG
)

# ä½¿ç”¨logger
logger.info("Training started")
logger.debug("Batch size: 32")
logger.warning("Learning rate is very high")
logger.error("CUDA out of memory")
```

---

## å‘½ä»¤è¡Œå·¥å…·

### è®­ç»ƒè„šæœ¬

#### `train.py`

è®­ç»ƒCLIPæ¨¡å‹ã€‚

**ç”¨æ³•**:
```bash
python code/02-fine-tuning/lora/train.py [OPTIONS]
```

**å‚æ•°**:
```
--config PATH          é…ç½®æ–‡ä»¶è·¯å¾„ [é»˜è®¤: config.yaml]
--data-dir PATH        æ•°æ®ç›®å½• [é»˜è®¤: data/train]
--output-dir PATH      è¾“å‡ºç›®å½• [é»˜è®¤: outputs]
--batch-size INT       æ‰¹å¤§å° [é»˜è®¤: 32]
--epochs INT           è®­ç»ƒè½®æ•° [é»˜è®¤: 10]
--lr FLOAT            å­¦ä¹ ç‡ [é»˜è®¤: 1e-5]
--device STR          è®¾å¤‡ (cuda/cpu) [é»˜è®¤: cuda]
--resume PATH         ä»æ£€æŸ¥ç‚¹æ¢å¤
--seed INT            éšæœºç§å­ [é»˜è®¤: 42]
--log-every INT       æ—¥å¿—é¢‘ç‡ [é»˜è®¤: 100]
--save-every INT      ä¿å­˜é¢‘ç‡ [é»˜è®¤: 1]
```

**ç¤ºä¾‹**:
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python code/02-fine-tuning/lora/train.py

# æŒ‡å®šé…ç½®æ–‡ä»¶
python code/02-fine-tuning/lora/train.py --config configs/base.yaml

# æˆ–ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python code/02-fine-tuning/lora/train.py --config configs/my_experiment.yaml

# è‡ªå®šä¹‰å‚æ•°
python code/02-fine-tuning/lora/train.py \
    --data-dir data/my_dataset \
    --batch-size 64 \
    --epochs 20 \
    --lr 2e-5

# ä»æ£€æŸ¥ç‚¹æ¢å¤
python code/02-fine-tuning/lora/train.py \
    --resume checkpoints/checkpoint_epoch_5.pth

# å¤šGPUè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3 python code/02-fine-tuning/lora/train.py \
    --batch-size 128
```

---

### è¯„ä¼°è„šæœ¬

#### `evaluate.py`

è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**ç”¨æ³•**:
```bash
python code/02-fine-tuning/lora/evaluate.py [OPTIONS]
```

**å‚æ•°**:
```
--model-path PATH      æ¨¡å‹æƒé‡è·¯å¾„ [å¿…éœ€]
--data-dir PATH        æµ‹è¯•æ•°æ®ç›®å½• [å¿…éœ€]
--batch-size INT       æ‰¹å¤§å° [é»˜è®¤: 32]
--output-file PATH     ç»“æœä¿å­˜è·¯å¾„
--metrics LIST         è¯„ä¼°æŒ‡æ ‡ [é»˜è®¤: accuracy,f1]
--device STR          è®¾å¤‡ [é»˜è®¤: cuda]
```

**ç¤ºä¾‹**:
```bash
# åŸºæœ¬è¯„ä¼°
python code/02-fine-tuning/lora/evaluate.py \
    --model-path checkpoints/best_model.pth \
    --data-dir data/test

# è¯¦ç»†è¯„ä¼°
python code/02-fine-tuning/lora/evaluate.py \
    --model-path checkpoints/best_model.pth \
    --data-dir data/test \
    --metrics accuracy,precision,recall,f1 \
    --output-file results/eval_results.json

# æ‰¹é‡è¯„ä¼°
for model in checkpoints/*.pth; do
    python code/02-fine-tuning/lora/evaluate.py \
        --model-path $model \
        --data-dir data/test \
        --output-file results/$(basename $model .pth).json
done
```

---

### æ¨ç†è„šæœ¬

#### `inference.py`

å¯¹å›¾ç‰‡è¿›è¡Œæ¨ç†ã€‚

**ç”¨æ³•**:
```bash
python code/02-fine-tuning/lora/inference.py [OPTIONS] IMAGE_PATH
```

**å‚æ•°**:
```
IMAGE_PATH            è¾“å…¥å›¾ç‰‡è·¯å¾„ [å¿…éœ€]
--model-path PATH     æ¨¡å‹æƒé‡è·¯å¾„ [å¿…éœ€]
--labels LIST         ç±»åˆ«æ ‡ç­¾
--top-k INT          è¿”å›Top-Kç»“æœ [é»˜è®¤: 5]
--device STR         è®¾å¤‡ [é»˜è®¤: cuda]
--output-file PATH   ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
```

**ç¤ºä¾‹**:
```bash
# å•å¼ å›¾ç‰‡æ¨ç†
python code/02-fine-tuning/lora/inference.py \
    test.jpg \
    --model-path checkpoints/best_model.pth \
    --labels "dog,cat,bird,fish"

# æ‰¹é‡æ¨ç†
for img in images/*.jpg; do
    python code/02-fine-tuning/lora/inference.py \
        $img \
        --model-path checkpoints/best_model.pth \
        --top-k 3 \
        --output-file results/$(basename $img .jpg).json
done

# ç›®å½•æ¨ç†
python code/02-fine-tuning/lora/inference.py \
    images/ \
    --model-path checkpoints/best_model.pth \
    --output-file results/batch_results.json
```

---

### æ¨¡å‹è½¬æ¢è„šæœ¬

#### `convert_to_onnx.py`

å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ã€‚

**ç”¨æ³•**:
```bash
python code/04-deployment/nvidia/onnx/convert_to_onnx.py [OPTIONS]
```

**å‚æ•°**:
```
--model-path PATH      PyTorchæ¨¡å‹è·¯å¾„ [å¿…éœ€]
--output-path PATH     ONNXè¾“å‡ºè·¯å¾„ [å¿…éœ€]
--input-size LIST      è¾“å…¥å°ºå¯¸ [é»˜è®¤: 1,3,224,224]
--opset-version INT    ONNX opsetç‰ˆæœ¬ [é»˜è®¤: 11]
--dynamic-axes BOOL    æ˜¯å¦ä½¿ç”¨åŠ¨æ€è½´ [é»˜è®¤: True]
--simplify BOOL        æ˜¯å¦ç®€åŒ–æ¨¡å‹ [é»˜è®¤: True]
```

**ç¤ºä¾‹**:
```bash
# åŸºæœ¬è½¬æ¢
python code/04-deployment/nvidia/onnx/convert_to_onnx.py \
    --model-path checkpoints/best_model.pth \
    --output-path models/model.onnx

# è‡ªå®šä¹‰è¾“å…¥å°ºå¯¸
python code/04-deployment/nvidia/onnx/convert_to_onnx.py \
    --model-path checkpoints/best_model.pth \
    --output-path models/model_256.onnx \
    --input-size 1,3,256,256

# å›ºå®šbatch size
python code/04-deployment/nvidia/onnx/convert_to_onnx.py \
    --model-path checkpoints/best_model.pth \
    --output-path models/model_batch8.onnx \
    --input-size 8,3,224,224 \
    --dynamic-axes false
```

---

### åŸºå‡†æµ‹è¯•è„šæœ¬

#### `run_benchmarks.sh`

è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•ã€‚

**ç”¨æ³•**:
```bash
bash scripts/run_benchmarks.sh [MODEL_PATH] [DATA_DIR]
```

**å‚æ•°**:
```
MODEL_PATH           æ¨¡å‹è·¯å¾„ [é»˜è®¤: checkpoints/best_model.pth]
DATA_DIR            æµ‹è¯•æ•°æ®ç›®å½• [é»˜è®¤: data/test]
```

**ç¤ºä¾‹**:
```bash
# ä½¿ç”¨é»˜è®¤è·¯å¾„
bash scripts/run_benchmarks.sh

# æŒ‡å®šè·¯å¾„
bash scripts/run_benchmarks.sh \
    checkpoints/my_model.pth \
    data/my_test

# æŸ¥çœ‹ç»“æœ
cat benchmark_results.txt
```

**è¾“å‡º**:
```
=== Benchmark Results ===
Accuracy: 92.5%
Speed: 45.2 ms/image
Memory: 1250 MB
Throughput: 22.1 images/sec
```

---

## é…ç½®æ–‡ä»¶

### è®­ç»ƒé…ç½® (configs/training/*.yaml)

**ç»“æ„**:
```yaml
# æ¨¡å‹é…ç½®
model:
  name: "openai/clip-vit-base-patch32"
  num_classes: 10
  freeze_backbone: false

# æ•°æ®é…ç½®
data:
  train_dir: "data/train"
  val_dir: "data/val"
  batch_size: 32
  num_workers: 4
  augmentation: true

# è®­ç»ƒé…ç½®
training:
  epochs: 50
  learning_rate: 1e-5
  weight_decay: 0.01
  warmup_steps: 500
  gradient_clip: 1.0
  mixed_precision: true
  
# ä¼˜åŒ–å™¨é…ç½®
optimizer:
  type: "adam"
  betas: [0.9, 0.999]
  eps: 1e-8

# å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler:
  type: "cosine"
  T_max: 50
  eta_min: 1e-7

# ä¿å­˜é…ç½®
checkpoint:
  save_dir: "checkpoints"
  save_every: 5
  keep_last_n: 3
  save_best: true

# æ—¥å¿—é…ç½®
logging:
  log_dir: "logs"
  log_every: 100
  use_tensorboard: true
```

**ä½¿ç”¨**:
```python
from utils.config_parser import load_config

# ä½¿ç”¨åŸºç¡€é…ç½®
config = load_config("configs/base.yaml")
batch_size = config['data']['batch_size']
learning_rate = config['training']['learning_rate']

# æˆ–ä½¿ç”¨æ¨¡å—ç‰¹å®šé…ç½®
lora_config = load_config("code/02-fine-tuning/lora/config.yaml")
```

---

### éƒ¨ç½²é…ç½® (configs/deployment/*.yaml)

**ç»“æ„**:
```yaml
# æœåŠ¡é…ç½®
server:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  timeout: 60

# æ¨¡å‹é…ç½®
model:
  path: "models/production/model.onnx"
  device: "cuda"
  batch_size: 32
  
# é¢„å¤„ç†é…ç½®
preprocessing:
  image_size: [224, 224]
  normalize: true
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# æ€§èƒ½é…ç½®
performance:
  use_fp16: true
  use_batch_inference: true
  max_batch_wait_time: 0.1
  
# ç¼“å­˜é…ç½®
cache:
  enabled: true
  max_size: 1000
  ttl: 3600

# é™æµé…ç½®
rate_limit:
  enabled: true
  requests_per_minute: 60
  requests_per_hour: 1000
```

---

## REST API

### APIæœåŠ¡ (code/04-deployment/api-server/app.py)

FastAPIæœåŠ¡ï¼Œæä¾›æ¨¡å‹æ¨ç†æ¥å£ã€‚

#### å¯åŠ¨æœåŠ¡

```bash
# å¼€å‘æ¨¡å¼
python code/04-deployment/api-server/app.py

# ç”Ÿäº§æ¨¡å¼ï¼ˆä½¿ç”¨gunicornï¼‰
gunicorn code.04-deployment.api-server.app:app \
    --workers 4 \
    --bind 0.0.0.0:8000 \
    --worker-class uvicorn.workers.UvicornWorker
```

---

#### `POST /predict`

å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹ã€‚

**è¯·æ±‚**:
```http
POST /predict
Content-Type: multipart/form-data

file: <image_file>
labels: ["dog", "cat", "bird"]  # å¯é€‰
top_k: 5  # å¯é€‰
```

**å“åº”**:
```json
{
  "predictions": [
    {
      "label": "dog",
      "confidence": 0.95
    },
    {
      "label": "cat",
      "confidence": 0.03
    }
  ],
  "inference_time_ms": 45.2
}
```

**ç¤ºä¾‹**:
```bash
# cURL
curl -X POST "http://localhost:8000/predict" \
    -F "file=@test.jpg" \
    -F "labels=dog,cat,bird" \
    -F "top_k=3"

# Python
import requests

files = {'file': open('test.jpg', 'rb')}
data = {'labels': 'dog,cat,bird', 'top_k': 3}
response = requests.post('http://localhost:8000/predict', files=files, data=data)
print(response.json())
```

---

#### `POST /batch_predict`

æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡ã€‚

**è¯·æ±‚**:
```http
POST /batch_predict
Content-Type: multipart/form-data

files: [<image_file_1>, <image_file_2>, ...]
labels: ["dog", "cat", "bird"]
```

**å“åº”**:
```json
{
  "results": [
    {
      "filename": "image1.jpg",
      "predictions": [...]
    },
    {
      "filename": "image2.jpg",
      "predictions": [...]
    }
  ],
  "total_time_ms": 120.5
}
```

---

#### `GET /health`

å¥åº·æ£€æŸ¥æ¥å£ã€‚

**è¯·æ±‚**:
```http
GET /health
```

**å“åº”**:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cuda:0",
  "memory_usage_mb": 1250.5
}
```

---

#### `GET /metrics`

è·å–æœåŠ¡æŒ‡æ ‡ã€‚

**è¯·æ±‚**:
```http
GET /metrics
```

**å“åº”**:
```json
{
  "total_requests": 1523,
  "average_inference_time_ms": 45.2,
  "requests_per_second": 12.5,
  "error_rate": 0.02
}
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### ç‰ˆæœ¬å…¼å®¹æ€§

- Python: >= 3.8
- PyTorch: >= 2.0.0
- transformers: >= 4.35.0

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹åŠ è½½å¤±è´¥**: æ£€æŸ¥æ¨¡å‹è·¯å¾„å’ŒCUDAæ˜¯å¦å¯ç”¨
2. **OOMé”™è¯¯**: å‡å°batch_sizeæˆ–ä½¿ç”¨FP16
3. **APIè¶…æ—¶**: å¢åŠ timeoutæˆ–ä¼˜åŒ–æ¨¡å‹æ¨ç†é€Ÿåº¦

### æœ€ä½³å®è·µ

1. ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†å‚æ•°
2. è®°å½•è¯¦ç»†æ—¥å¿—ä¾¿äºè°ƒè¯•
3. å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
4. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒåŠ é€Ÿ
5. éƒ¨ç½²å‰è¿›è¡Œæ€§èƒ½æµ‹è¯•

---

## ğŸ”— ç›¸å…³èµ„æº

- [ä½¿ç”¨è¯´æ˜](docs/05-ä½¿ç”¨è¯´æ˜/)
- [å¸¸è§é—®é¢˜FAQ](docs/05-ä½¿ç”¨è¯´æ˜/03-å¸¸è§é—®é¢˜FAQ.md)
- [æœ€ä½³å®è·µ](docs/05-ä½¿ç”¨è¯´æ˜/04-æœ€ä½³å®è·µ.md)

---

**æœ€åæ›´æ–°**: 2025-11-05  
**ç‰ˆæœ¬**: v1.0

