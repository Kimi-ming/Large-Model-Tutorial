# 模型对比与评测

##  学习者提示

本章节提供详细的模型对比数据和评测方法，帮助您基于量化指标做出选型决策。

**学习目标**：
- 理解视觉大模型的评测指标
- 掌握多维度对比方法
- 能够根据指标选择合适的模型

**先修要求**：
- 已阅读"主流视觉大模型概述"
- 了解基本的评测指标（准确率、F1等）

**难度**：⭐⭐☆☆☆（初级）  
**预计时间**：45-60分钟

---

##  评测维度说明

### 1. 性能指标

| 任务类型 | 主要指标 | 说明 |
|---------|---------|------|
| **图像分类** | Top-1/Top-5准确率 | 预测正确的比例 |
| **目标检测** | mAP | 检测精度和召回率的综合 |
| **图像分割** | mIoU | 分割区域的重叠度 |
| **图像描述** | CIDEr, BLEU | 生成文本的质量 |
| **视觉问答** | 准确率 | 回答的正确性 |

### 2. 效率指标

| 指标 | 单位 | 说明 |
|------|------|------|
| **推理速度** | images/sec | 处理速度 |
| **显存占用** | GB | GPU内存需求 |
| **模型大小** | MB/GB | 存储空间需求 |

---

##  综合性能对比

### 图文多模态任务

基于 COCO 图文检索和 ImageNet 零样本分类的对比：

| 模型 | ImageNet Zero-shot | COCO R@1 | 推理速度 | 显存 |
|------|:---:|:---:|:---:|:---:|
| **CLIP-ViT-B/32** | 63.2% | 58.4% | ~50 img/s | 2.5GB |
| **CLIP-ViT-L/14** | 75.5% | 63.9% | ~15 img/s | 4.8GB |
| **BLIP-2** | - | 77.2% | ~8 img/s | 6.8GB |

** 解读**：CLIP适合需要快速推理的场景，BLIP-2性能最强但推理最慢

---

### 视觉问答（VQA）

基于 VQAv2 数据集：

| 模型 | 整体准确率 | Yes/No | Number | 推理时间 |
|------|:---:|:---:|:---:|:---:|
| **BLIP-2** | 82.2% | 91.4% | 56.8% | ~150ms |
| **LLaVA-1.5-7B** | 78.5% | 89.2% | 53.6% | ~200ms |
| **Qwen-VL** | 79.8% | 89.8% | 54.9% | ~220ms |

---

##  选型决策树

```
开始
├─ 是否需要中文支持？
│  ├─ 是 → Qwen-VL / InternVL
│  └─ 否 → 继续
│
├─ 主要任务类型？
│  ├─ 图文检索 → CLIP
│  ├─ 图像分割 → SAM
│  └─ 视觉问答 → BLIP-2 / LLaVA
│
└─ 资源约束？
   ├─ 低(<8GB) → CLIP
   ├─ 中(8-16GB) → SAM / LLaVA-7B
   └─ 高(>16GB) → Qwen-VL
```

---

##  实践任务

创建一个对比表格，对比3-5个候选模型的性能、资源需求和成本。

---

## ➡️ 下一步

- [03-选型策略](./03-选型策略.md) - 系统化的选型方法
- [04-基准测试实践](./04-基准测试实践.md) - 动手测试模型

---

**文档版本**: v1.0  
**最后更新**: 2025-11-01
