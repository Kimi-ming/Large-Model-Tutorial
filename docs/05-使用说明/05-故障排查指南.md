# æ•…éšœæ’æŸ¥æŒ‡å—

æœ¬æ–‡æ¡£æä¾›ç³»ç»ŸåŒ–çš„æ•…éšœæ’æŸ¥æ–¹æ³•ï¼Œå¸®åŠ©ä½ å¿«é€Ÿå®šä½å’Œè§£å†³é—®é¢˜ã€‚

---

## ğŸ“‹ ç›®å½•

1. [æ•…éšœæ’æŸ¥æµç¨‹](#æ•…éšœæ’æŸ¥æµç¨‹)
2. [ç¯å¢ƒé—®é¢˜æ’æŸ¥](#ç¯å¢ƒé—®é¢˜æ’æŸ¥)
3. [è®­ç»ƒé—®é¢˜æ’æŸ¥](#è®­ç»ƒé—®é¢˜æ’æŸ¥)
4. [æ¨ç†é—®é¢˜æ’æŸ¥](#æ¨ç†é—®é¢˜æ’æŸ¥)
5. [æ€§èƒ½é—®é¢˜æ’æŸ¥](#æ€§èƒ½é—®é¢˜æ’æŸ¥)
6. [æ—¥å¿—åˆ†æ](#æ—¥å¿—åˆ†æ)

---

## æ•…éšœæ’æŸ¥æµç¨‹

### é€šç”¨æ’æŸ¥æ­¥éª¤

```
1. æ”¶é›†ä¿¡æ¯
   â”œâ”€â”€ é”™è¯¯ä¿¡æ¯
   â”œâ”€â”€ ç³»ç»Ÿç¯å¢ƒ
   â”œâ”€â”€ å¤ç°æ­¥éª¤
   â””â”€â”€ æ—¥å¿—æ–‡ä»¶

2. å®šä½é—®é¢˜
   â”œâ”€â”€ ç¯å¢ƒé—®é¢˜
   â”œâ”€â”€ æ•°æ®é—®é¢˜
   â”œâ”€â”€ ä»£ç é—®é¢˜
   â””â”€â”€ ç¡¬ä»¶é—®é¢˜

3. éªŒè¯ä¿®å¤
   â”œâ”€â”€ æœ€å°å¤ç°
   â”œâ”€â”€ å•å…ƒæµ‹è¯•
   â””â”€â”€ é›†æˆæµ‹è¯•

4. æ–‡æ¡£è®°å½•
   â””â”€â”€ æ›´æ–°FAQ
```

### ä¿¡æ¯æ”¶é›†è„šæœ¬

```python
#!/usr/bin/env python
"""ç³»ç»Ÿä¿¡æ¯æ”¶é›†è„šæœ¬"""

import os
import sys
import platform
import subprocess

def collect_system_info():
    """æ”¶é›†ç³»ç»Ÿä¿¡æ¯"""
    info = {}
    
    # æ“ä½œç³»ç»Ÿ
    info['os'] = platform.system()
    info['os_version'] = platform.version()
    info['python_version'] = sys.version
    
    # CUDA
    try:
        result = subprocess.run(
            ['nvcc', '--version'],
            capture_output=True,
            text=True
        )
        info['cuda_version'] = result.stdout
    except:
        info['cuda_version'] = "Not installed"
    
    # PyTorch
    try:
        import torch
        info['torch_version'] = torch.__version__
        info['torch_cuda_available'] = torch.cuda.is_available()
        if torch.cuda.is_available():
            info['cuda_device_count'] = torch.cuda.device_count()
            info['cuda_device_name'] = torch.cuda.get_device_name(0)
    except:
        info['torch_version'] = "Not installed"
    
    # GPUä¿¡æ¯
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=name,driver_version,memory.total',
             '--format=csv,noheader'],
            capture_output=True,
            text=True
        )
        info['gpu_info'] = result.stdout.strip()
    except:
        info['gpu_info'] = "nvidia-smi not available"
    
    # å†…å­˜
    try:
        import psutil
        mem = psutil.virtual_memory()
        info['total_memory_gb'] = mem.total / (1024**3)
        info['available_memory_gb'] = mem.available / (1024**3)
    except:
        pass
    
    # ç¯å¢ƒå˜é‡
    important_vars = [
        'CUDA_HOME', 'CUDA_VISIBLE_DEVICES',
        'HF_HOME', 'TRANSFORMERS_CACHE'
    ]
    info['env_vars'] = {
        k: os.environ.get(k, 'Not set')
        for k in important_vars
    }
    
    return info

def print_system_info():
    """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
    info = collect_system_info()
    
    print("="*50)
    print("ç³»ç»Ÿä¿¡æ¯")
    print("="*50)
    
    for key, value in info.items():
        if isinstance(value, dict):
            print(f"\n{key}:")
            for k, v in value.items():
                print(f"  {k}: {v}")
        else:
            print(f"{key}: {value}")
    
    print("\n" + "="*50)

if __name__ == "__main__":
    print_system_info()
```

---

## ç¯å¢ƒé—®é¢˜æ’æŸ¥

### é—®é¢˜1: ImportError

**ç—‡çŠ¶**: 
```python
ImportError: No module named 'xxx'
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥æ˜¯å¦å®‰è£…
pip list | grep xxx

# 2. æ£€æŸ¥Pythonè·¯å¾„
python -c "import sys; print('\n'.join(sys.path))"

# 3. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
which python
echo $VIRTUAL_ENV

# 4. é‡æ–°å®‰è£…
pip uninstall xxx
pip install xxx

# 5. æ£€æŸ¥ç‰ˆæœ¬å†²çª
pip check
```

### é—®é¢˜2: CUDA/cuDNNä¸åŒ¹é…

**ç—‡çŠ¶**:
```
RuntimeError: CUDA error: no kernel image is available for execution
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version
ls -l /usr/local/cuda

# 2. æ£€æŸ¥PyTorch CUDAç‰ˆæœ¬
python -c "import torch; print(torch.version.cuda)"

# 3. æ£€æŸ¥cuDNN
python -c "import torch; print(torch.backends.cudnn.version())"

# 4. åŒ¹é…å®‰è£…
# ç³»ç»ŸCUDA 11.8 â†’ PyTorch CUDA 11.8
pip install torch==2.0.1 --index-url https://download.pytorch.org/whl/cu118
```

**ç‰ˆæœ¬å¯¹åº”è¡¨**:
| PyTorch | CUDA | cuDNN |
|---------|------|-------|
| 2.0.1   | 11.8 | 8.7   |
| 2.0.1   | 11.7 | 8.5   |
| 1.13.1  | 11.7 | 8.5   |

### é—®é¢˜3: é©±åŠ¨é—®é¢˜

**ç—‡çŠ¶**:
```
NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥é©±åŠ¨çŠ¶æ€
nvidia-smi

# 2. æ£€æŸ¥é©±åŠ¨æ¨¡å—
lsmod | grep nvidia

# 3. é‡æ–°åŠ è½½é©±åŠ¨
sudo modprobe nvidia

# 4. é‡å¯é©±åŠ¨æœåŠ¡
sudo systemctl restart nvidia-persistenced

# 5. æ£€æŸ¥é©±åŠ¨æ—¥å¿—
dmesg | grep -i nvidia

# 6. é‡æ–°å®‰è£…é©±åŠ¨ï¼ˆæœ€åæ‰‹æ®µï¼‰
sudo apt-get purge nvidia-*
sudo apt-get install nvidia-driver-525
sudo reboot
```

---

## è®­ç»ƒé—®é¢˜æ’æŸ¥

### é—®é¢˜1: OOMæ’æŸ¥

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory
```

**æ’æŸ¥å·¥å…·**:
```python
import torch

def diagnose_oom(model, batch_size, image_size=(3, 224, 224)):
    """è¯Šæ–­OOMé—®é¢˜"""
    device = next(model.parameters()).device
    
    print("=== OOMè¯Šæ–­ ===")
    
    # 1. æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\n1. æ¨¡å‹å‚æ•°:")
    print(f"   æ€»å‚æ•°: {total_params:,} ({total_params * 4 / 1024**2:.2f} MB)")
    print(f"   å¯è®­ç»ƒ: {trainable_params:,} ({trainable_params * 4 / 1024**2:.2f} MB)")
    
    # 2. GPUå†…å­˜
    if device.type == 'cuda':
        total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**2
        allocated = torch.cuda.memory_allocated(device) / 1024**2
        cached = torch.cuda.memory_reserved(device) / 1024**2
        
        print(f"\n2. GPUå†…å­˜:")
        print(f"   æ€»å†…å­˜: {total_memory:.2f} MB")
        print(f"   å·²åˆ†é…: {allocated:.2f} MB ({allocated/total_memory*100:.1f}%)")
        print(f"   å·²ç¼“å­˜: {cached:.2f} MB ({cached/total_memory*100:.1f}%)")
    
    # 3. ä¼°ç®—batch sizeå†…å­˜
    try:
        torch.cuda.reset_peak_memory_stats()
        
        # æ¨¡æ‹Ÿä¸€æ¬¡å‰å‘ä¼ æ’­
        dummy_input = torch.randn(batch_size, *image_size).to(device)
        with torch.no_grad():
            output = model(dummy_input)
        
        peak_memory = torch.cuda.max_memory_allocated(device) / 1024**2
        
        print(f"\n3. Batchå†…å­˜:")
        print(f"   Batch size: {batch_size}")
        print(f"   å³°å€¼å†…å­˜: {peak_memory:.2f} MB")
        print(f"   æ¯ä¸ªæ ·æœ¬: {peak_memory/batch_size:.2f} MB")
        
        # ä¼°ç®—æœ€å¤§batch size
        available = total_memory - allocated
        max_batch_size = int(available / (peak_memory/batch_size) * 0.8)  # ç•™20%ä½™é‡
        
        print(f"\n4. å»ºè®®:")
        print(f"   æœ€å¤§batch size: ~{max_batch_size}")
        
        if max_batch_size < batch_size:
            print(f"   âš ï¸  å½“å‰batch size ({batch_size}) å¯èƒ½å¯¼è‡´OOM!")
            print(f"   å»ºè®®:")
            print(f"   - å‡å°batch sizeåˆ° {max_batch_size}")
            print(f"   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§batch")
            print(f"   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (FP16)")
            print(f"   - å†»ç»“éƒ¨åˆ†å±‚å‡å°‘æ˜¾å­˜å ç”¨")
        
    except RuntimeError as e:
        print(f"\nâŒ è¯Šæ–­å¤±è´¥: {e}")

# ä½¿ç”¨
diagnose_oom(model, batch_size=32)
```

**è§£å†³æ–¹æ¡ˆä¼˜å…ˆçº§**:
1. å‡å°batch size
2. ä½¿ç”¨FP16æ··åˆç²¾åº¦
3. æ¢¯åº¦æ£€æŸ¥ç‚¹
4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
5. åˆ†å¸ƒå¼è®­ç»ƒ

### é—®é¢˜2: è®­ç»ƒä¸æ”¶æ•›

**æ’æŸ¥æ¸…å•**:
```python
def debug_training(model, dataloader, optimizer):
    """è°ƒè¯•è®­ç»ƒé—®é¢˜"""
    
    print("=== è®­ç»ƒè°ƒè¯• ===\n")
    
    # 1. æ£€æŸ¥æ•°æ®
    print("1. æ•°æ®æ£€æŸ¥:")
    images, labels = next(iter(dataloader))
    print(f"   Image shape: {images.shape}")
    print(f"   Image range: [{images.min():.3f}, {images.max():.3f}]")
    print(f"   Labels shape: {labels.shape}")
    print(f"   Labels range: [{labels.min()}, {labels.max()}]")
    print(f"   Unique labels: {torch.unique(labels).tolist()}")
    
    # 2. æ£€æŸ¥æ¨¡å‹è¾“å‡º
    print("\n2. æ¨¡å‹è¾“å‡º:")
    model.eval()
    with torch.no_grad():
        outputs = model(images[:1])
    print(f"   Output shape: {outputs.shape}")
    print(f"   Output range: [{outputs.min():.3f}, {outputs.max():.3f}]")
    print(f"   Output mean: {outputs.mean():.3f}")
    print(f"   Output std: {outputs.std():.3f}")
    
    # 3. æ£€æŸ¥æ¢¯åº¦
    print("\n3. æ¢¯åº¦æ£€æŸ¥:")
    model.train()
    outputs = model(images[:4])
    loss = nn.functional.cross_entropy(outputs, labels[:4])
    loss.backward()
    
    grad_norms = []
    for name, param in model.named_parameters():
        if param.requires_grad and param.grad is not None:
            grad_norm = param.grad.norm().item()
            grad_norms.append((name, grad_norm))
    
    # æ’åºæ˜¾ç¤ºæœ€å¤§å’Œæœ€å°çš„æ¢¯åº¦
    grad_norms.sort(key=lambda x: x[1], reverse=True)
    print("   æœ€å¤§æ¢¯åº¦:")
    for name, norm in grad_norms[:3]:
        print(f"     {name}: {norm:.6f}")
    print("   æœ€å°æ¢¯åº¦:")
    for name, norm in grad_norms[-3:]:
        print(f"     {name}: {norm:.6f}")
    
    # 4. æ£€æŸ¥æƒé‡æ›´æ–°
    print("\n4. æƒé‡æ›´æ–°:")
    old_params = {name: param.clone() for name, param in model.named_parameters()}
    optimizer.step()
    
    max_change = 0
    for name, param in model.named_parameters():
        if name in old_params:
            change = (param - old_params[name]).abs().max().item()
            max_change = max(max_change, change)
    
    print(f"   æœ€å¤§æƒé‡å˜åŒ–: {max_change:.6f}")
    
    if max_change < 1e-7:
        print("   âš ï¸  æƒé‡å‡ ä¹æ²¡æœ‰æ›´æ–°ï¼")
        print("   å¯èƒ½åŸå› :")
        print("   - å­¦ä¹ ç‡å¤ªå°")
        print("   - æ¢¯åº¦æ¶ˆå¤±")
        print("   - æ‰€æœ‰å±‚éƒ½è¢«å†»ç»“äº†")
    
    # 5. æ£€æŸ¥å­¦ä¹ ç‡
    print("\n5. å­¦ä¹ ç‡:")
    for i, param_group in enumerate(optimizer.param_groups):
        print(f"   Group {i}: {param_group['lr']:.6f}")

# ä½¿ç”¨
debug_training(model, train_loader, optimizer)
```

### é—®é¢˜3: losså˜æˆNaN

**æ’æŸ¥è„šæœ¬**:
```python
def find_nan_source(model, dataloader):
    """å®šä½NaNæ¥æº"""
    
    print("=== NaNæ¥æºå®šä½ ===\n")
    
    device = next(model.parameters()).device
    
    for batch_idx, (images, labels) in enumerate(dataloader):
        images, labels = images.to(device), labels.to(device)
        
        # 1. æ£€æŸ¥è¾“å…¥
        if torch.isnan(images).any() or torch.isinf(images).any():
            print(f"âŒ Batch {batch_idx}: è¾“å…¥åŒ…å«NaN/Inf!")
            print(f"   NaNæ•°é‡: {torch.isnan(images).sum()}")
            print(f"   Infæ•°é‡: {torch.isinf(images).sum()}")
            return
        
        # 2. é€å±‚æ£€æŸ¥
        hooks = []
        nan_found = False
        
        def check_output(name):
            def hook(module, input, output):
                nonlocal nan_found
                if isinstance(output, torch.Tensor):
                    if torch.isnan(output).any() or torch.isinf(output).any():
                        print(f"âŒ NaN/Infå‡ºç°åœ¨: {name}")
                        print(f"   Output shape: {output.shape}")
                        print(f"   NaNæ•°é‡: {torch.isnan(output).sum()}")
                        print(f"   Infæ•°é‡: {torch.isinf(output).sum()}")
                        nan_found = True
            return hook
        
        # æ³¨å†Œé’©å­
        for name, module in model.named_modules():
            hooks.append(module.register_forward_hook(check_output(name)))
        
        # å‰å‘ä¼ æ’­
        try:
            outputs = model(images)
            loss = nn.functional.cross_entropy(outputs, labels)
            
            if torch.isnan(loss):
                print(f"âŒ Lossä¸ºNaN!")
                print(f"   Outputs: min={outputs.min():.3f}, max={outputs.max():.3f}")
                print(f"   Labels: {labels}")
                nan_found = True
        except Exception as e:
            print(f"âŒ å‰å‘ä¼ æ’­é”™è¯¯: {e}")
            nan_found = True
        
        # ç§»é™¤é’©å­
        for hook in hooks:
            hook.remove()
        
        if nan_found:
            print("\nå»ºè®®:")
            print("1. é™ä½å­¦ä¹ ç‡ (å¦‚1e-6)")
            print("2. ä½¿ç”¨æ¢¯åº¦è£å‰ª")
            print("3. æ£€æŸ¥æ•°æ®é¢„å¤„ç†")
            print("4. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
            return
        
        if batch_idx >= 10:  # åªæ£€æŸ¥å‰10ä¸ªbatch
            print("âœ“ å‰10ä¸ªbatchæœªå‘ç°NaN")
            break

# ä½¿ç”¨
find_nan_source(model, train_loader)
```

---

## æ¨ç†é—®é¢˜æ’æŸ¥

### é—®é¢˜1: æ¨ç†é€Ÿåº¦æ…¢

**æ€§èƒ½åˆ†æ**:
```python
import time
from torch.profiler import profile, ProfilerActivity

def profile_inference(model, input_size=(1, 3, 224, 224), device="cuda"):
    """æ€§èƒ½åˆ†æ"""
    
    model.eval()
    model = model.to(device)
    dummy_input = torch.randn(input_size).to(device)
    
    # 1. åŸºæœ¬é€Ÿåº¦æµ‹è¯•
    print("=== é€Ÿåº¦æµ‹è¯• ===\n")
    
    # é¢„çƒ­
    for _ in range(10):
        with torch.no_grad():
            _ = model(dummy_input)
    
    if device == "cuda":
        torch.cuda.synchronize()
    
    # æµ‹é€Ÿ
    times = []
    for _ in range(100):
        start = time.time()
        with torch.no_grad():
            _ = model(dummy_input)
        if device == "cuda":
            torch.cuda.synchronize()
        times.append(time.time() - start)
    
    avg_time = sum(times) / len(times)
    print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time*1000:.2f} ms")
    print(f"ååé‡: {1/avg_time:.2f} images/sec")
    
    # 2. è¯¦ç»†æ€§èƒ½åˆ†æ
    print("\n=== è¯¦ç»†æ€§èƒ½åˆ†æ ===\n")
    
    with profile(
        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
        record_shapes=True
    ) as prof:
        with torch.no_grad():
            _ = model(dummy_input)
    
    # æ‰“å°æœ€è€—æ—¶çš„æ“ä½œ
    print(prof.key_averages().table(
        sort_by="cuda_time_total" if device == "cuda" else "cpu_time_total",
        row_limit=10
    ))
    
    # 3. å†…å­˜åˆ†æ
    if device == "cuda":
        print("\n=== å†…å­˜åˆ†æ ===\n")
        torch.cuda.reset_peak_memory_stats()
        
        with torch.no_grad():
            _ = model(dummy_input)
        
        peak_memory = torch.cuda.max_memory_allocated() / 1024**2
        print(f"å³°å€¼å†…å­˜: {peak_memory:.2f} MB")

# ä½¿ç”¨
profile_inference(model)
```

### é—®é¢˜2: æ¨ç†ç»“æœä¸ä¸€è‡´

**ä¸€è‡´æ€§æ£€æŸ¥**:
```python
def check_inference_consistency(model, input_tensor, n_runs=10):
    """æ£€æŸ¥æ¨ç†ä¸€è‡´æ€§"""
    
    print("=== ä¸€è‡´æ€§æ£€æŸ¥ ===\n")
    
    model.eval()
    results = []
    
    # å¤šæ¬¡æ¨ç†
    for i in range(n_runs):
        with torch.no_grad():
            output = model(input_tensor)
        results.append(output.cpu())
    
    # æ£€æŸ¥å·®å¼‚
    max_diff = 0
    for i in range(len(results)-1):
        diff = (results[i] - results[i+1]).abs().max().item()
        max_diff = max(max_diff, diff)
    
    print(f"æœ€å¤§å·®å¼‚: {max_diff}")
    
    if max_diff > 1e-5:
        print("âš ï¸  æ¨ç†ç»“æœä¸ä¸€è‡´!")
        print("å¯èƒ½åŸå› :")
        print("1. Dropoutå±‚æ²¡æœ‰å…³é—­ (model.eval())")
        print("2. BatchNormå±‚åœ¨è®­ç»ƒæ¨¡å¼")
        print("3. æ¨¡å‹åŒ…å«éšæœºæ€§æ“ä½œ")
        
        # æ£€æŸ¥dropout
        has_dropout = any(isinstance(m, nn.Dropout) for m in model.modules())
        if has_dropout:
            print("\næ¨¡å‹åŒ…å«Dropoutå±‚ï¼Œç¡®ä¿è°ƒç”¨äº†model.eval()")
        
        # æ£€æŸ¥batchnorm
        has_bn = any(isinstance(m, nn.BatchNorm2d) for m in model.modules())
        if has_bn:
            print("æ¨¡å‹åŒ…å«BatchNormï¼Œç¡®ä¿è°ƒç”¨äº†model.eval()")
    else:
        print("âœ“ æ¨ç†ç»“æœä¸€è‡´")

# ä½¿ç”¨
input_tensor = torch.randn(1, 3, 224, 224).to(device)
check_inference_consistency(model, input_tensor)
```

---

## æ€§èƒ½é—®é¢˜æ’æŸ¥

### GPUåˆ©ç”¨ç‡ä½

**æ’æŸ¥å·¥å…·**:
```bash
#!/bin/bash
# gpu_monitor.sh - GPUç›‘æ§è„šæœ¬

echo "GPUå®æ—¶ç›‘æ§ (Ctrl+Cé€€å‡º)"
echo "================================"

watch -n 1 'nvidia-smi --query-gpu=timestamp,name,utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu --format=csv'

# æˆ–è€…æ›´è¯¦ç»†çš„ç›‘æ§
# nvidia-smi dmon -s pucvmet
```

**å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆ**:

| ç—‡çŠ¶ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| GPUåˆ©ç”¨ç‡<50% | æ•°æ®åŠ è½½å¤ªæ…¢ | å¢åŠ num_workers, ä½¿ç”¨SSD |
| å†…å­˜æœªæ»¡ä½†æ…¢ | Batch sizeå¤ªå° | å¢å¤§batch size |
| æ³¢åŠ¨å¤§ | è®­ç»ƒæ­¥éª¤ä¸å‡è¡¡ | ä¼˜åŒ–æ•°æ®pipeline |
| å¤šGPUä¸å‡è¡¡ | ä½¿ç”¨DataParallel | æ”¹ç”¨DistributedDataParallel |

---

## æ—¥å¿—åˆ†æ

### æ—¥å¿—æ”¶é›†

```python
import logging
import sys
from pathlib import Path

def setup_comprehensive_logging(log_dir="logs", experiment_name="default"):
    """è®¾ç½®å…¨é¢çš„æ—¥å¿—ç³»ç»Ÿ"""
    
    log_dir = Path(log_dir) / experiment_name
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºlogger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    
    # æ§åˆ¶å°handler (INFOçº§åˆ«)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_format = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%H:%M:%S'
    )
    console_handler.setFormatter(console_format)
    
    # æ–‡ä»¶handler - INFO
    info_handler = logging.FileHandler(log_dir / 'info.log')
    info_handler.setLevel(logging.INFO)
    file_format = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d - %(message)s'
    )
    info_handler.setFormatter(file_format)
    
    # æ–‡ä»¶handler - DEBUG
    debug_handler = logging.FileHandler(log_dir / 'debug.log')
    debug_handler.setLevel(logging.DEBUG)
    debug_handler.setFormatter(file_format)
    
    # æ–‡ä»¶handler - ERROR
    error_handler = logging.FileHandler(log_dir / 'error.log')
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(file_format)
    
    # æ·»åŠ handlers
    logger.addHandler(console_handler)
    logger.addHandler(info_handler)
    logger.addHandler(debug_handler)
    logger.addHandler(error_handler)
    
    return logger
```

### æ—¥å¿—åˆ†æè„šæœ¬

```python
def analyze_training_log(log_file):
    """åˆ†æè®­ç»ƒæ—¥å¿—"""
    
    import re
    import matplotlib.pyplot as plt
    
    # æå–losså’Œaccuracy
    losses = []
    accuracies = []
    epochs = []
    
    loss_pattern = r'Loss:\s*([\d.]+)'
    acc_pattern = r'Acc:\s*([\d.]+)'
    epoch_pattern = r'Epoch\s*(\d+)'
    
    with open(log_file) as f:
        for line in f:
            epoch_match = re.search(epoch_pattern, line)
            if epoch_match:
                current_epoch = int(epoch_match.group(1))
            
            loss_match = re.search(loss_pattern, line)
            if loss_match:
                losses.append(float(loss_match.group(1)))
                if epoch_match:
                    epochs.append(current_epoch)
            
            acc_match = re.search(acc_pattern, line)
            if acc_match:
                accuracies.append(float(acc_match.group(1)))
    
    # ç»˜å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    ax1.plot(losses)
    ax1.set_xlabel('Step')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training Loss')
    ax1.grid(True)
    
    if accuracies:
        ax2.plot(accuracies)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Validation Accuracy')
        ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('training_analysis.png')
    print(f"åˆ†æç»“æœå·²ä¿å­˜åˆ° training_analysis.png")
    
    # æ‰“å°ç»Ÿè®¡
    print("\n=== è®­ç»ƒç»Ÿè®¡ ===")
    print(f"æ€»æ­¥æ•°: {len(losses)}")
    print(f"æœ€ç»ˆloss: {losses[-1]:.4f}")
    print(f"æœ€ä½loss: {min(losses):.4f}")
    if accuracies:
        print(f"æœ€é«˜å‡†ç¡®ç‡: {max(accuracies):.2%}")
        print(f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracies[-1]:.2%}")

# ä½¿ç”¨
analyze_training_log("logs/experiment1/train.log")
```

---

## ğŸ”§ å¸¸ç”¨è°ƒè¯•å‘½ä»¤

### PyTorchè°ƒè¯•

```python
# å¯ç”¨å¼‚å¸¸æ£€æµ‹
torch.autograd.set_detect_anomaly(True)

# è®¾ç½®éšæœºç§å­ï¼ˆå¯é‡ç°ï¼‰
torch.manual_seed(42)
torch.cuda.manual_seed_all(42)

# æ‰“å°æ¨¡å‹ç»“æ„
print(model)

# ç»Ÿè®¡å‚æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
print(f"Total parameters: {total_params:,}")

# æ£€æŸ¥æ¢¯åº¦
for name, param in model.named_parameters():
    if param.grad is not None:
        print(f"{name}: grad_norm={param.grad.norm():.4f}")

# å¯è§†åŒ–è®¡ç®—å›¾
from torchviz import make_dot
make_dot(output, params=dict(model.named_parameters())).render("model_graph")
```

### ç³»ç»Ÿè°ƒè¯•

```bash
# æŸ¥çœ‹GPUä½¿ç”¨
nvidia-smi

# å®æ—¶ç›‘æ§GPU
watch -n 1 nvidia-smi

# æŸ¥çœ‹è¿›ç¨‹GPUå ç”¨
nvidia-smi pmon

# æŸ¥çœ‹ç³»ç»Ÿèµ„æº
htop

# æŸ¥çœ‹ç£ç›˜IO
iotop

# æŸ¥çœ‹ç½‘ç»œ
iftop
```

---

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœæœ¬æŒ‡å—æ— æ³•è§£å†³ä½ çš„é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ–‡æ¡£**: [å¸¸è§é—®é¢˜FAQ](./03-å¸¸è§é—®é¢˜FAQ.md)
2. **æäº¤Issue**: https://github.com/YourRepo/issues
3. **ç¤¾åŒºè®¨è®º**: GitHub Discussions

---

**æœ€åæ›´æ–°**: 2025-11-05  
**ç‰ˆæœ¬**: v1.0

