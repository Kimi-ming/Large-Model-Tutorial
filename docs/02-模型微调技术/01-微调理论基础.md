# 01 - 微调理论基础

> 📚 **学习目标**  
> - 理解什么是模型微调及其必要性
> - 掌握全参数微调与参数高效微调的区别
> - 了解常见的微调方法及其适用场景
> - 为后续实践打下理论基础

> 🎯 **先修要求**  
> - 完成第一部分：模型调研与选型
> - 熟悉PyTorch基础
> - 了解Transformer架构基础

> ⏱️ **预计学习时间**: 30-45分钟  
> 🏷️ **难度**: ⭐⭐☆☆☆ 初级

---

## 📖 目录

- [什么是模型微调](#什么是模型微调)
- [为什么需要微调](#为什么需要微调)
- [微调方法分类](#微调方法分类)
- [微调的关键概念](#微调的关键概念)
- [如何选择微调方法](#如何选择微调方法)
- [学习成果验收](#学习成果验收)

---

## 什么是模型微调

### 定义

**模型微调（Fine-tuning）** 是指在预训练模型的基础上，使用特定任务的数据集进行进一步训练，使模型适应新任务的过程。

### 基本流程

```
预训练模型（通用能力）
    ↓
加载预训练权重
    ↓
在特定任务数据上训练
    ↓
微调后的模型（任务专用）
```

### 示例对比

**预训练模型**（通用能力）:
```python
# CLIP模型可以理解通用的图文关系
image = "一只动物的照片"
texts = ["猫", "狗", "鸟"]
# 输出：可以识别，但可能不够精确
```

**微调后模型**（专用能力）:
```python
# 在宠物数据集上微调后
image = "一只金毛犬的照片"
texts = ["金毛犬", "拉布拉多", "哈士奇"]
# 输出：可以精确识别犬种
```

---

## 为什么需要微调

### 1. 任务特异性

预训练模型虽然具有强大的通用能力，但对于特定任务可能不够精确。

**示例**：医学影像分析
- ❌ 通用CLIP：可以识别"X光片"、"CT扫描"
- ✅ 微调后：可以识别"肺部结节"、"骨折类型"

### 2. 领域适应

不同领域的数据分布和术语可能差异很大。

**示例**：工业质检
- ❌ 通用模型：识别"划痕"、"污渍"
- ✅ 微调后：识别"焊接缺陷"、"表面氧化"、"尺寸偏差"

### 3. 数据隐私

某些场景下，数据不能发送到云端API。

**解决方案**：
- 在本地数据上微调开源模型
- 部署到私有环境

### 4. 成本优化

微调小模型可能比调用大模型API更经济。

**成本对比**（假设）:
| 方案 | 初始成本 | 运行成本（1M次调用）|
|------|---------|-------------------|
| GPT-4V API | $0 | $30,000+ |
| 微调CLIP | $500（GPU时间）| $100（推理成本）|

---

## 微调方法分类

### 按参数更新范围分类

#### 1. 全参数微调（Full Fine-tuning）

**定义**：更新模型的所有参数

**优点**:
- ✅ 效果最好
- ✅ 适应能力最强

**缺点**:
- ❌ 需要大量显存
- ❌ 训练时间长
- ❌ 容易过拟合

**适用场景**:
- 有大量标注数据（10K+样本）
- 有充足的计算资源
- 任务与预训练任务差异大

**示例**:
```python
# 全参数微调
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")

# 所有参数都参与训练
for param in model.parameters():
    param.requires_grad = True  # 全部可训练

optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)
```

---

#### 2. 参数高效微调（PEFT - Parameter-Efficient Fine-Tuning）

**定义**：只更新模型的一小部分参数，冻结大部分预训练权重

**优点**:
- ✅ 显存需求小（1/10 - 1/100）
- ✅ 训练速度快
- ✅ 不容易过拟合
- ✅ 可以保存多个任务适配器

**缺点**:
- ⚠️ 效果可能略低于全参数微调
- ⚠️ 需要选择合适的方法

**常见方法**:

##### a) LoRA（Low-Rank Adaptation）⭐ 推荐

**原理**：在模型的注意力层添加低秩矩阵

```
原始权重矩阵 W (d×d)
    ↓ 冻结
W + ΔW
    ↑
ΔW = A×B (A: d×r, B: r×d, r<<d)
    ↑ 只训练这部分
```

**参数量对比**:
- 原始: d×d = 768×768 = 589,824
- LoRA (r=8): d×r + r×d = 768×8 + 8×768 = 12,288
- **减少98%参数量！**

**示例**:
```python
from peft import LoraConfig, get_peft_model

# 配置LoRA
config = LoraConfig(
    r=8,                    # 秩
    lora_alpha=32,          # 缩放因子
    target_modules=["q_proj", "v_proj"],  # 目标层
    lora_dropout=0.1,
)

# 应用LoRA
model = get_peft_model(model, config)
model.print_trainable_parameters()
# 输出: trainable params: 294,912 || all params: 149,620,224 || trainable%: 0.20%
```

##### b) QLoRA（Quantized LoRA）

**原理**：LoRA + 4bit量化

**优势**:
- 显存需求更小（可在消费级GPU上微调70B模型）
- 训练速度更快

**示例**:
```python
from transformers import BitsAndBytesConfig

# 4bit量化配置
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

# 加载量化模型
model = AutoModel.from_pretrained(
    "model_name",
    quantization_config=bnb_config,
)
```

##### c) Adapter Tuning

**原理**：在Transformer层之间插入小型适配器模块

```
Transformer Layer
    ↓
Adapter (down-project → activation → up-project)
    ↓
Transformer Layer
```

##### d) Prefix Tuning

**原理**：在输入序列前添加可训练的"前缀"向量

```
[trainable_prefix] + [input_tokens] → Model → Output
```

##### e) Prompt Tuning

**原理**：只训练输入的prompt嵌入，模型参数完全冻结

---

### 按训练策略分类

#### 1. 监督微调（Supervised Fine-Tuning, SFT）

**定义**：使用标注数据进行有监督训练

**数据格式**:
```json
{
  "image": "path/to/image.jpg",
  "text": "一只金毛犬在草地上奔跑",
  "label": "golden_retriever"
}
```

#### 2. 少样本学习（Few-Shot Learning）

**定义**：只使用少量样本（通常<100）进行微调

**技巧**:
- 使用PEFT方法
- 增加数据增强
- 使用更小的学习率

#### 3. 零样本迁移（Zero-Shot Transfer）

**定义**：不进行微调，直接使用预训练模型

**适用场景**:
- 没有标注数据
- 任务与预训练任务相似

---

## 微调的关键概念

### 1. 学习率（Learning Rate）

**重要性**：微调时的学习率通常比预训练时小得多

**推荐值**:
- 全参数微调：1e-5 ~ 5e-5
- LoRA微调：1e-4 ~ 5e-4
- Adapter微调：1e-3 ~ 5e-3

**原因**：预训练权重已经很好，大幅度更新会破坏已学到的知识

### 2. 学习率调度（Learning Rate Scheduling）

**常用策略**:

```python
# 1. 线性预热 + 余弦衰减
from transformers import get_cosine_schedule_with_warmup

scheduler = get_cosine_schedule_with_warmup(
    optimizer,
    num_warmup_steps=100,      # 预热步数
    num_training_steps=1000,   # 总步数
)
```

**调度曲线**:
```
Learning Rate
    ↑
    |     /\
    |    /  \___
    |   /        \___
    |  /             \___
    |_/___________________\___→ Steps
      预热  稳定训练    衰减
```

### 3. 灾难性遗忘（Catastrophic Forgetting）

**问题**：微调后模型在新任务上表现好，但在原任务上表现下降

**解决方案**:
- 使用PEFT方法（保留原始权重）
- 混合训练数据（新任务 + 原任务样本）
- 使用较小的学习率
- Early Stopping

### 4. 过拟合（Overfitting）

**表现**：训练集准确率高，验证集准确率低

**解决方案**:
- 数据增强
- Dropout
- 权重衰减（Weight Decay）
- Early Stopping
- 使用PEFT方法

### 5. 数据增强（Data Augmentation）

**图像增强**:
```python
from torchvision import transforms

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.4, 0.4, 0.4),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])
```

**文本增强**:
- 同义词替换
- 回译（翻译成其他语言再翻译回来）
- 随机插入/删除/替换

---

## 如何选择微调方法

### 决策树

```
开始
  ↓
有多少标注数据？
  ├─ <100样本 → 使用Few-Shot + LoRA
  ├─ 100-10K样本 → 使用LoRA/QLoRA
  └─ >10K样本 → 可考虑全参数微调
      ↓
有多少GPU显存？
  ├─ <8GB → 使用QLoRA
  ├─ 8-24GB → 使用LoRA
  └─ >24GB → 可使用全参数微调
      ↓
任务与预训练任务相似度？
  ├─ 非常相似 → 可能不需要微调（Zero-Shot）
  ├─ 中等相似 → LoRA足够
  └─ 差异很大 → 考虑全参数微调
```

### 方法对比表

| 方法 | 参数量 | 显存需求 | 训练速度 | 效果 | 推荐场景 |
|------|--------|---------|---------|------|---------|
| **全参数微调** | 100% | 很高（40GB+）| 慢 | ⭐⭐⭐⭐⭐ | 大数据集+充足资源 |
| **LoRA** | 0.1-1% | 低（8-16GB）| 快 | ⭐⭐⭐⭐☆ | 中小数据集（推荐）|
| **QLoRA** | 0.1-1% | 很低（4-8GB）| 很快 | ⭐⭐⭐⭐☆ | 消费级GPU |
| **Adapter** | 1-5% | 低 | 快 | ⭐⭐⭐☆☆ | 多任务场景 |
| **Prefix Tuning** | <0.1% | 很低 | 很快 | ⭐⭐⭐☆☆ | 极少数据 |
| **Prompt Tuning** | <0.01% | 极低 | 极快 | ⭐⭐☆☆☆ | 探索性实验 |

### 实际案例推荐

#### 案例1：宠物品种识别（1000张图像）
**推荐**：LoRA
- 数据量适中
- 任务与CLIP预训练相似
- 单卡GPU即可

#### 案例2：医学影像分析（100张CT扫描）
**推荐**：QLoRA + Few-Shot
- 数据量少
- 需要强数据增强
- 可能需要多轮迭代

#### 案例3：工业质检（50,000张缺陷图像）
**推荐**：全参数微调或LoRA
- 数据量大
- 任务特定性强
- 可投入较多资源

---

## 微调的一般流程

### 步骤1：准备数据

```python
# 数据集结构
dataset/
├── train/
│   ├── class_1/
│   │   ├── img_001.jpg
│   │   └── ...
│   └── class_2/
│       └── ...
└── val/
    └── ...
```

### 步骤2：加载预训练模型

```python
from transformers import CLIPModel, CLIPProcessor

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
```

### 步骤3：配置微调方法

```python
# 选择LoRA
from peft import LoraConfig, get_peft_model

config = LoraConfig(r=8, lora_alpha=32, target_modules=["q_proj", "v_proj"])
model = get_peft_model(model, config)
```

### 步骤4：训练

```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    learning_rate=5e-4,
    warmup_steps=100,
    logging_steps=10,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
)

trainer.train()
```

### 步骤5：评估和保存

```python
# 评估
results = trainer.evaluate()
print(results)

# 保存
model.save_pretrained("./my_finetuned_model")
```

---

## 常见问题

### Q1: 微调需要多少数据？

**答案**：取决于任务和方法
- **Few-Shot（<100）**: 使用QLoRA + 强数据增强
- **中等（100-10K）**: LoRA效果很好
- **大规模（>10K）**: 可考虑全参数微调

### Q2: 微调需要多长时间？

**答案**：取决于数据量和硬件
- **LoRA（1000样本，单卡V100）**: 30分钟 - 2小时
- **全参数微调（10K样本，单卡V100）**: 4-8小时

### Q3: 如何判断微调是否成功？

**指标**：
- 验证集准确率提升
- 训练损失稳定下降
- 没有严重过拟合（训练/验证差距<10%）

### Q4: 微调后效果不好怎么办？

**排查步骤**:
1. 检查数据质量和标注准确性
2. 尝试不同的学习率
3. 增加数据增强
4. 检查是否过拟合
5. 尝试不同的微调方法

---

## 学习成果验收

### 📋 理论理解检查

完成以下问题，确保理解核心概念：

- [ ] 能解释什么是模型微调，以及为什么需要微调
- [ ] 能说出全参数微调和PEFT的区别
- [ ] 能列举至少3种PEFT方法及其特点
- [ ] 理解LoRA的基本原理
- [ ] 能根据数据量和资源选择合适的微调方法

### 🎯 实践准备检查

- [ ] 已安装必要的库（transformers, peft, torch）
- [ ] 理解微调的基本流程（5个步骤）
- [ ] 准备好进入下一章节的实践

### 📝 自测题

1. **选择题**：以下哪种情况最适合使用LoRA？
   - A. 有100,000张标注图像，4张A100 GPU
   - B. 有1,000张标注图像，1张RTX 3090
   - C. 有50张标注图像，1张GTX 1080Ti
   - D. 有10张标注图像，只有CPU

   <details>
   <summary>点击查看答案</summary>
   答案：B。LoRA适合中等数据量和单卡GPU场景。A适合全参数微调，C和D适合QLoRA或Few-Shot。
   </details>

2. **填空题**：LoRA通过添加______矩阵来减少可训练参数，通常可以将参数量减少到原来的______。

   <details>
   <summary>点击查看答案</summary>
   答案：低秩（Low-Rank）；0.1-1%或更少。
   </details>

3. **简答题**：为什么微调时的学习率要比预训练时小？

   <details>
   <summary>点击查看答案</summary>
   答案：因为预训练权重已经学到了很好的通用特征，使用过大的学习率会破坏这些已有知识，导致灾难性遗忘。较小的学习率可以在保留原有知识的基础上，逐步适应新任务。
   </details>

---

## 下一步

恭喜完成理论学习！接下来您可以：

1. **实践LoRA微调** → [02-LoRA微调实践](02-LoRA微调实践.md) ⭐ 推荐
2. **了解全参数微调** → [03-全参数微调](03-全参数微调.md)
3. **探索其他PEFT方法** → [04-其他PEFT方法](04-其他PEFT方法.md)

---

## 参考资源

### 论文

- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
- [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751)

### 代码库

- [Hugging Face PEFT](https://github.com/huggingface/peft)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

### 教程

- [Hugging Face Fine-tuning Guide](https://huggingface.co/docs/transformers/training)
- [PEFT Documentation](https://huggingface.co/docs/peft)

---

**📝 文档版本**: v1.0  
**✍️ 最后更新**: 2025-11-01  
**👥 贡献者**: Large-Model-Tutorial Team

