# æŒç»­å­¦ä¹ ä¸å¢é‡è®­ç»ƒ

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•è®©è§†è§‰å¤§æ¨¡å‹æŒç»­å­¦ä¹ æ–°çŸ¥è¯†ï¼ŒåŒæ—¶é¿å…é—å¿˜æ—§çŸ¥è¯†ï¼Œå®ç°æ¨¡å‹çš„æŒç»­è¿›åŒ–å’Œé€‚åº”ã€‚

---

## ğŸ“‹ ç›®å½•

1. [æŒç»­å­¦ä¹ æ¦‚è¿°](#æŒç»­å­¦ä¹ æ¦‚è¿°)
2. [ç¾éš¾æ€§é—å¿˜é—®é¢˜](#ç¾éš¾æ€§é—å¿˜é—®é¢˜)
3. [æŒç»­å­¦ä¹ ç­–ç•¥](#æŒç»­å­¦ä¹ ç­–ç•¥)
4. [å¢é‡è®­ç»ƒå®è·µ](#å¢é‡è®­ç»ƒå®è·µ)
5. [åœ¨çº¿å­¦ä¹ ç³»ç»Ÿ](#åœ¨çº¿å­¦ä¹ ç³»ç»Ÿ)
6. [æ€§èƒ½è¯„ä¼°](#æ€§èƒ½è¯„ä¼°)

---

## æŒç»­å­¦ä¹ æ¦‚è¿°

### ä»€ä¹ˆæ˜¯æŒç»­å­¦ä¹ 

æŒç»­å­¦ä¹ ï¼ˆContinual Learningï¼‰æ˜¯æŒ‡æ¨¡å‹èƒ½å¤Ÿä¸æ–­å­¦ä¹ æ–°ä»»åŠ¡æˆ–æ–°æ•°æ®ï¼ŒåŒæ—¶ä¿æŒå¯¹æ—§ä»»åŠ¡çš„æ€§èƒ½ã€‚

**ä¼ ç»Ÿå­¦ä¹  vs æŒç»­å­¦ä¹ **:

| ç»´åº¦ | ä¼ ç»Ÿå­¦ä¹  | æŒç»­å­¦ä¹  |
|------|---------|---------|
| **æ•°æ®** | ä¸€æ¬¡æ€§å…¨éƒ¨å¯ç”¨ | åºåˆ—åˆ°è¾¾ |
| **ä»»åŠ¡** | å›ºå®šå•ä¸€ä»»åŠ¡ | å¤šä»»åŠ¡åºåˆ— |
| **è®­ç»ƒ** | ç¦»çº¿æ‰¹é‡è®­ç»ƒ | åœ¨çº¿å¢é‡è®­ç»ƒ |
| **æŒ‘æˆ˜** | è¿‡æ‹Ÿåˆ | ç¾éš¾æ€§é—å¿˜ |

### ä¸ºä»€ä¹ˆéœ€è¦æŒç»­å­¦ä¹ 

**å®é™…åœºæ™¯éœ€æ±‚**:
- ğŸ·ï¸ **æ–°ç±»åˆ«å‡ºç°**: ç”µå•†å¹³å°ä¸æ–­æ¨å‡ºæ–°å•†å“
- ğŸ“Š **æ•°æ®åˆ†å¸ƒå˜åŒ–**: ç”¨æˆ·åå¥½éšæ—¶é—´æ¼”å˜
- ğŸŒ **é¢†åŸŸæ‰©å±•**: æ¨¡å‹éœ€è¦é€‚åº”æ–°çš„åº”ç”¨åœºæ™¯
- ğŸ’° **æˆæœ¬é™åˆ¶**: æ— æ³•æ¯æ¬¡éƒ½é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹

**æŒç»­å­¦ä¹ çš„ä¼˜åŠ¿**:
- âœ… å¿«é€Ÿé€‚åº”æ–°çŸ¥è¯†
- âœ… èŠ‚çœè®¡ç®—èµ„æº
- âœ… ä¿æŒå†å²æ€§èƒ½
- âœ… æ”¯æŒç»ˆèº«å­¦ä¹ 

---

## ç¾éš¾æ€§é—å¿˜é—®é¢˜

### ä»€ä¹ˆæ˜¯ç¾éš¾æ€§é—å¿˜

å½“ç¥ç»ç½‘ç»œåœ¨æ–°ä»»åŠ¡ä¸Šè®­ç»ƒæ—¶ï¼Œä¼šæ€¥å‰§å¿˜è®°æ—§ä»»åŠ¡çš„çŸ¥è¯†ã€‚

```python
import torch
import clip
from torch.utils.data import DataLoader

def demonstrate_catastrophic_forgetting():
    """æ¼”ç¤ºç¾éš¾æ€§é—å¿˜"""
    
    device = "cuda"
    model, preprocess = clip.load("ViT-B/32", device=device)
    
    # ä»»åŠ¡1ï¼šç‹—çš„åˆ†ç±»
    print("è®­ç»ƒä»»åŠ¡1ï¼šç‹—çš„åˆ†ç±»...")
    task1_loader = get_dog_dataloader()
    train(model, task1_loader, epochs=10)
    
    # è¯„ä¼°ä»»åŠ¡1
    acc1_before = evaluate(model, task1_loader)
    print(f"ä»»åŠ¡1å‡†ç¡®ç‡: {acc1_before:.2%}")
    
    # ä»»åŠ¡2ï¼šçŒ«çš„åˆ†ç±»
    print("\nè®­ç»ƒä»»åŠ¡2ï¼šçŒ«çš„åˆ†ç±»...")
    task2_loader = get_cat_dataloader()
    train(model, task2_loader, epochs=10)
    
    # å†æ¬¡è¯„ä¼°ä»»åŠ¡1
    acc1_after = evaluate(model, task1_loader)
    print(f"ä»»åŠ¡1å‡†ç¡®ç‡ï¼ˆé—å¿˜åï¼‰: {acc1_after:.2%}")
    print(f"æ€§èƒ½ä¸‹é™: {(acc1_before - acc1_after):.2%}")
    
    # è¯„ä¼°ä»»åŠ¡2
    acc2 = evaluate(model, task2_loader)
    print(f"ä»»åŠ¡2å‡†ç¡®ç‡: {acc2:.2%}")

# è¿è¡Œæ¼”ç¤º
demonstrate_catastrophic_forgetting()

# å…¸å‹è¾“å‡º:
# ä»»åŠ¡1å‡†ç¡®ç‡: 92.5%
# ä»»åŠ¡1å‡†ç¡®ç‡ï¼ˆé—å¿˜åï¼‰: 45.3%  â† ç¾éš¾æ€§é—å¿˜ï¼
# æ€§èƒ½ä¸‹é™: 47.2%
# ä»»åŠ¡2å‡†ç¡®ç‡: 89.1%
```

### é—å¿˜çš„åŸå› 

1. **å‚æ•°å¹²æ‰°**: æ–°ä»»åŠ¡çš„æ¢¯åº¦è¦†ç›–æ—§ä»»åŠ¡çš„å‚æ•°
2. **è¡¨ç¤ºæ¼‚ç§»**: ç‰¹å¾è¡¨ç¤ºå‘ç”Ÿå˜åŒ–
3. **è¾“å‡ºå±‚ç«äº‰**: ä¸åŒä»»åŠ¡çš„è¾“å‡ºå±‚ç›¸äº’å†²çª

---

## æŒç»­å­¦ä¹ ç­–ç•¥

### ç­–ç•¥1: ç»éªŒå›æ”¾ï¼ˆExperience Replayï¼‰

ä¿å­˜æ—§ä»»åŠ¡çš„æ ·æœ¬ï¼Œåœ¨è®­ç»ƒæ–°ä»»åŠ¡æ—¶æ··åˆä½¿ç”¨ã€‚

```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from collections import deque
import random

class ReplayBuffer:
    """ç»éªŒå›æ”¾ç¼“å†²åŒº"""
    
    def __init__(self, capacity=10000):
        """
        Args:
            capacity: ç¼“å†²åŒºæœ€å¤§å®¹é‡
        """
        self.buffer = deque(maxlen=capacity)
    
    def add(self, images, labels):
        """æ·»åŠ æ ·æœ¬åˆ°ç¼“å†²åŒº"""
        for img, label in zip(images, labels):
            self.buffer.append((img.cpu(), label.cpu()))
    
    def sample(self, batch_size):
        """ä»ç¼“å†²åŒºé‡‡æ ·"""
        samples = random.sample(self.buffer, min(batch_size, len(self.buffer)))
        images, labels = zip(*samples)
        return torch.stack(images), torch.stack(labels)
    
    def __len__(self):
        return len(self.buffer)

class ContinualLearnerWithReplay:
    """ä½¿ç”¨ç»éªŒå›æ”¾çš„æŒç»­å­¦ä¹ å™¨"""
    
    def __init__(self, model, replay_capacity=10000, replay_ratio=0.5):
        """
        Args:
            model: è¦è®­ç»ƒçš„æ¨¡å‹
            replay_capacity: å›æ”¾ç¼“å†²åŒºå¤§å°
            replay_ratio: å›æ”¾æ ·æœ¬å æ¯”
        """
        self.model = model
        self.replay_buffer = ReplayBuffer(capacity=replay_capacity)
        self.replay_ratio = replay_ratio
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        self.criterion = nn.CrossEntropyLoss()
    
    def train_task(self, dataloader, epochs=10):
        """è®­ç»ƒä¸€ä¸ªæ–°ä»»åŠ¡"""
        self.model.train()
        device = next(self.model.parameters()).device
        
        for epoch in range(epochs):
            total_loss = 0
            
            for images, labels in dataloader:
                images, labels = images.to(device), labels.to(device)
                
                # æ·»åŠ åˆ°å›æ”¾ç¼“å†²åŒº
                self.replay_buffer.add(images, labels)
                
                # å‡†å¤‡è®­ç»ƒæ‰¹æ¬¡
                batch_size = len(images)
                replay_size = int(batch_size * self.replay_ratio)
                new_size = batch_size - replay_size
                
                # æ··åˆæ–°æ—§æ ·æœ¬
                if len(self.replay_buffer) > 0 and replay_size > 0:
                    replay_images, replay_labels = self.replay_buffer.sample(replay_size)
                    replay_images = replay_images.to(device)
                    replay_labels = replay_labels.to(device)
                    
                    # åˆå¹¶
                    mixed_images = torch.cat([images[:new_size], replay_images])
                    mixed_labels = torch.cat([labels[:new_size], replay_labels])
                else:
                    mixed_images, mixed_labels = images, labels
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(mixed_images)
                loss = self.criterion(outputs, mixed_labels)
                
                # åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item()
            
            avg_loss = total_loss / len(dataloader)
            print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

# ä½¿ç”¨ç¤ºä¾‹
from transformers import CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
learner = ContinualLearnerWithReplay(
    model,
    replay_capacity=5000,
    replay_ratio=0.5  # 50%çš„æ‰¹æ¬¡æ¥è‡ªå›æ”¾
)

# æŒç»­å­¦ä¹ å¤šä¸ªä»»åŠ¡
task_loaders = [task1_loader, task2_loader, task3_loader]

for task_id, task_loader in enumerate(task_loaders):
    print(f"\nè®­ç»ƒä»»åŠ¡ {task_id + 1}...")
    learner.train_task(task_loader, epochs=10)
    
    # è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
    print(f"\nè¯„ä¼°æ‰€æœ‰ä»»åŠ¡:")
    for i, eval_loader in enumerate(task_loaders[:task_id+1]):
        acc = evaluate(model, eval_loader)
        print(f"  ä»»åŠ¡ {i+1} å‡†ç¡®ç‡: {acc:.2%}")
```

### ç­–ç•¥2: å¼¹æ€§æƒé‡å·©å›ºï¼ˆEWCï¼‰

ä¿æŠ¤å¯¹æ—§ä»»åŠ¡é‡è¦çš„å‚æ•°ã€‚

```python
import torch
import torch.nn as nn
from copy import deepcopy

class EWC:
    """å¼¹æ€§æƒé‡å·©å›ºï¼ˆElastic Weight Consolidationï¼‰"""
    
    def __init__(self, model, dataloader, device="cuda", lambda_ewc=1000):
        """
        Args:
            model: è¦ä¿æŠ¤çš„æ¨¡å‹
            dataloader: æ—§ä»»åŠ¡çš„æ•°æ®
            lambda_ewc: EWCæ­£åˆ™åŒ–ç³»æ•°
        """
        self.model = model
        self.lambda_ewc = lambda_ewc
        self.device = device
        
        # ä¿å­˜æ—§å‚æ•°
        self.old_params = {
            name: param.clone().detach()
            for name, param in model.named_parameters()
            if param.requires_grad
        }
        
        # è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µ
        self.fisher = self._compute_fisher(dataloader)
    
    def _compute_fisher(self, dataloader):
        """è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µï¼ˆå‚æ•°é‡è¦æ€§ï¼‰"""
        fisher = {
            name: torch.zeros_like(param)
            for name, param in self.model.named_parameters()
            if param.requires_grad
        }
        
        self.model.eval()
        criterion = nn.CrossEntropyLoss()
        
        for images, labels in dataloader:
            images, labels = images.to(self.device), labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(images)
            loss = criterion(outputs, labels)
            
            # åå‘ä¼ æ’­
            self.model.zero_grad()
            loss.backward()
            
            # ç´¯ç§¯æ¢¯åº¦å¹³æ–¹ï¼ˆFisherä¿¡æ¯ï¼‰
            for name, param in self.model.named_parameters():
                if param.requires_grad and param.grad is not None:
                    fisher[name] += param.grad.data ** 2
        
        # å¹³å‡
        n_samples = len(dataloader.dataset)
        for name in fisher:
            fisher[name] /= n_samples
        
        return fisher
    
    def penalty(self):
        """è®¡ç®—EWCæƒ©ç½šé¡¹"""
        loss = 0
        for name, param in self.model.named_parameters():
            if name in self.old_params:
                # (Î¸ - Î¸*)^2 * F
                loss += torch.sum(
                    self.fisher[name] * (param - self.old_params[name]) ** 2
                )
        
        return self.lambda_ewc * loss

class ContinualLearnerWithEWC:
    """ä½¿ç”¨EWCçš„æŒç»­å­¦ä¹ å™¨"""
    
    def __init__(self, model, lambda_ewc=1000):
        self.model = model
        self.lambda_ewc = lambda_ewc
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        self.criterion = nn.CrossEntropyLoss()
        self.ewc_tasks = []
    
    def train_task(self, dataloader, epochs=10):
        """è®­ç»ƒæ–°ä»»åŠ¡"""
        device = next(self.model.parameters()).device
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            total_task_loss = 0
            total_ewc_loss = 0
            
            for images, labels in dataloader:
                images, labels = images.to(device), labels.to(device)
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(images)
                task_loss = self.criterion(outputs, labels)
                
                # è®¡ç®—EWCæƒ©ç½š
                ewc_loss = 0
                for ewc in self.ewc_tasks:
                    ewc_loss += ewc.penalty()
                
                # æ€»æŸå¤±
                loss = task_loss + ewc_loss
                
                # åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item()
                total_task_loss += task_loss.item()
                total_ewc_loss += ewc_loss.item() if ewc_loss != 0 else 0
            
            print(f"Epoch {epoch+1}: Loss={total_loss/len(dataloader):.4f}, "
                  f"Task={total_task_loss/len(dataloader):.4f}, "
                  f"EWC={total_ewc_loss/len(dataloader):.4f}")
        
        # å®Œæˆä»»åŠ¡åï¼Œæ·»åŠ EWC
        print("è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µ...")
        ewc = EWC(self.model, dataloader, device=device, 
                 lambda_ewc=self.lambda_ewc)
        self.ewc_tasks.append(ewc)

# ä½¿ç”¨ç¤ºä¾‹
model = get_model()
learner = ContinualLearnerWithEWC(model, lambda_ewc=5000)

for task_id, task_loader in enumerate(task_loaders):
    print(f"\n=== è®­ç»ƒä»»åŠ¡ {task_id + 1} ===")
    learner.train_task(task_loader, epochs=10)
```

### ç­–ç•¥3: æ¸è¿›ç¥ç»ç½‘ç»œï¼ˆProgressive Networksï¼‰

ä¸ºæ¯ä¸ªæ–°ä»»åŠ¡æ·»åŠ æ–°çš„ç½‘ç»œåˆ†æ”¯ã€‚

```python
import torch
import torch.nn as nn

class ProgressiveNetwork(nn.Module):
    """æ¸è¿›ç¥ç»ç½‘ç»œ"""
    
    def __init__(self, base_model, feature_dim=512):
        super().__init__()
        self.feature_dim = feature_dim
        self.tasks = nn.ModuleList([base_model])
        self.adapters = nn.ModuleList([])
    
    def add_task(self, new_model):
        """æ·»åŠ æ–°ä»»åŠ¡çš„ç½‘ç»œ"""
        # å†»ç»“æ—§ä»»åŠ¡çš„å‚æ•°
        for task in self.tasks:
            for param in task.parameters():
                param.requires_grad = False
        
        # æ·»åŠ æ–°ä»»åŠ¡
        self.tasks.append(new_model)
        
        # æ·»åŠ ä¾§å‘è¿æ¥ï¼ˆä»æ—§ä»»åŠ¡åˆ°æ–°ä»»åŠ¡ï¼‰
        n_old_tasks = len(self.tasks) - 1
        adapter = nn.ModuleList([
            nn.Linear(self.feature_dim, self.feature_dim)
            for _ in range(n_old_tasks)
        ])
        self.adapters.append(adapter)
    
    def forward(self, x, task_id):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥
            task_id: ä»»åŠ¡IDï¼ˆ0-basedï¼‰
        """
        # è®¡ç®—æ‰€æœ‰å…ˆå‰ä»»åŠ¡çš„ç‰¹å¾
        prev_features = []
        for i in range(task_id):
            with torch.no_grad():
                feat = self.tasks[i](x)
            prev_features.append(feat)
        
        # å½“å‰ä»»åŠ¡çš„ç‰¹å¾
        current_feat = self.tasks[task_id](x)
        
        # ä¾§å‘è¿æ¥ï¼šèåˆå…ˆå‰ä»»åŠ¡çš„çŸ¥è¯†
        if task_id > 0:
            lateral = sum(
                self.adapters[task_id][i](prev_features[i])
                for i in range(task_id)
            )
            current_feat = current_feat + lateral
        
        return current_feat

# ä½¿ç”¨ç¤ºä¾‹
base_model = ImageEncoder(output_dim=512)
prog_net = ProgressiveNetwork(base_model)

# è®­ç»ƒç¬¬ä¸€ä¸ªä»»åŠ¡
train(prog_net.tasks[0], task1_loader)

# æ·»åŠ ç¬¬äºŒä¸ªä»»åŠ¡
task2_model = ImageEncoder(output_dim=512)
prog_net.add_task(task2_model)
train(prog_net.tasks[1], task2_loader)

# æ¨ç†
with torch.no_grad():
    # ä»»åŠ¡1
    output1 = prog_net(test_image, task_id=0)
    # ä»»åŠ¡2ï¼ˆåˆ©ç”¨ä»»åŠ¡1çš„çŸ¥è¯†ï¼‰
    output2 = prog_net(test_image, task_id=1)
```

### ç­–ç•¥4: çŸ¥è¯†è’¸é¦æŒç»­å­¦ä¹ 

ä½¿ç”¨æ—§æ¨¡å‹ä½œä¸ºæ•™å¸ˆæŒ‡å¯¼æ–°æ¨¡å‹ã€‚

```python
class LwF:
    """Learning without Forgetting (LwF)"""
    
    def __init__(self, model, temperature=2.0, alpha=0.5):
        """
        Args:
            model: æ¨¡å‹
            temperature: è’¸é¦æ¸©åº¦
            alpha: è’¸é¦æŸå¤±æƒé‡
        """
        self.model = model
        self.old_model = None
        self.temperature = temperature
        self.alpha = alpha
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        self.criterion = nn.CrossEntropyLoss()
    
    def train_task(self, dataloader, new_classes, epochs=10):
        """
        è®­ç»ƒæ–°ä»»åŠ¡
        
        Args:
            dataloader: æ–°ä»»åŠ¡çš„æ•°æ®
            new_classes: æ–°ç±»åˆ«æ•°é‡
        """
        device = next(self.model.parameters()).device
        
        # ä¿å­˜æ—§æ¨¡å‹
        if self.old_model is None:
            # ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼Œæ²¡æœ‰è’¸é¦
            self.old_model = deepcopy(self.model)
            self.old_model.eval()
            for param in self.old_model.parameters():
                param.requires_grad = False
        
        # æ‰©å±•åˆ†ç±»å¤´
        old_classes = self.model.classifier.out_features
        new_classifier = nn.Linear(
            self.model.classifier.in_features,
            old_classes + new_classes
        )
        
        # å¤åˆ¶æ—§æƒé‡
        with torch.no_grad():
            new_classifier.weight[:old_classes] = self.model.classifier.weight
            new_classifier.bias[:old_classes] = self.model.classifier.bias
        
        self.model.classifier = new_classifier.to(device)
        
        # è®­ç»ƒ
        self.model.train()
        for epoch in range(epochs):
            for images, labels in dataloader:
                images, labels = images.to(device), labels.to(device)
                labels += old_classes  # è°ƒæ•´æ ‡ç­¾åç§»
                
                # æ–°æ¨¡å‹è¾“å‡º
                outputs = self.model(images)
                
                # ä»»åŠ¡æŸå¤±
                task_loss = self.criterion(outputs[:, old_classes:], 
                                          labels - old_classes)
                
                # è’¸é¦æŸå¤±ï¼ˆå¯¹äºæ—§ç±»åˆ«ï¼‰
                if old_classes > 0:
                    with torch.no_grad():
                        old_outputs = self.old_model(images)
                    
                    distill_loss = nn.KLDivLoss(reduction='batchmean')(
                        nn.functional.log_softmax(
                            outputs[:, :old_classes] / self.temperature, dim=1
                        ),
                        nn.functional.softmax(
                            old_outputs / self.temperature, dim=1
                        )
                    ) * (self.temperature ** 2)
                else:
                    distill_loss = 0
                
                # æ€»æŸå¤±
                loss = self.alpha * distill_loss + (1 - self.alpha) * task_loss
                
                # æ›´æ–°
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
        
        # æ›´æ–°æ—§æ¨¡å‹
        self.old_model = deepcopy(self.model)
        self.old_model.eval()
        for param in self.old_model.parameters():
            param.requires_grad = False

# ä½¿ç”¨ç¤ºä¾‹
model = CLIPClassifier(num_classes=10)  # åˆå§‹10ä¸ªç±»åˆ«
lwf = LwF(model, temperature=2.0, alpha=0.5)

# ä»»åŠ¡1: 10ä¸ªç±»åˆ«
lwf.train_task(task1_loader, new_classes=10, epochs=10)

# ä»»åŠ¡2: æ–°å¢5ä¸ªç±»åˆ«
lwf.train_task(task2_loader, new_classes=5, epochs=10)

# ä»»åŠ¡3: æ–°å¢8ä¸ªç±»åˆ«
lwf.train_task(task3_loader, new_classes=8, epochs=10)

# ç°åœ¨æ¨¡å‹å¯ä»¥è¯†åˆ« 10+5+8=23 ä¸ªç±»åˆ«
```

---

## å¢é‡è®­ç»ƒå®è·µ

### CLIPæ¨¡å‹çš„å¢é‡è®­ç»ƒ

```python
import torch
import clip
from torch.utils.data import DataLoader

class IncrementalCLIP:
    """CLIPå¢é‡è®­ç»ƒ"""
    
    def __init__(self, model_name="ViT-B/32", strategy="replay"):
        """
        Args:
            model_name: CLIPæ¨¡å‹åç§°
            strategy: å¢é‡å­¦ä¹ ç­–ç•¥ ('replay', 'ewc', 'lwf')
        """
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.preprocess = clip.load(model_name, device=self.device)
        self.strategy = strategy
        
        # æ ¹æ®ç­–ç•¥åˆå§‹åŒ–
        if strategy == "replay":
            self.replay_buffer = ReplayBuffer(capacity=5000)
        elif strategy == "ewc":
            self.ewc_tasks = []
        elif strategy == "lwf":
            self.old_model = None
    
    def incremental_train(self, new_dataloader, epochs=5):
        """
        å¢é‡è®­ç»ƒ
        
        Args:
            new_dataloader: æ–°æ•°æ®çš„DataLoader
            epochs: è®­ç»ƒè½®æ•°
        """
        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)
        
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            
            for images, texts in new_dataloader:
                images = images.to(self.device)
                texts = clip.tokenize(texts).to(self.device)
                
                # CLIPå¯¹æ¯”å­¦ä¹ æŸå¤±
                image_features = self.model.encode_image(images)
                text_features = self.model.encode_text(texts)
                
                # å½’ä¸€åŒ–
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                
                # å¯¹æ¯”æŸå¤±
                logits = (image_features @ text_features.T) * 100
                labels = torch.arange(len(logits)).to(self.device)
                
                loss_i2t = nn.functional.cross_entropy(logits, labels)
                loss_t2i = nn.functional.cross_entropy(logits.T, labels)
                loss = (loss_i2t + loss_t2i) / 2
                
                # æ ¹æ®ç­–ç•¥æ·»åŠ æ­£åˆ™åŒ–
                if self.strategy == "replay" and len(self.replay_buffer) > 0:
                    # æ··åˆå›æ”¾æ ·æœ¬
                    replay_images, replay_texts = self.replay_buffer.sample(len(images) // 2)
                    # ... è®¡ç®—å›æ”¾æŸå¤±å¹¶åŠ åˆ°lossä¸Š
                    pass
                
                elif self.strategy == "ewc":
                    # æ·»åŠ EWCæƒ©ç½š
                    for ewc in self.ewc_tasks:
                        loss += ewc.penalty()
                
                elif self.strategy == "lwf" and self.old_model is not None:
                    # æ·»åŠ è’¸é¦æŸå¤±
                    with torch.no_grad():
                        old_image_feat = self.old_model.encode_image(images)
                        old_image_feat = old_image_feat / old_image_feat.norm(dim=-1, keepdim=True)
                    
                    distill_loss = 1 - (image_features * old_image_feat).sum(dim=-1).mean()
                    loss += 0.5 * distill_loss
                
                # æ›´æ–°
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                
                # æ·»åŠ åˆ°å›æ”¾ç¼“å†²åŒº
                if self.strategy == "replay":
                    self.replay_buffer.add(images, texts)
            
            print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(new_dataloader):.4f}")
        
        # ä»»åŠ¡åå¤„ç†
        if self.strategy == "ewc":
            ewc = EWC(self.model, new_dataloader, self.device)
            self.ewc_tasks.append(ewc)
        elif self.strategy == "lwf":
            self.old_model = deepcopy(self.model)
            self.old_model.eval()
    
    def evaluate(self, test_dataloader):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for images, texts in test_dataloader:
                images = images.to(self.device)
                texts = clip.tokenize(texts).to(self.device)
                
                image_features = self.model.encode_image(images)
                text_features = self.model.encode_text(texts)
                
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                
                similarity = (image_features @ text_features.T)
                predictions = similarity.argmax(dim=-1)
                labels = torch.arange(len(images)).to(self.device)
                
                correct += (predictions == labels).sum().item()
                total += len(images)
        
        accuracy = correct / total
        return accuracy

# ä½¿ç”¨ç¤ºä¾‹
incre_clip = IncrementalCLIP(model_name="ViT-B/32", strategy="replay")

# åºåˆ—ä»»åŠ¡
tasks = [
    ("animals", animal_loader),
    ("vehicles", vehicle_loader),
    ("furniture", furniture_loader)
]

for task_name, task_loader in tasks:
    print(f"\nè®­ç»ƒä»»åŠ¡: {task_name}")
    incre_clip.incremental_train(task_loader, epochs=5)
    
    # è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
    for name, eval_loader in tasks[:tasks.index((task_name, task_loader))+1]:
        acc = incre_clip.evaluate(eval_loader)
        print(f"  {name} å‡†ç¡®ç‡: {acc:.2%}")
```

---

## åœ¨çº¿å­¦ä¹ ç³»ç»Ÿ

### å®æ—¶å¢é‡å­¦ä¹ æœåŠ¡

```python
from fastapi import FastAPI, UploadFile, File
from PIL import Image
import io
import torch

app = FastAPI()

class OnlineLearningSystem:
    """åœ¨çº¿å­¦ä¹ ç³»ç»Ÿ"""
    
    def __init__(self):
        self.model, self.preprocess = clip.load("ViT-B/32")
        self.model.train()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)
        
        # ç´¯ç§¯æ¢¯åº¦ï¼ˆç”¨äºå°æ‰¹é‡æ›´æ–°ï¼‰
        self.accumulated_gradients = []
        self.batch_size = 32
    
    def predict(self, image, text_candidates):
        """é¢„æµ‹"""
        self.model.eval()
        
        # é¢„å¤„ç†
        image_input = self.preprocess(image).unsqueeze(0)
        text_input = clip.tokenize(text_candidates)
        
        # æ¨ç†
        with torch.no_grad():
            image_features = self.model.encode_image(image_input)
            text_features = self.model.encode_text(text_input)
            
            # ç›¸ä¼¼åº¦
            similarity = (image_features @ text_features.T).softmax(dim=-1)
        
        best_idx = similarity.argmax().item()
        return text_candidates[best_idx], similarity[0, best_idx].item()
    
    def online_update(self, image, correct_label):
        """åœ¨çº¿æ›´æ–°æ¨¡å‹"""
        self.model.train()
        
        # å‡†å¤‡æ•°æ®
        image_input = self.preprocess(image).unsqueeze(0)
        text_input = clip.tokenize([correct_label])
        
        # å‰å‘ä¼ æ’­
        image_features = self.model.encode_image(image_input)
        text_features = self.model.encode_text(text_input)
        
        # å¯¹æ¯”æŸå¤±ï¼ˆæ­£æ ·æœ¬å¯¹ï¼‰
        similarity = (image_features @ text_features.T)
        loss = -similarity.mean()  # æœ€å¤§åŒ–ç›¸ä¼¼åº¦
        
        # ç´¯ç§¯æ¢¯åº¦
        loss.backward()
        self.accumulated_gradients.append(loss.item())
        
        # æ‰¹é‡æ›´æ–°
        if len(self.accumulated_gradients) >= self.batch_size:
            self.optimizer.step()
            self.optimizer.zero_grad()
            
            avg_loss = sum(self.accumulated_gradients) / len(self.accumulated_gradients)
            self.accumulated_gradients = []
            
            print(f"æ¨¡å‹å·²æ›´æ–°ï¼Œå¹³å‡æŸå¤±: {avg_loss:.4f}")
            return True
        
        return False

# å…¨å±€å­¦ä¹ ç³»ç»Ÿ
learning_system = OnlineLearningSystem()

@app.post("/predict")
async def predict(file: UploadFile = File(...), candidates: list[str] = None):
    """é¢„æµ‹æ¥å£"""
    image = Image.open(io.BytesIO(await file.read()))
    prediction, confidence = learning_system.predict(image, candidates)
    
    return {
        "prediction": prediction,
        "confidence": float(confidence)
    }

@app.post("/feedback")
async def feedback(file: UploadFile = File(...), correct_label: str = None):
    """åé¦ˆæ¥å£ï¼ˆè§¦å‘åœ¨çº¿å­¦ä¹ ï¼‰"""
    image = Image.open(io.BytesIO(await file.read()))
    updated = learning_system.online_update(image, correct_label)
    
    return {
        "status": "updated" if updated else "accumulated",
        "message": "æ¨¡å‹å·²æ›´æ–°" if updated else "åé¦ˆå·²è®°å½•"
    }

# è¿è¡ŒæœåŠ¡
# uvicorn online_learning:app --host 0.0.0.0 --port 8000
```

---

## æ€§èƒ½è¯„ä¼°

### æŒç»­å­¦ä¹ è¯„ä¼°æŒ‡æ ‡

```python
class ContinualLearningEvaluator:
    """æŒç»­å­¦ä¹ è¯„ä¼°å™¨"""
    
    def __init__(self):
        self.task_accuracies = []  # æ¯ä¸ªä»»åŠ¡åœ¨å„ä¸ªæ—¶åˆ»çš„å‡†ç¡®ç‡
    
    def evaluate_all_tasks(self, model, task_loaders, current_task_id):
        """è¯„ä¼°æ‰€æœ‰å·²å­¦ä¹ çš„ä»»åŠ¡"""
        accuracies = []
        
        for task_id, task_loader in enumerate(task_loaders[:current_task_id+1]):
            acc = evaluate(model, task_loader)
            accuracies.append(acc)
        
        self.task_accuracies.append(accuracies)
        return accuracies
    
    def compute_average_accuracy(self):
        """è®¡ç®—å¹³å‡å‡†ç¡®ç‡"""
        if not self.task_accuracies:
            return 0
        
        # æœ€åä¸€è½®çš„å¹³å‡å‡†ç¡®ç‡
        last_round = self.task_accuracies[-1]
        return sum(last_round) / len(last_round)
    
    def compute_forgetting(self):
        """
        è®¡ç®—é—å¿˜ç¨‹åº¦
        
        Returns:
            forgetting: å¹³å‡é—å¿˜ç‡
        """
        if len(self.task_accuracies) < 2:
            return 0
        
        forgetting_per_task = []
        
        for task_id in range(len(self.task_accuracies[-1]) - 1):
            # ä»»åŠ¡task_idçš„æœ€é«˜å‡†ç¡®ç‡
            max_acc = max(round[task_id] for round in self.task_accuracies 
                         if len(round) > task_id)
            
            # æœ€ç»ˆå‡†ç¡®ç‡
            final_acc = self.task_accuracies[-1][task_id]
            
            # é—å¿˜ = æœ€é«˜ - æœ€ç»ˆ
            forgetting = max_acc - final_acc
            forgetting_per_task.append(forgetting)
        
        return sum(forgetting_per_task) / len(forgetting_per_task)
    
    def compute_forward_transfer(self):
        """
        è®¡ç®—æ­£å‘è¿ç§»ï¼ˆæ–°ä»»åŠ¡ä»æ—§çŸ¥è¯†ä¸­å—ç›Šç¨‹åº¦ï¼‰
        
        Returns:
            forward_transfer: æ­£å‘è¿ç§»åˆ†æ•°
        """
        if len(self.task_accuracies) < 2:
            return 0
        
        # å¯¹æ¯”ï¼šæœ‰é¢„è®­ç»ƒ vs ä»å¤´è®­ç»ƒ
        # ç®€åŒ–ç‰ˆæœ¬ï¼šçœ‹æ–°ä»»åŠ¡çš„åˆå§‹å‡†ç¡®ç‡
        transfers = []
        
        for i in range(1, len(self.task_accuracies)):
            # æ–°ä»»åŠ¡çš„åˆå§‹è¡¨ç°
            initial_acc = self.task_accuracies[i][-1]
            # ä¸éšæœºåˆå§‹åŒ–å¯¹æ¯”ï¼ˆå‡è®¾ä¸º0ï¼‰
            transfer = initial_acc - 0.1  # 0.1ä¸ºéšæœºbaseline
            transfers.append(transfer)
        
        return sum(transfers) / len(transfers) if transfers else 0
    
    def print_summary(self):
        """æ‰“å°è¯„ä¼°æ‘˜è¦"""
        print("\n" + "="*50)
        print("æŒç»­å­¦ä¹ è¯„ä¼°æ‘˜è¦")
        print("="*50)
        
        print(f"\n1. å¹³å‡å‡†ç¡®ç‡: {self.compute_average_accuracy():.2%}")
        print(f"2. å¹³å‡é—å¿˜ç‡: {self.compute_forgetting():.2%}")
        print(f"3. æ­£å‘è¿ç§»: {self.compute_forward_transfer():.2%}")
        
        print("\nå„ä»»åŠ¡å‡†ç¡®ç‡å˜åŒ–:")
        for round_id, accuracies in enumerate(self.task_accuracies):
            print(f"  ç¬¬{round_id+1}è½®: {[f'{acc:.2%}' for acc in accuracies]}")

# ä½¿ç”¨ç¤ºä¾‹
evaluator = ContinualLearningEvaluator()

for task_id, task_loader in enumerate(task_loaders):
    # è®­ç»ƒä»»åŠ¡
    train_task(model, task_loader)
    
    # è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
    accuracies = evaluator.evaluate_all_tasks(model, task_loaders, task_id)
    print(f"\nä»»åŠ¡{task_id+1}åçš„å‡†ç¡®ç‡: {[f'{acc:.2%}' for acc in accuracies]}")

# æœ€ç»ˆè¯„ä¼°
evaluator.print_summary()
```

### å…¸å‹è¾“å‡º

```
==================================================
æŒç»­å­¦ä¹ è¯„ä¼°æ‘˜è¦
==================================================

1. å¹³å‡å‡†ç¡®ç‡: 85.3%
2. å¹³å‡é—å¿˜ç‡: 5.2%
3. æ­£å‘è¿ç§»: 3.8%

å„ä»»åŠ¡å‡†ç¡®ç‡å˜åŒ–:
  ç¬¬1è½®: ['92.5%']
  ç¬¬2è½®: ['88.3%', '89.1%']
  ç¬¬3è½®: ['85.7%', '86.4%', '87.9%']
  ç¬¬4è½®: ['83.2%', '84.8%', '85.6%', '86.7%']
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„ç­–ç•¥

| åœºæ™¯ | æ¨èç­–ç•¥ | ç†ç”± |
|------|---------|------|
| **å†…å­˜å……è¶³** | ç»éªŒå›æ”¾ | æ•ˆæœæœ€å¥½ï¼Œå®ç°ç®€å• |
| **å†…å­˜å—é™** | EWC/LwF | ä¸éœ€è¦å­˜å‚¨æ—§æ•°æ® |
| **å¤šä»»åŠ¡å¹¶è¡Œ** | æ¸è¿›ç½‘ç»œ | ä»»åŠ¡é—´ä¸å¹²æ‰° |
| **å®æ—¶åœ¨çº¿** | å°æ‰¹é‡å›æ”¾ + LwF | å¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœ |

### 2. è¶…å‚æ•°è°ƒä¼˜

```python
# ç»éªŒå›æ”¾
replay_ratio = 0.3-0.5  # 30-50%çš„æ‰¹æ¬¡æ¥è‡ªå›æ”¾
buffer_size = 5000-10000  # æ ¹æ®å†…å­˜è°ƒæ•´

# EWC
lambda_ewc = 1000-10000  # æ ¹æ®ä»»åŠ¡æ•°é‡è°ƒæ•´

# LwF
temperature = 2.0-4.0  # è’¸é¦æ¸©åº¦
alpha = 0.3-0.7  # è’¸é¦æŸå¤±æƒé‡
```

### 3. ç›‘æ§å’Œè°ƒè¯•

```python
# è®°å½•å…³é”®æŒ‡æ ‡
def log_continual_learning_metrics(model, task_id, epoch):
    """è®°å½•æŒç»­å­¦ä¹ æŒ‡æ ‡"""
    metrics = {
        'task_id': task_id,
        'epoch': epoch,
        'timestamp': datetime.now(),
        'model_size_mb': get_model_size(model),
        'num_parameters': count_parameters(model),
    }
    
    # è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
    for i in range(task_id + 1):
        acc = evaluate(model, task_loaders[i])
        metrics[f'task_{i}_accuracy'] = acc
    
    # è®¡ç®—é—å¿˜
    if task_id > 0:
        metrics['forgetting'] = compute_forgetting(metrics)
    
    # ä¿å­˜
    save_metrics(metrics)
    
    return metrics
```

---

## ğŸ”— å‚è€ƒèµ„æº

### è®ºæ–‡
- [Continual Lifelong Learning with Neural Networks](https://www.sciencedirect.com/science/article/pii/S0893608019300231)
- [Overcoming Catastrophic Forgetting](https://arxiv.org/abs/1612.00796) (EWC)
- [Learning without Forgetting](https://arxiv.org/abs/1606.09282) (LwF)
- [Progressive Neural Networks](https://arxiv.org/abs/1606.04671)

### å·¥å…·åº“
- [Avalanche](https://github.com/ContinualAI/avalanche): æŒç»­å­¦ä¹ åº“
- [Continuum](https://github.com/Continvvm/continuum): æŒç»­å­¦ä¹ åŸºå‡†

### ç›¸å…³æ–‡æ¡£
- [æ¨¡å‹å¾®è°ƒ](../02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/02-LoRAå¾®è°ƒå®è·µ.md)
- [çŸ¥è¯†è’¸é¦](./01-æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ.md#çŸ¥è¯†è’¸é¦)

---

## ğŸ¯ å®è·µä»»åŠ¡

### ä»»åŠ¡1: å®ç°ç»éªŒå›æ”¾
1. åˆ›å»ºå›æ”¾ç¼“å†²åŒº
2. å®ç°æ··åˆé‡‡æ ·ç­–ç•¥
3. å¯¹æ¯”æœ‰æ— å›æ”¾çš„æ•ˆæœ

### ä»»åŠ¡2: EWCå®è·µ
1. è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µ
2. å®ç°EWCæƒ©ç½šé¡¹
3. è°ƒä¼˜lambda_ewcå‚æ•°

### ä»»åŠ¡3: æ„å»ºåœ¨çº¿å­¦ä¹ ç³»ç»Ÿ
1. å®ç°å®æ—¶é¢„æµ‹æ¥å£
2. æ·»åŠ åé¦ˆæ›´æ–°æœºåˆ¶
3. è¯„ä¼°åœ¨çº¿å­¦ä¹ æ•ˆæœ

### ä»»åŠ¡4: å¤šç­–ç•¥å¯¹æ¯”
1. å®ç°3ç§æŒç»­å­¦ä¹ ç­–ç•¥
2. åœ¨ç›¸åŒä»»åŠ¡åºåˆ—ä¸Šæµ‹è¯•
3. å¯¹æ¯”é—å¿˜ç‡å’Œå‡†ç¡®ç‡

---

**ç›¸å…³æ–‡æ¡£**:
- [æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ](./01-æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ.md)
- [å¤šæ¨¡æ€èåˆ](./02-å¤šæ¨¡æ€èåˆ.md)
- [LoRAå¾®è°ƒå®è·µ](../02-æ¨¡å‹å¾®è°ƒæŠ€æœ¯/02-LoRAå¾®è°ƒå®è·µ.md)

